{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kuhan Wang 17-09-15\n",
    "#This code is mostly cribbed from tutorials from Matvey Ezhov's Github\n",
    "#at https://github.com/ematvey/tensorflow-seq2seq-tutorials\n",
    "\n",
    "#Modifications have been made to allow for the encoder and decoders to be stacked\n",
    "#into multiple layers and to output the inference probabilities.\n",
    "#In addition, as opposed Ezhov's original copy task example, the hyperparameters\n",
    "#have been tuned to apply to a more realistic language model problem.\n",
    "\n",
    "#Otherwise, the code implements a bidirectional seq2seq model with attention as\n",
    "#laid out in Ezhov's original tutorial.\n",
    "\n",
    "#This code is successfully executed on tensorflow 1.0 with python 3.5\n",
    "#Benchmark language models can be trained within 2-3 days on a single Tesla K10.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import helpers\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def devCheck(dev_encoded_text, dev_decoded_text, inf_dev):\n",
    "\n",
    "        fd_inf = make_inference_inputs([i for i in dev_encoded_text])\n",
    "\n",
    "        if inf_dev == True:\n",
    "            \n",
    "            inf_out = session.run(decoder_prediction_inference, fd_inf)\n",
    "            inf_prob_out = session.run(decoder_prediction_prob_inference, fd_inf)\n",
    "\n",
    "            for (idx, pred) in enumerate(zip(inf_out.T, inf_prob_out.T)):\n",
    "\n",
    "                print ('INFERENCE EXAMPLE: ', idx)\n",
    "                print ('encode in', [inv_map[i] for i in dev_encoded_text[idx]])\n",
    "                print ('decode in', [inv_map[i] for i in dev_decoded_text[idx]])\n",
    "\n",
    "                print ('inference text out', [inv_map[i] for i in pred[0]])\n",
    "                print ('inference out prob', pred[1][idx])\n",
    "\n",
    "                if idx>1: break\n",
    "\n",
    "            return inf_out, inf_prob_out\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return fd_inf\n",
    "\n",
    "def make_train_inputs(input_seq, target_seq):\n",
    "    inputs_, inputs_length_ = helpers.batch(input_seq)\n",
    "    targets_, targets_length_ = helpers.batch(target_seq)\n",
    "    \n",
    "    return {\n",
    "        encoder_inputs: inputs_,\n",
    "        encoder_inputs_length: inputs_length_,\n",
    "        decoder_targets: targets_,\n",
    "        decoder_targets_length: targets_length_,\n",
    "    }\n",
    "\n",
    "def make_inference_inputs(input_seq):\n",
    "    inputs_, inputs_length_ = helpers.batch(input_seq)\n",
    "\n",
    "    return {\n",
    "        encoder_inputs: inputs_,\n",
    "        encoder_inputs_length: inputs_length_,\n",
    "    }\n",
    "\n",
    "def numericEncode(sent):\n",
    "\n",
    "    if type(sent) == str: sent = sent.split(' ')\n",
    "    \n",
    "    return [vocab_dict[word] if word in vocab_dict else 2 for word in sent]\n",
    "\n",
    "def decodeSent(sent):\n",
    "    return [inv_map[i] for i in sent]\n",
    "\n",
    "def predictionCheck(mean_metric):\n",
    "\n",
    "    df_metric = pd.DataFrame(mean_metric, columns=['input', 'truth', 'inference', 'inference_prob', 'epoch', 'batch'])\n",
    "\n",
    "    checkListResults = list(map(checkList, df_metric['truth'].values, df_metric['inference'].values))\n",
    "\n",
    "    df_metric['input_sent'] = df_metric['input'].apply(decodeSent)\n",
    "\n",
    "    df_metric['truth_sent'] = df_metric['truth'].apply(decodeSent)\n",
    "    df_metric['inference_sent'] = df_metric['inference'].apply(decodeSent)\n",
    "    df_metric['checkList'] = checkListResults\n",
    "\n",
    "    df_metric['meanCheckList'] = df_metric['checkList'].apply(np.mean)\n",
    "    \n",
    "    return df_metric\n",
    "\n",
    "def checkList(x, y):\n",
    "    \n",
    "    len_y = len(y)\n",
    "    len_x = len(x)\n",
    "    \n",
    "    matching = [x[i]==y[i] if i<len_y else False for i in range(len_x)]\n",
    "    \n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = pd.read_pickle('processed_data_v01_EN-DE_py35_seq_length_5_15_sample_540659_limited_vocab.pkl')\n",
    "#vocab_dict = pickle.load(open('word_dict_v01_EN-DE_py35_seq_length_5_15_sample_540659_limited_vocab.pkl', 'rb'))\n",
    "\n",
    "df_all = pd.read_pickle('processed_data\\processed_data_v01_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl')\n",
    "vocab_dict = pickle.load(open('dicts\\word_dict_v01_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl', 'rb'))\n",
    "\n",
    "#Encode sequences\n",
    "df_all['alpha_Pair_1_encoding'] =  df_all['alpha_Pair_1_tokens'].apply(numericEncode)\n",
    "df_all['alpha_Pair_0_encoding'] = df_all['alpha_Pair_0_tokens'].apply(numericEncode)\n",
    "\n",
    "df_all['Index'] = df_all.index.values\n",
    "\n",
    "df_all_train = df_all.sample(frac=0.90, random_state=0)\n",
    "\n",
    "df_all_dev = df_all[df_all['Index'].isin(df_all_train['Index'].values) == False]\n",
    "\n",
    "inv_map = {v: k for k, v in vocab_dict.items()}\n",
    "\n",
    "dev_encoded_text = df_all_dev['alpha_Pair_0_encoding'].values\n",
    "dev_decoded_text = df_all_dev['alpha_Pair_1_encoding'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3830, 5), (58, 5), 7239)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_train.shape, df_all_dev.shape, len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = len(vocab_dict) \n",
    "input_embedding_size = 256\n",
    "\n",
    "length_from = 3\n",
    "length_to = 49\n",
    "vocab_lower = 0\n",
    "vocab_upper = vocab_size\n",
    "n_batch_size = 32\n",
    "\n",
    "batches_in_epoch = df_all_train.shape[0]/n_batch_size\n",
    "\n",
    "n_cells = 128\n",
    "num_layers = 2\n",
    "\n",
    "n_epochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.6875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_in_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_batches = helpers.random_sequences(length_from=length_from, length_to=length_to,\n",
    "                                       vocab_lower=vocab_lower, vocab_upper=vocab_size,\n",
    "                                       batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create handles for encoder and decoders\n",
    "encoder_inputs = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs',\n",
    "        )\n",
    "\n",
    "encoder_inputs_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs_length',\n",
    "        )\n",
    "\n",
    "# required for training, not required for testing\n",
    "decoder_targets = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_targets'\n",
    "        )\n",
    "\n",
    "decoder_targets_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_targets_length',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_size, batch_size = tf.unstack(tf.shape(decoder_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make EOS and PAD matrices to concatenate with targets\n",
    "EOS_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * EOS\n",
    "PAD_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding EOS to the beginning of the decoder targets\n",
    "decoder_train_inputs = tf.concat([EOS_SLICE, decoder_targets], axis=0)\n",
    "decoder_train_length = decoder_targets_length + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_train_targets = tf.concat([decoder_targets, PAD_SLICE], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_train_targets_seq_len, _ = tf.unstack(tf.shape(decoder_train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pad out the decoder matrix to be time major\n",
    "#Which decoder matrix? must be in input?\n",
    "#This puts the EOS in the correct position and puts zeroes else, then the actual encoded seq is added on?\n",
    "decoder_train_targets_eos_mask = tf.one_hot(decoder_train_length - 1,\n",
    "                                                        decoder_train_targets_seq_len,\n",
    "                                                        on_value=EOS, off_value=PAD,\n",
    "                                                        dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why are we transposing here?\n",
    "decoder_train_targets_eos_mask = tf.transpose(decoder_train_targets_eos_mask, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yep looks like it, add the decoder targets and the Padded matrix to create the time major matrix\n",
    "decoder_train_targets = tf.add(decoder_train_targets,\n",
    "                                           decoder_train_targets_eos_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One parameter characterizing the weight in each target? Make the length equal to the longest sequence in the batch\n",
    "loss_weights = tf.ones([batch_size, \n",
    "                        tf.reduce_max(decoder_train_length)], \n",
    "                        dtype=tf.float32, name=\"loss_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create word embeddings\n",
    "sqrt3 = math.sqrt(3)\n",
    "initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "\n",
    "#Randomly initialize a embedding vector for each term in the vocabulary\n",
    "embedding_matrix = tf.get_variable(name=\"embedding_matrix\", shape=[vocab_size, input_embedding_size],\n",
    "                                    initializer=initializer, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map each input unit to a column in the embedding matrix\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, encoder_inputs)\n",
    "\n",
    "decoder_train_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, decoder_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bi-directional encoder, encoding the forward and backward states\n",
    "#The core abstraction is in tf.nn.bidirectional_dynamic_rnn!\n",
    "#The encoder_cell is the LSTM itself\n",
    "#Here cell refers to all the units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_keep = 1\n",
    "decoder_output_keep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell_fw = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells), input_keep_prob=1, \n",
    "                                             output_keep_prob=encoder_output_keep)\n",
    "\n",
    "#encoder_cell = tf.contrib.rnn.LSTMCell(n_cells)\n",
    "encoder_cell_fw = tf.contrib.rnn.MultiRNNCell([encoder_cell_fw for _ in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell_bw = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells), input_keep_prob=1, \n",
    "                                             output_keep_prob=encoder_output_keep)\n",
    "\n",
    "#encoder_cell = tf.contrib.rnn.LSTMCell(n_cells)\n",
    "encoder_cell_bw = tf.contrib.rnn.MultiRNNCell([encoder_cell_bw for _ in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells*2), input_keep_prob=1, \n",
    "                                             output_keep_prob=decoder_output_keep)\n",
    "\n",
    "#decoder_cell = tf.contrib.rnn.LSTMCell(n_cells*2)\n",
    "decoder_cell = tf.contrib.rnn.MultiRNNCell([decoder_cell for _ in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_cell.state_size, encoder_inputs_embedded, encoder_inputs_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    " (encoder_fw_outputs, encoder_bw_outputs),\n",
    " (encoder_fw_state, encoder_bw_state)\n",
    ") = (\n",
    "     tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell_fw, \n",
    "                                     cell_bw=encoder_cell_bw,\n",
    "                                     inputs=encoder_inputs_embedded,\n",
    "                                     sequence_length=encoder_inputs_length,\n",
    "                                     time_major=True, dtype=tf.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate backward and forward outputs\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#encoder_state_c = tf.concat((encoder_fw_state.c, encoder_bw_state.c), 1, name='bidirectional_concat_c')\n",
    "#encoder_state_h = tf.concat((encoder_fw_state.h, encoder_bw_state.h), 1, name='bidirectional_concat_h')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_state = tf.contrib.rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_state = []\n",
    "\n",
    "for i in range(num_layers):\n",
    "    \n",
    "   # if isinstance(encoder_fw_state[i], tf.contrib.rnn.LSTMStateTuple):\n",
    "\n",
    "    encoder_state_c = tf.concat((encoder_fw_state[i].c, encoder_bw_state[i].c), 1, name='bidirectional_concat_c')\n",
    "    encoder_state_h = tf.concat((encoder_fw_state[i].h, encoder_bw_state[i].h), 1, name='bidirectional_concat_h')\n",
    "    \n",
    "    current_encoder_state = tf.contrib.rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "   #elif isinstance(encoder_fw_state[i], tf.Tensor):\n",
    "   #current_encoder_state = tf.concat((encoder_fw_state[i], encoder_bw_state[i]), 1, name='bidirectional_concat')\n",
    "    \n",
    "    encoder_state.append(current_encoder_state)\n",
    "\n",
    "encoder_state = tuple(encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_states = tf.transpose(encoder_outputs, perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the purpose of scope?\n",
    "\n",
    "with tf.variable_scope('Decoder') as scope:\n",
    "\n",
    "    def output_fn(outputs):\n",
    "        return tf.contrib.layers.linear(outputs, vocab_size, scope=scope)\n",
    " \n",
    "    attention_states = tf.transpose(encoder_outputs, perm=[1, 0, 2])\n",
    "\n",
    "    (\n",
    "        attention_keys,\n",
    "        attention_values,\n",
    "        attention_score_fn,\n",
    "        attention_construct_fn\n",
    "    ) = tf.contrib.seq2seq.prepare_attention(\n",
    "                        attention_states=attention_states,\n",
    "                        attention_option=\"bahdanau\",\n",
    "                        num_units=decoder_cell.output_size) \n",
    "\n",
    "    decoder_fn_train = tf.contrib.seq2seq.attention_decoder_fn_train(\n",
    "                        encoder_state=encoder_state,\n",
    "                        attention_keys=attention_keys,\n",
    "                        attention_values=attention_values,\n",
    "                        attention_score_fn=attention_score_fn,\n",
    "                        attention_construct_fn=attention_construct_fn,\n",
    "                        name='attention_decoder')\n",
    "\n",
    "    decoder_fn_inference = tf.contrib.seq2seq.attention_decoder_fn_inference(\n",
    "                        output_fn=output_fn,\n",
    "                        encoder_state=encoder_state,\n",
    "                        attention_keys=attention_keys,\n",
    "                        attention_values=attention_values,\n",
    "                        attention_score_fn=attention_score_fn,\n",
    "                        attention_construct_fn=attention_construct_fn,\n",
    "                        embeddings=embedding_matrix,\n",
    "                        start_of_sequence_id=EOS,\n",
    "                        end_of_sequence_id=EOS,\n",
    "                        maximum_length=tf.reduce_max(encoder_inputs_length) + 3,\n",
    "                        num_decoder_symbols=vocab_size\n",
    "                    )\n",
    "\n",
    "    (\n",
    "     decoder_outputs_train,\n",
    "     decoder_state_train,\n",
    "     decoder_context_state_train\n",
    "    ) = (tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "                                           cell=decoder_cell,\n",
    "                                           decoder_fn=decoder_fn_train,\n",
    "                                           inputs=decoder_train_inputs_embedded,\n",
    "                                           sequence_length=decoder_train_length,\n",
    "                                           time_major=True, scope=scope,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    decoder_logits_train = output_fn(decoder_outputs_train)\n",
    "\n",
    "    decoder_prediction_train = tf.argmax(decoder_logits_train, axis=-1, name='decoder_prediction_train')\n",
    "    \n",
    "    \n",
    "    scope.reuse_variables()\n",
    "\n",
    "    (decoder_logits_inference,\n",
    "     decoder_state_inference,\n",
    "     decoder_context_state_inference) = (\n",
    "        tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "            cell=decoder_cell,\n",
    "            decoder_fn=decoder_fn_inference,\n",
    "            time_major=True,\n",
    "           scope=scope,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    decoder_prediction_inference = tf.argmax(decoder_logits_inference, axis=-1, name='decoder_prediction_inference')\n",
    "   \n",
    "    decoder_prediction_prob_inference = tf.nn.softmax(decoder_logits_inference, name='decoder_prediction_prob_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optimizer\n",
    "\n",
    "logits = tf.transpose(decoder_logits_train, [1, 0, 2])\n",
    "targets = tf.transpose(decoder_train_targets, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.contrib.seq2seq.sequence_loss(logits=logits, targets=targets,\n",
    "                                  weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.001\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, \\\n",
    "                                           n_epochs*int(batches_in_epoch), 0.0001, staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_track = []\n",
    "dev_loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_task = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 1\n",
      "learning rate 0.000999923\n",
      "epoch 0\n",
      "batch 0\n",
      "training minibatch loss: 8.870307922363281\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 290 5139 5490 4058  818  175 4260  592 4780  398  516  818 6432 6806 4440\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > you access in response to this latest email we may need to kick it higher <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5075  393 6826 3974 2595 2132 5893 2222 4880 3837 3576   86    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > if they are being registered at all ? enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6315 6315    1    1    1    1    1    1    1    1    1    1    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > phony phony <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.00828262339419\n",
      "0.00552747140523\n",
      "global_step: 120\n",
      "learning rate 0.000990755\n",
      "epoch 1\n",
      "batch 0\n",
      "training minibatch loss: 7.414375305175781\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5444 1728 5762 5518 2637 5893 5505 3723 1408  390 5577 2072 1435  243 2222\n",
      " 6261 4880 3837 3576   86    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > entity has had some or all of its assets purchased by carolina power light ? thanks enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4297  818 5933 7196 3499 4880 3837 3576   86    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > confirm to sandra please advise enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [439   1 208   1 208   1   1   1   1   1   1   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "    dec train predicted > i <EOS> the <EOS> the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.0329239073146\n",
      "0.0298447754675\n",
      "global_step: 239\n",
      "learning rate 0.000981672\n",
      "epoch 2\n",
      "batch 0\n",
      "training minibatch loss: 7.056860446929932\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [6179 6826 4780 1654  175 6762 2222 2038 2222 5747 7196 3499 4671 3581 4533\n",
      " 6681 5505  208 3890 5505  208 2225 7196 3499 5075 5984 1621 5106 5384 1557\n",
      " 1165  290 2615 2861 4880   86    1    0    0    0    0    0]\n",
      "    enc input           > where are we on this case ? sanders ? dave please advise bob richard and me of the nature of the dispute please advise if not received within business day thank you litigation unit enron corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 3808 2732  175 3706 6806 1707  818 6681 2222 7070  818 4714 1437 5890\n",
      " 5577 3990 1654 4533 7196 3499 5075 5984 1621 5106 5384 1557 1165  290    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > i never got this does it belong to me ? hearing to operational energy corporation by fedex on and please advise if not received within business day thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880  208  208  208  208  208 4880  208  208    1    1  208  208  208  208\n",
      "  208  208  208  208  208  208    1  290  208  208  208  208    1  290  290\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > enron the the the the the enron the the <EOS> <EOS> the the the the the the the the the the <EOS> you the the the the <EOS> you you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.0402282246481\n",
      "0.0525063294145\n",
      "global_step: 358\n",
      "learning rate 0.000972672\n",
      "epoch 3\n",
      "batch 0\n",
      "training minibatch loss: 6.794994354248047\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1821 6826  290 6637 1156 5934 6583 1614    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > here are you positions have a good evening <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 803 6362 5075  290 4505  175 4639 5698    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > take see if you like this one better <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439  208  818  290  290  818  208 2222 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > i the to you you to the ? ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.022041774887\n",
      "0.0147670616421\n",
      "global_step: 477\n",
      "learning rate 0.000963754\n",
      "epoch 4\n",
      "batch 0\n",
      "training minibatch loss: 6.260334014892578\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1903 4725  763 1597 6826 5253 5740 3626 6257 2881 4786 2611 1557 4771  763\n",
      "  693 1654  208 5036 6268  818 5036  208 1415    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > anymore problems b there are no new messages added for that given day yet b click on the send button to send the message <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1384 6806 6042  818 2883 3887 6818  601 1654  208 3044 1415 1915 2222 6261\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > is it okay to set up these guys on the gas message board ? thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196  208 1384  818  208  818  818  208  208  208 1415 5505    1    1    1\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > please the is to the to to the the the message of <EOS> <EOS> <EOS> <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0290656448167\n",
      "0.0113980217811\n",
      "global_step: 596\n",
      "learning rate 0.000954919\n",
      "epoch 5\n",
      "batch 0\n",
      "training minibatch loss: 6.234484672546387\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 3832 3872  439 5675 4371 3249 5934 6583 3858 1141 6681 3832    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i know someone i think would be a good fit let me know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4399  439 5036  208 3188  818 3405 2637  290 1264 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > should i send the resume to dawn or you directly ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 3249 4505  208 5856    1  208    1 1141    1  818    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > i be like the meeting <EOS> the <EOS> let <EOS> to <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.0312036394208\n",
      "0.00696159969258\n",
      "global_step: 715\n",
      "learning rate 0.000946164\n",
      "epoch 6\n",
      "batch 0\n",
      "training minibatch loss: 5.660416603088379\n",
      "  sample 1:\n",
      "    Index 6\n",
      "    enc input           > [4185 6336  439 1179 2985 3969 5687 3588    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > nice presentation i ll give other comments later <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2088 4230 1281 4786 1384 6225  208 5698 4686 1654 3403 3724  153 5674 4631\n",
      "  208 3258 3082  179 1141 6681 3832 1916 5911 4780 2545  753 2589  175 2884\n",
      "    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > more interesting content that is published the better summaries on enrononline objection over us publishing the kase newsletters pls let me know asap so we can proceed with this further <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439  439  439  439  439 2274  818 3969 1141    1  208    1    1  208    1\n",
      "    1 2040    1    1 1141 6681 3832 5075    1  439 2545 1156    1  208 6261\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > i i i i i been to other let <EOS> the <EOS> <EOS> the <EOS> <EOS> desk <EOS> <EOS> let me know if <EOS> i can have <EOS> the thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.0797698289886\n",
      "0.0102058531746\n",
      "global_step: 834\n",
      "learning rate 0.00093749\n",
      "epoch 7\n",
      "batch 0\n",
      "training minibatch loss: 5.882485389709473\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2919 1384  759 1654  175 3997  724 6826 1894  393 5632 2274 3708 2919 2888\n",
      " 1894 4533 4780 4952 1894 1654 7058 2146  200  208 6409 1357 1894 1654 6818\n",
      "  724    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > prebon is right on this both deals are mw they ve been changed prebon shows mw and we show mw on each deal confirmed the megawatts as mw on these deals <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6850 3708 1544 5617 4742  208 3764 2919 2888 1894 4533 4780 4952 1894 1654\n",
      " 7058 2146  200  208 6409 1357 1894 1654 6818  724    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > were changed accordingly sorry about the confusion prebon shows mw and we show mw on each deal confirmed the megawatts as mw on these deals <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6818 3708  279 1654  175  208 6409 1894 1894 1894 4533 1894 1894 6818  279\n",
      " 6818 6409 4533 1894 6409    1 1894 5505 6818  724 1894    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > these changed out on this the megawatts mw mw mw and mw mw these out these megawatts and mw megawatts <EOS> mw of these deals mw <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.0549121602356\n",
      "0.0124873863267\n",
      "global_step: 953\n",
      "learning rate 0.000928894\n",
      "epoch 8\n",
      "batch 0\n",
      "training minibatch loss: 5.169139385223389\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4361 6412 4780 6411 4574 5707  208 2311 3974 6774  987 4019 2222    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > how do we immunize ourselves from the workouts being shed into raptor ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4989  208 1858 3398 4780 5675 4399   20 2222 4361 6412 4780 6411 4574 5707\n",
      "  208 2311 3974 6774  987 4019 2222    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > incorporate the write downs we think should occur ? how do we immunize ourselves from the workouts being shed into raptor ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4989 4989 2311 3398 1384 6411  439 4705 2222    1 2255 4780 6411  130 2222\n",
      "  208 2311 6774 6774 3398 4019 2222    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > incorporate incorporate workouts downs is immunize i get ? <EOS> s we immunize helpful ? the workouts shed shed downs raptor ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.0615673215008\n",
      "0.00357340410507\n",
      "global_step: 1072\n",
      "learning rate 0.000920378\n",
      "epoch 9\n",
      "batch 0\n",
      "training minibatch loss: 5.291324615478516\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 994 4990 4786 2545  439 4705 5934  481 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > advice changes that can i get a copy ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5253 6143 2545 2388 1165  290 4645  994 4990 4786 2545  439 4705 5934  481\n",
      " 2222    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > no problema can t thank you enough advice changes that can i get a copy ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2545 6143 2545 2388 4705  290  208 2222 2222 4786  439  290 4705 5934  481\n",
      " 2222    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > can problema can t get you the ? ? that i you get a copy ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104358526468\n",
      "0.00700231481481\n",
      "global_step: 1191\n",
      "learning rate 0.00091194\n",
      "epoch 10\n",
      "batch 0\n",
      "training minibatch loss: 5.440119743347168\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [6164 4149 4739 2589 5702  393 1156 6806 1255 4399 3249 2050 5893  971 6826\n",
      " 6583 6261    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > chris just checked with broker they have it wrong should be np all trades are good thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5893  971 6826 6583 6261    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > all trades are good thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6806 1384 1384 2274 2589    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > it is is been with <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.139861423492\n",
      "0.0094696969697\n",
      "global_step: 1310\n",
      "learning rate 0.00090358\n",
      "epoch 11\n",
      "batch 0\n",
      "training minibatch loss: 5.048754692077637\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1974 5712 3249 5720 5577 4635 1908 4880 3837 3576   86    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > group must be approved by mark taylor enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 625 7196 3307 5257 4880 3837 3576   86 1974 5712 3249 5720 5577 4635 1908\n",
      " 4880 3837 3576   86    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > stephanie please note below enron north america corp group must be approved by mark taylor enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 625 1384 3499 5257 7196 3837 3576   86    1 1384 1156  306 2881 4880 1908\n",
      " 1384 3837 3576   86    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > stephanie is advise below please north america corp <EOS> is have able for enron taylor is north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.156361018302\n",
      "0.0176131721628\n",
      "global_step: 1429\n",
      "learning rate 0.000895296\n",
      "epoch 12\n",
      "batch 0\n",
      "training minibatch loss: 4.683619022369385\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [ 439 4649 6386  290 5934 3188 5505 4328 4848 3431 3883 5505 1260 1210 1384\n",
      " 5646 5934 2170 2132 5518 5014  818 1349 7015 5106 4880 4742 4880 5253  516\n",
      "  818 1741 6806 2255 5934 4545 2578 1156 5934 4567 5123 5709    1]\n",
      "    enc input           > i am sending you a resume of renee smith an employee of ebs she is considering a transfer at some point to another position within enron about enron no need to mention it s a confidential request have a very happy thanksgiving <EOS>\n",
      "    dec input           > [ 660 1970 2546 3188 1357 4780 5762 5872 5483 1597 1654 1906 2637 1384 6701\n",
      "  439 1179 6412 4786 5996 6746 2222 2222 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > find attached my resume as we had arranged yesterday there on january or is ok i ll do that holyday season ? ? ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4491 1970  208 3188 5505 1597 5762 5872 5872 5872 1384  208 2222 4880 5934\n",
      " 2222 1179 6412 6806 5996 6746 2222    1 2222 2222    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > attend attached the resume of there had arranged arranged arranged is the ? enron a ? ll do it holyday season ? <EOS> ? ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.216497753194\n",
      "0.0183767539597\n",
      "global_step: 1548\n",
      "learning rate 0.000887087\n",
      "epoch 13\n",
      "batch 0\n",
      "training minibatch loss: 4.3863067626953125\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 175  434 6806 1384 3887  818  290    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > this month it is up to you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2545  290 1095 6415  208  339 2222 4081 4941 4780 2395 2110 5957 2219 2827\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > can you track down the info ? close once we deliver our deliverables stay tuned <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2545  290 1095 6681  208  339    1 2395    1 1421 2395 6806 5957 2395 2827\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > can you track me the info <EOS> deliver <EOS> fun deliver it deliverables deliver tuned <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.165285816079\n",
      "0.00867660984848\n",
      "global_step: 1667\n",
      "learning rate 0.000878955\n",
      "epoch 14\n",
      "batch 0\n",
      "training minibatch loss: 4.187537670135498\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4786 3872 5490 4887 2222 6164 1384  208 1478 7116 4880 3837 3576   86 6983\n",
      "  175  818 3872 5703    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > that someone in global ? chris is the ces expert enron north america corp forward this to someone else <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 2545 1141  413 3832 3796 5265 4705 2589  290 4742  208\n",
      " 3027 1561 6826 5257  439 4649 6436  818  660  279 5471  818 3864  500 5911\n",
      " 2129  290 2545 4378 6681 5750 4371 3249 1041 4647    1    0    0    0    0]\n",
      "    dec input           > enron north america corp can let her know pam will get with you about the koch piece are below i am trying to find out who to pay monday so whatever you can tell me today would be greatly appreciated <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86  439 3209 6681 3832 3796 5265  660 4742 1344 2222  208\n",
      " 3027 1561 1384 2222  439 4649  955  818 4705 6361 5505  439  208  208  439\n",
      "  439  290  516 4705 6681  818  439 3249 1041 4647    1    1    0    0    0\n",
      "    0]\n",
      "    dec train predicted > enron north america corp i feel me know pam will find about him ? the koch piece is ? i am left to get together of i the the i i you need get me to i be greatly appreciated <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20773161245\n",
      "0.0184179678142\n",
      "global_step: 1786\n",
      "learning rate 0.000870896\n",
      "epoch 15\n",
      "batch 0\n",
      "training minibatch loss: 4.1201043128967285\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86 2132 2365 5490 3676 2387 5934    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > enron north america corp at pm in conference room a <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 2110 2002 2881  175 5856 1728  210  818 1149 4880 3837\n",
      " 3576   86 2132 2365 5490 3676 2387 5934    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > enron north america corp our location for this meeting has moved to c enron north america corp at pm in conference room a <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 4880 2002 2881  208 5856 5265  210  818 3771    1   86\n",
      " 3576   86    1 4649 5490 6583 2387 5490 3676    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > enron north america corp enron location for the meeting will moved to attending <EOS> corp america corp <EOS> am in good room in conference <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.267080308988\n",
      "0.0171490446258\n",
      "global_step: 1905\n",
      "learning rate 0.000862912\n",
      "epoch 16\n",
      "batch 0\n",
      "training minibatch loss: 3.962716817855835\n",
      "  sample 1:\n",
      "    Index 681\n",
      "    enc input           > [1141 6681 6362 2826  439 2545 6412 6815 7036  175 3569 3051 2388 2732 5253\n",
      " 5465 2222 2455 2132 4153 1893 1069    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > let me see what i can do filing since this order ain t got no details ? faxed at noon california time <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5427 4635 6547 5265 2467  175 3887 4880 3837 3576   86 2132  208 5856 5471\n",
      " 4399 4780 4243 2589 1654  175 2222 5563 1427    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > yes mark greenberg will pick this up enron north america corp at the meeting who should we work with on this ? best regards <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5427 4635 6547 5265 6616 6806  818 4880 3837 3576   86    1 4526 5856 2222\n",
      " 1384 4780 4705 1654 2222  175 2222 1427 1427    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > yes mark greenberg will help it to enron north america corp <EOS> your meeting ? is we get on ? this ? regards regards <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.31716325931\n",
      "0.014125485945\n",
      "global_step: 2024\n",
      "learning rate 0.000855001\n",
      "epoch 17\n",
      "batch 0\n",
      "training minibatch loss: 4.0710954666137695\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2251 2531 2881 2279 1357 4394 2826 6826 4526 4030 2222  790 5490  208 6893\n",
      " 2335 5317 4399 4780 3266 3277 3629 2222 1349  981 6907  434 1814 1862 1394\n",
      " 2160  208 3721 4533 3406  208 2040 5707 3614 3510 6022  208 1581    1    0]\n",
      "    enc input           > cash risk for baseload as well what are your thoughts ? interest in the west fundies lately should we keep his services ? another book prompt month phys fixed price nom the market and prevent the desk from working markets through the brokers <EOS> <PAD>\n",
      "    dec input           > [2126 2251 2338 3829 2251 2531 2881 2279 1357 4394 2826 6826 4526 4030 2222\n",
      "  790 5490  208 6893 2335 5317 4399 4780 3266 3277 3629 2222 1349  981 6907\n",
      "  434 1814 1862 1394 2160  208 3721 4533 3406  208 2040 5707 3614 3510 6022\n",
      "  208 1581    1]\n",
      "    dec input           > subject cash books etc cash risk for baseload as well what are your thoughts ? interest in the west fundies lately should we keep his services ? another book prompt month phys fixed price nom the market and prevent the desk from working markets through the brokers <EOS>\n",
      "    dec train predicted > [2126 2251 2338 3829 2251 2531 1357 2279 1357 4394 1357 6826  208 4030 2222\n",
      " 2531 5490  208 6893 2335 5317 4399  208 4170  208 3629 2132 1349  434 6907\n",
      "  434 1814 6508 1394 2160  208 3721    1 3406  208  434    1  208 3510 2132\n",
      "  208 1581    1    1]\n",
      "    dec train predicted > subject cash books etc cash risk as baseload as well as are the thoughts ? risk in the west fundies lately should the hear the services at another month prompt month phys scott price nom the market <EOS> prevent the month <EOS> the markets at the brokers <EOS> <EOS>\n",
      "0.350935168503\n",
      "0.0140346777066\n",
      "global_step: 2143\n",
      "learning rate 0.000847162\n",
      "epoch 18\n",
      "batch 0\n",
      "training minibatch loss: 3.555765151977539\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3403 6261 3520   34 7196 1141 6681 3832    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > enrononline thanks resolutions prepared please let me know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2222 4880 3837 3576   86 4281 1988  485 3403 6261 3520   34 7196 1141 6681\n",
      " 3832    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > ? enron north america corp ena legal dept enrononline thanks resolutions prepared please let me know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2222 4880 3837 3576   86 4281 1988  485 3403 4533 3520   34 7196 1141 6681\n",
      " 3832 6261    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > ? enron north america corp ena legal dept enrononline and resolutions prepared please let me know thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.343422984865\n",
      "0.0\n",
      "global_step: 2262\n",
      "learning rate 0.000839395\n",
      "epoch 19\n",
      "batch 0\n",
      "training minibatch loss: 3.9693102836608887\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3234 4505 4786 4533 6873 4371  290 6779 6806 2132 4243 2222    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > something like that and why would you announce it at work ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5939 3237 5712 3249 1654 3237 3234 4505 4786 4533 6873 4371  290 6779 6806\n",
      " 2132 4243 2222    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > strong drugs must be on drugs something like that and why would you announce it at work ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5939 3237 5712 3249 5490 3237 5911 4505 4786 2222 4361 4371  290 6779 4786\n",
      " 2222  208 2222    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > strong drugs must be in drugs so like that ? how would you announce that ? the ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.440882174817\n",
      "0.00804620726496\n",
      "global_step: 2381\n",
      "learning rate 0.000831699\n",
      "epoch 20\n",
      "batch 0\n",
      "training minibatch loss: 2.889997720718384\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7001  262 6826 5984 5353  818 3619 5091 6467 1160 5934 5966  722 6467 1337\n",
      " 4533 4078 2361 2222 6826 4737 2589  175 6957 2160 5707  208 6573 4780 5265\n",
      " 1141  290 3832    1    0    0    0    0    0    0    0]\n",
      "    enc input           > particular entities are not supposed to trade correct counterparty without a written assignment counterparty assignor and assignee suffice ? are issues with this late nom from the pipeline we will let you know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4495  408 4635 1908 5265 2374  208 5562 4533 3227 1728 2808  818  175 6826\n",
      " 4737 2589  175 6957 2160 5707  208 6573 4780 5265 1141  290 3832    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > excellent solution mark taylor will draft the agreements and aquila has agreed to this are issues with this late nom from the pipeline we will let you know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4495  408 4635 1908 5265 2374  208 5562  818 3227 1728 2808  818  175 6826\n",
      " 2160 2589  175 5483 2160 5707  208 6573 2222 5265 1141  290 3832    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > excellent solution mark taylor will draft the agreements to aquila has agreed to this are nom with this yesterday nom from the pipeline ? will let you know <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.444243493939\n",
      "0.0148094044946\n",
      "global_step: 2500\n",
      "learning rate 0.000824074\n",
      "epoch 21\n",
      "batch 0\n",
      "training minibatch loss: 3.089569091796875\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 308 5490  208 2057 4976 3887  325 2881 4533 2881  208 4652 1394  981 2881\n",
      " 1156 4374  763 1149  393 6826 6280 2040  724 5106 4880  755 6935 4533 1450\n",
      "  208 4257 4593 7007 3561 5902 2058    1]\n",
      "    enc input           > included in the information picked up friday for and for the ng price book for have confirms b c they are intra desk deals within enron nov dec and e the december management p l top page <EOS>\n",
      "    dec input           > [6818 6850 6434 2858 5505 5934 2146 2245 5490  208  981  755 6935 4533 1450\n",
      "  208 4257 4593 7007 3561 5902 2058    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > these were internal unwinds of a deal already in the book nov dec and e the december management p l top page <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6818 6850 6434 2858 5505  208 1394 5183 1654  208 5902  755 6935 4533 1450\n",
      "  208 5902 4593 7007 3561 5902 2058    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > these were internal unwinds of the price only on the top nov dec and e the top management p l top page <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.503474557598\n",
      "0.0\n",
      "global_step: 2619\n",
      "learning rate 0.000816519\n",
      "epoch 22\n",
      "batch 0\n",
      "training minibatch loss: 3.101874351501465\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3069 6261    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > possible thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 208 6108 6491 2610 4880 3837 3576   86    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > the hiring supervisor george enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 208 6108 6491 2610 4880 3837 3576   86    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > the hiring supervisor george enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.483854005609\n",
      "0.00873161764706\n",
      "global_step: 2738\n",
      "learning rate 0.000809033\n",
      "epoch 23\n",
      "batch 0\n",
      "training minibatch loss: 2.9889028072357178\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6179 2222 4149 4330    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > where ? just curious <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6762  439 3872 1460 6681 2222 6179 2222 4149 4330    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > case i someone ask me ? where ? just curious <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6762  439 1179 1460 6681 2222 6179 2222 4149 4330    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > case i ll ask me ? where ? just curious <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.51853683546\n",
      "0.00240384615385\n",
      "global_step: 2857\n",
      "learning rate 0.000801616\n",
      "epoch 24\n",
      "batch 0\n",
      "training minibatch loss: 2.6104979515075684\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5305  208 4990 2442 4281 2255 6140  212  262 2222 6122    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > made the changes myself ena s illinois project entities ? pseg <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 4149 2852 5934 6110 4168  439 1179 3495 6412  290 1156 1397 5687 2222\n",
      " 3832 5305  208 4990 2442 4281 2255 6140  212  262 2222 6122    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > i just noticed a glitch which i ll fix do you have any comments ? know made the changes myself ena s illinois project entities ? pseg <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 4149 2852 6806 6110 3044  439 1179 3495 6412  290 1156 1397 5687 2222\n",
      " 3832 2442  208 3044 2442 4281 2255 6140  212  262 2222 6122    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > i just noticed it glitch gas i ll fix do you have any comments ? know myself the gas myself ena s illinois project entities ? pseg <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532414146499\n",
      "0.00356177387427\n",
      "global_step: 2976\n",
      "learning rate 0.000794267\n",
      "epoch 25\n",
      "batch 0\n",
      "training minibatch loss: 2.618928909301758\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [2546 6497 5322 2688 5265 3249 6386 6806  818  290 4942  179 5036 6681 5934\n",
      " 3621  481 5505  208 3884 5882 4211 5250 7196 3499 4533  439 5265 5638  208\n",
      " 2057 1654  818 7111 4880 3447 3619 4536   86 3786 2222    1    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > my assistant taffy milligan will be sending it to you inc pls send me a electronic copy of the executed contract tks hi please advise and i will pass the information on to utilicorp enron capital trade resources corp isda ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5851 1654 4168 4880 5444 4780 5265 5781 2881  658 5490  208 5674 2222 6412\n",
      " 4780 1156 5934 1482 5681 2881 4887 3786 5562 2222    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > justin on which enron entity we will use for trading in the us ? do we have a clearing house for global isda agreements ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5851 1654 4168 4168 5444 4780 5265 5781 2881  658 5490  208 5674 2222 6412\n",
      " 4780 1156 5934 1482 5681 2881 4887 3786 5562 2222    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > justin on which which entity we will use for trading in the us ? do we have a clearing house for global isda agreements ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.697718335331\n",
      "0.0246356820183\n",
      "global_step: 3095\n",
      "learning rate 0.000786985\n",
      "epoch 26\n",
      "batch 0\n",
      "training minibatch loss: 2.356991767883301\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [ 439 1179 4243 1654 2418 6806 2881  290  439 2230 2388 5675  439 1156 3762\n",
      " 4588 1156 3762 4588 1141 6681 3832 4533  439 5265 4705  290 5139    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > i ll work on getting it for you i don t think i have edit capability have edit capability let me know and i will get you access <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5775 4742 5934 7226 5893 3287  279    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > question about a master all figured out <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5775 4742 5934 7226 5893 3287  279    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > question about a master all figured out <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.650434579919\n",
      "0.00298032407407\n",
      "global_step: 3214\n",
      "learning rate 0.00077977\n",
      "epoch 27\n",
      "batch 0\n",
      "training minibatch loss: 2.3632421493530273\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [1165  290  175 5856 1728 2274 3708  818 2365 1479 1989  439 4649 5984 2998\n",
      " 1010 2365 1384 6806   70  818 3870  857  208 1200 2222 3288 2255 2315 5994\n",
      " 6508 4259 5265 7073  208 5856 2132 2365    1    0    0    0    0    0]\n",
      "    enc input           > thank you this meeting has been changed to pm thursday october i am not available until pm is it possilble to push back the start ? mcconnell s office eb scott neal will join the meeting at pm <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196 3307 4533 2764  818 2546 6126  175 5856 1728 2274 3708  818 2365 1479\n",
      " 1989  439 4649 5984 2998 1010 2365 1384 6806   70  818 3870  857  208 1200\n",
      " 2222 3288 2255 2315 5994 6508 4259 5265 7073  208 5856 2132 2365    1    0\n",
      "    0    0    0]\n",
      "    dec input           > please note and add to my schedule this meeting has been changed to pm thursday october i am not available until pm is it possilble to push back the start ? mcconnell s office eb scott neal will join the meeting at pm <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196 3307 4533 2764  818 2546 6126  175 5856 1728 2274 3708  818 2365 1479\n",
      " 1989  439 4649 5984 2998 1010 2365 1384 6806   70  818 3870  857  208 1200\n",
      " 2222 3288 2255 2315 5994 6508 4259 5265 7073  208 5856 2132 2365    1    1\n",
      "    0    0    0    0]\n",
      "    dec train predicted > please note and add to my schedule this meeting has been changed to pm thursday october i am not available until pm is it possilble to push back the start ? mcconnell s office eb scott neal will join the meeting at pm <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "0.747700083247\n",
      "0.00311407342657\n",
      "global_step: 3333\n",
      "learning rate 0.000772621\n",
      "epoch 28\n",
      "batch 0\n",
      "training minibatch loss: 2.1110312938690186\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4149 5934  674 1930 1648 1116  818   48 5490  208 6289 2244 2637 1384 6603\n",
      " 7168 4880 1435 6736 4942    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > just a minute did he forget to put in the off peak or is fpl incorrect enron power marketing inc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 818  803 1360 5505 6806 2442 5075  439 2545 1930 1648 1116  818   48 5490\n",
      "  208 6289 2244 2637 1384 6603 7168 4880 1435 6736 4942    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > to take care of it myself if i can did he forget to put in the off peak or is fpl incorrect enron power marketing inc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 818  803 1360 5505 6806 2637 5075  439 1930 1930 1648 1116  818   48 5490\n",
      "  208 6289 2244 2637 1384 6603 7168 4880 1435 6736 4942    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > to take care of it or if i did did he forget to put in the off peak or is fpl incorrect enron power marketing inc <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.76489982785\n",
      "0.00501540186346\n",
      "global_step: 3452\n",
      "learning rate 0.000765537\n",
      "epoch 29\n",
      "batch 0\n",
      "training minibatch loss: 1.9768987894058228\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2826 6628  208 3619 4935 1654  175 2222 2126 4457 2146 2222 6289 2244 5239\n",
      " 2589 3193 6261    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > what was the trade date on this ? subject missing deal ? off peak hours with mike thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5984 6806 2255 5934 6583 3619 2126 6792 4457 2146 2222 2126 6792 4457 2146\n",
      " 2222 2826 6628  208 3619 4935 1654  175 2222 2126 4457 2146 2222 6289 2244\n",
      " 5239 2589 3193 6261    1    0    0    0    0]\n",
      "    dec input           > not it s a good trade subject re missing deal ? subject re missing deal ? what was the trade date on this ? subject missing deal ? off peak hours with mike thanks <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5984 6806 2255 5934 6583 3619 2126 6792 4457 2146 2222 2126 6792 4457 2146\n",
      " 2222 2126 6628  208 3619 3619 1654  175 2222 2126 4457 2146 2222 6289 2244\n",
      " 5239 2589 3193 6261    1    1    0    0    0    0]\n",
      "    dec train predicted > not it s a good trade subject re missing deal ? subject re missing deal ? subject was the trade trade on this ? subject missing deal ? off peak hours with mike thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792855242601\n",
      "0.0\n",
      "global_step: 3571\n",
      "learning rate 0.000758519\n",
      "epoch 30\n",
      "batch 0\n",
      "training minibatch loss: 2.213416814804077\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [5812  439 5632  471  175 2589 4635 4533 1648  136 2388 1156 1397 4683 2589\n",
      " 6806 4880 3837 3576   86 1716 6859 4484 6445 5562 4705  175 2883 3887 6261\n",
      " 3075    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > fyi i ve discussed this with mark and he didn t have any problem with it enron north america corp immediately land equipment option agreements get this set up thanks kay <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2589 1357 1582 1357 3069 2132 4941  818  208 2295 1397 3969 6742 2222 3706\n",
      " 1397 1651 1285  516  818 3249   34  818 1760  175 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > with as many as possible at once to the reports any other ideas ? does any formal documentation need to be prepared to accomplish this ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2589 1357 1582 1357 3069 2132 4941  818  208 2295 1397 6742 6742 2222 3706\n",
      " 1397 1651 1285 5265  818 3249   34  818 1760  175 2222    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > with as many as possible at once to the reports any ideas ideas ? does any formal documentation will to be prepared to accomplish this ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.852248859335\n",
      "0.0182151149934\n",
      "global_step: 3690\n",
      "learning rate 0.000751565\n",
      "epoch 31\n",
      "batch 0\n",
      "training minibatch loss: 1.9825737476348877\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6179 6412 4780  672 1654  175 2222 5250 4692 4533 5619  439 5265 2374 5934\n",
      " 3464 1061 4533 6983 3142  818  290  208 1953 4639 2139 5577 4880 4533 7092\n",
      " 1544 2881 2659 6659 4203  818  175 2508 5490  208 4567 5266 3577 5666 1435\n",
      " 5603 4942    1]\n",
      "    enc input           > where do we stand on this ? hi debra and macs i will draft a credit worksheet and forward same to you the original one used by enron and edited accordingly for enovate llc closure to this agreement in the very near future constellation power source inc <EOS>\n",
      "    dec input           > [5707 6890 2222 5250 4692 4533 5619  439 5265 2374 5934 3464 1061 4533 6983\n",
      " 3142  818  290  208 1953 4639 2139 5577 4880 4533 7092 1544 2881 2659 6659\n",
      " 4203  818  175 2508 5490  208 4567 5266 3577 5666 1435 5603 4942    1    0]\n",
      "    dec input           > from rudwell ? hi debra and macs i will draft a credit worksheet and forward same to you the original one used by enron and edited accordingly for enovate llc closure to this agreement in the very near future constellation power source inc <EOS> <PAD>\n",
      "    dec train predicted > [5707 6890 2222 5250 4692 4533 5619  439 5265 2374 5934 3464 1061 4533 6983\n",
      " 3142  818  290  208 1953 4639 2139 5577 4880 4533 7092 1544 2881 2659 6659\n",
      " 4203  818  175 2508 5490  208 4567 5266 3577 5666 1435 5603 4942    1    1\n",
      "    0]\n",
      "    dec train predicted > from rudwell ? hi debra and macs i will draft a credit worksheet and forward same to you the original one used by enron and edited accordingly for enovate llc closure to this agreement in the very near future constellation power source inc <EOS> <EOS> <PAD>\n",
      "0.847351934585\n",
      "0.00240384615385\n",
      "global_step: 3809\n",
      "learning rate 0.000744674\n",
      "epoch 32\n",
      "batch 0\n",
      "training minibatch loss: 1.9118081331253052\n",
      "  sample 1:\n",
      "    Index 26\n",
      "    enc input           > [ 439 4149 6257 6824 2881  208 5702    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i just added apb for the broker <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4635 2255 2400 2146  818 6824 1648 5762 6806 5490 2589 3825    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > mark s changing deal to apb he had it in with bloomberg <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4635 2255 2400 2146  818 6824 1648 5762 6806 5490 2589 3825    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > mark s changing deal to apb he had it in with bloomberg <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.819099390496\n",
      "0.00413572246816\n",
      "global_step: 3928\n",
      "learning rate 0.000737847\n",
      "epoch 33\n",
      "batch 0\n",
      "training minibatch loss: 1.7216895818710327\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [5651 2255 1974 4793  818 1047 4533 6036  639  818  208  364 3048  992 1654\n",
      " 3464 6463 4168 4780 6015 6412 5075 1597 6628 5934 1047 2246 4786 5655 3249\n",
      " 4922    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > gary s group due to tax and regulatory reasons to the overnight rate depending on credit brazil which we might do if there was a tax benefit that could be obtained <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2074  208 5107   34  813 6895 4780 5265 5036 6024  818  290 7139 6741 4533\n",
      "  439 5265 4782 1716 4801 4780 2545 1810 1654  818 3969  695 3069    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > finalizing the matrix prepared last year we will send them to you shortly comment and i will respond immediately then we can move on to other things possible <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2074  208 5107   34  813 6895 4780 5265 5036 6024  818  290 7139 6741 4533\n",
      "  439 5265 4782 1716 4801 4780 2545 1810 1654  818 3969  695 3069    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > finalizing the matrix prepared last year we will send them to you shortly comment and i will respond immediately then we can move on to other things possible <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.851238983517\n",
      "0.00368923611111\n",
      "global_step: 4047\n",
      "learning rate 0.000731083\n",
      "epoch 34\n",
      "batch 0\n",
      "training minibatch loss: 1.9265904426574707\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [6015 1156 2426 1165  290 2881 4526 6616    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > might have again thank you for your help <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2779 1654 4361  439 6015 1351  175 3291 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > suggestions on how i might tackle this issue ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2779 1654 4361  439 6015 1351  175 3291 2222    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > suggestions on how i might tackle this issue ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907202921029\n",
      "0.0\n",
      "global_step: 4166\n",
      "learning rate 0.00072438\n",
      "epoch 35\n",
      "batch 0\n",
      "training minibatch loss: 1.7496029138565063\n",
      "  sample 1:\n",
      "    Index 673\n",
      "    enc input           > [ 516 5483  722 5707 6475 2985 6681 5934   63 2132    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > need yesterday assignment from steve give me a call at <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4333 2840 2881 6681  818 4491  208 5856 2222  905 1654  208 6433 6107 5655\n",
      "  290 6156 2589  804  818 4705  208 1069 4533  851 4964 6415 2222    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > make sense for me to attend the meeting ? morning on the third jeff could you coordinate with rosie to get the time and place nailed down ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4333 2840 2881 6681  818 4491  208 5856 2222  905 1654  208 6433 6107 5655\n",
      "  290 6156 2589  804  818 4705  208 1069 4533  851 4964 6415 2222    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > make sense for me to attend the meeting ? morning on the third jeff could you coordinate with rosie to get the time and place nailed down ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.906388260432\n",
      "0.00327672735761\n",
      "global_step: 4285\n",
      "learning rate 0.000717739\n",
      "epoch 36\n",
      "batch 0\n",
      "training minibatch loss: 1.7249183654785156\n",
      "  sample 1:\n",
      "    Index 679\n",
      "    enc input           > [5253 6189 4361  703  439 1156 3723 3808 4645 6701 2258 4361  703 6412  290\n",
      " 6404 2222 1150 1069 1384 2915  279 4533 4780  516  290 1325 3662 1344 5718\n",
      " 3277 6811 2222 6261 2881 4526 1340  439 3665 6983  818 7070 5707  290 5915\n",
      "    1]\n",
      "    enc input           > no matter how much i have its never enough ok sherri how much do you want ? weekend time is running out and we need you consider helping him reach his goal ? thanks for your consideration i look forward to hearing from you tomorrow <EOS>\n",
      "    dec input           > [ 208 3588  313 6618 6981 2881 6681 6475  439 5675 4843 2245 5344  175 1069\n",
      "  818 5721 6261    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > the later hour works perfectly for me steve i think veronica already mentioned this time to debbie thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 208 3588  313 6618 6981 2881 6681 6475  439 5675 4843 2245 5344  175 1069\n",
      "  818 5721 6261    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > the later hour works perfectly for me steve i think veronica already mentioned this time to debbie thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.924924939191\n",
      "0.00358043224891\n",
      "global_step: 4404\n",
      "learning rate 0.000711159\n",
      "epoch 37\n",
      "batch 0\n",
      "training minibatch loss: 1.2328184843063354\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1397 5687 1654  208 1970 2483 1067 2929 6792  608 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > any comments on the attached control area memo re compliance ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 1179 1725 2426 2881 7184 2720 4533 1619    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > i ll ciculate again for final review and commentary <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 1179 1725 2426 2881 7184 2720 4533 1619    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > i ll ciculate again for final review and commentary <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.967324561404\n",
      "0.0129583942495\n",
      "global_step: 4523\n",
      "learning rate 0.000704639\n",
      "epoch 38\n",
      "batch 0\n",
      "training minibatch loss: 1.5088356733322144\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5295 6232 2222 6179 2255 4526 5209 6115 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "    enc input           > fir jan ? where s your curve now ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7010 1231 3946 1654 4786 2222 6179 2255 4526 5209 6115 2222    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > wan na wager on that ? where s your curve now ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7010 1231 3946 1654 4786 2222 6179 2255 4526 5209 6115 2222    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > wan na wager on that ? where s your curve now ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.961805555556\n",
      "0.0126756122425\n",
      "global_step: 4642\n",
      "learning rate 0.000698178\n",
      "epoch 39\n",
      "batch 0\n",
      "training minibatch loss: 1.3208603858947754\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7196 3499 4880 3837 3576   86    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > please advise enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196 3499 1582 6261 4880 3837 3576   86    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > please advise many thanks enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196 3499 1582 6261 4880 3837 3576   86    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > please advise many thanks enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972293177324\n",
      "0.00523897058824\n",
      "global_step: 4761\n",
      "learning rate 0.000691777\n",
      "epoch 40\n",
      "batch 0\n",
      "training minibatch loss: 1.1970974206924438\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5308 1597 1384  709 2881  208  289 4533  289  208 2040 5617  439 5655 5984\n",
      " 3249 5505 2088 4044 5075 4780 2230 2388 1156  818 3387 2589 6024    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > however there is nothing for the th and th the desk sorry i could not be of more assistance if we don t have to meet with them <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 516  818 1156  208  192  361 5577 3355 4593  208 2040 5617  439 5655 5984\n",
      " 3249 5505 2088 4044 5075 4780 2230 2388 1156  818 3387 2589 6024    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > need to have the volumes updated by volume management the desk sorry i could not be of more assistance if we don t have to meet with them <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 516  818 1156  208  192  361 5577 3355 4593  208 2040 5617  439 5655 5984\n",
      " 3249 5505  208 4044 5075 4780 2230 2388 1156  818 3387 2589 6024    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > need to have the volumes updated by volume management the desk sorry i could not be of the assistance if we don t have to meet with them <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.955958008899\n",
      "0.0109456578385\n",
      "global_step: 4880\n",
      "learning rate 0.000685435\n",
      "epoch 41\n",
      "batch 0\n",
      "training minibatch loss: 1.234014868736267\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2545  290 7196 4491 2222 5617 2881  208   57  595 2681 3701 1384 6799  818\n",
      " 3249 2905    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > can you please attend ? sorry for the inconvenience but david oxley is going to be traveling <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 1156 2389 1495  818 4491 5617 2881  208   57  595 2681 3701 1384 6799\n",
      "  818 3249 2905    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > i have asked stinson to attend sorry for the inconvenience but david oxley is going to be traveling <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 1156 2389 1495  818 4491 5617 2881  208   57  595 2681 3701 1384 6799\n",
      "  818 3249 2905    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > i have asked stinson to attend sorry for the inconvenience but david oxley is going to be traveling <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.880170306899\n",
      "0.0103046058362\n",
      "global_step: 4999\n",
      "learning rate 0.000679151\n",
      "epoch 42\n",
      "batch 0\n",
      "training minibatch loss: 1.1890519857406616\n",
      "  sample 1:\n",
      "    Index 24\n",
      "    enc input           > [6412  290 4170 4786 2222  208 1556 6160 5490  208 2705 1384 4829 4698    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > do you hear that ? the smallest violin in the world is playing tune <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3832  439 4649 1654 2546 4876  759 2222 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > know i am on my way right ? ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3832  439 4649 1654 2546 4876  759 2222 2222    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > know i am on my way right ? ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.995324337121\n",
      "0.00602678571429\n",
      "global_step: 5118\n",
      "learning rate 0.000672925\n",
      "epoch 43\n",
      "batch 0\n",
      "training minibatch loss: 1.0318307876586914\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [5265 6412 2418 6715 4533 3429 5365 5577  208 4226 5646 4533 3179 5934 3048\n",
      " 4875  259 5490 4673  818 7091  208 3291  552 1295 6305    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > will do getting nd and rd guessed by the commission considering and implementing a rate stabilization plan in q to address the issue sr admin asst <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4533 2826 3048 3146 6826 6595  818 1760 1570 5934 6878 2657  314 4780 5265\n",
      " 2985 5934 1963 2211 1654  208 3676   63 5441 5257 5265  803  175 3887 2132\n",
      " 2365  818 7091  208 3291  552 1295 6305    1    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > and what rate adjustments are necessary to accomplish such a result reasonable rates we will give a full report on the conference call scheduled below will take this up at pm to address the issue sr admin asst <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4533 2826 3048 3146 6826 6595  818 1760 1570 5934 6878 2657  314 4780 5265\n",
      " 2985 5934 1963 2211 1654  208 3676   63 5441 5257 5265  803  175 3887 2132\n",
      " 2365  818 7091  208 3291  552 1295 6305    1    1    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > and what rate adjustments are necessary to accomplish such a result reasonable rates we will give a full report on the conference call scheduled below will take this up at pm to address the issue sr admin asst <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.994501100002\n",
      "0.00867858270202\n",
      "global_step: 5237\n",
      "learning rate 0.000666755\n",
      "epoch 44\n",
      "batch 0\n",
      "training minibatch loss: 0.907383918762207\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1970 1384 2546 5791 3217 1061 2881 1989 1654  208 2623 2959 2146    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > attached is my demand charge worksheet for october on the big citygate deal <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5724  290 6826 6289  208 1528 1970 1384 2546 5791 3217 1061 2881 1989 1654\n",
      "  208 2623 2959 2146    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > alfonso you are off the hook attached is my demand charge worksheet for october on the big citygate deal <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5724  290 6826 6289  208 1528 1970 1384 2546 5791 3217 1061 2881 1989 1654\n",
      "  208 2623 2959 2146    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > alfonso you are off the hook attached is my demand charge worksheet for october on the big citygate deal <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989583333333\n",
      "0.0173290598291\n",
      "global_step: 5356\n",
      "learning rate 0.000660642\n",
      "epoch 45\n",
      "batch 0\n",
      "training minibatch loss: 0.9765597581863403\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1384 5934 4580 3692  212    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > is a long term project <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196 6983  818  208 4393    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > please forward to the traders <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196 6983  818  208 4393    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > please forward to the traders <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.988085686778\n",
      "0.00799314967598\n",
      "global_step: 5475\n",
      "learning rate 0.000654585\n",
      "epoch 46\n",
      "batch 0\n",
      "training minibatch loss: 0.7218260765075684\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3721 6480 3084 5075  393 4472 1821  533 2653 2881 4880 1397 4737  439 2006\n",
      " 5693 2222    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > market affiliate rules if they apply here drew saving for enron any issues i m overlooking ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1923  439 2230 2388 1156 2546 4880  623 1654 3721 6480 3084 5075  393 4472\n",
      " 1821  533 2653 2881 4880 1397 4737  439 2006 5693 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > maybe i don t have my enron hat on market affiliate rules if they apply here drew saving for enron any issues i m overlooking ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1923  439 2230 2388 1156 2546 4880  623 1654 3721 6480 3084 5075  393 4472\n",
      " 1821  533 2653 2881 4880 1397 4737  439 2006 5693 2222    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > maybe i don t have my enron hat on market affiliate rules if they apply here drew saving for enron any issues i m overlooking ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.955655364372\n",
      "0.00240384615385\n",
      "global_step: 5594\n",
      "learning rate 0.000648584\n",
      "epoch 47\n",
      "batch 0\n",
      "training minibatch loss: 0.7959429621696472\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2637 5075 1597 6826 3033 4745 2998    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > or if there are tickets still available <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5471 2255  596 4533 4361 1582 4561 6826 4780 3112 2222  987  208 2387    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > who s driving and how many cars are we taking ? into the room <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5471 2255  596 4533 4361 1582 4561 6826 4780 3112 2222  987  208 2387    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > who s driving and how many cars are we taking ? into the room <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.952910539216\n",
      "0.00274417562724\n",
      "global_step: 5713\n",
      "learning rate 0.000642638\n",
      "epoch 48\n",
      "batch 0\n",
      "training minibatch loss: 0.6856511831283569\n",
      "  sample 1:\n",
      "    Index 7\n",
      "    enc input           > [3193 4428 4149 4739  279 2589 5702 5183 4639 2146 3708    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > mike swerzbin just checked out with broker only one deal changed <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1156 3997 2274 3708  818 4624 2881 5702 5702 1537  208 6585  971 6826 5984\n",
      "  862    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > have both been changed to tradition for broker broker says the above trades are not theres <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1156 3997 2274 3708  818 4624 2881 5702 5702 1537  208 6585  971 6826 5984\n",
      "  862    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > have both been changed to tradition for broker broker says the above trades are not theres <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.970473057644\n",
      "0.0109872766123\n",
      "global_step: 5832\n",
      "learning rate 0.000636746\n",
      "epoch 49\n",
      "batch 0\n",
      "training minibatch loss: 0.7520343065261841\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4394 2589 5893  208 6402  279 1597    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > well with all the craziness out there <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1597 5490  291 4030 2222 1384 1935 6799 2222 4880 3447 3619 4536   86 5856\n",
      "  208 3899 1384 4415 2998 1654 2060 2255 4980 2132 7065    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > there in person thoughts ? is anyone going ? enron capital trade resources corp meeting the notice is also available on ferc s website at wwwfercfedus <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1597 5490  291 4030 2222 1384 1935 6799 2222 4880 3447 3619 4536   86 5856\n",
      "  208 3899 1384 4415 2998 1654 2060 2255 4980 2132 7065    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > there in person thoughts ? is anyone going ? enron capital trade resources corp meeting the notice is also available on ferc s website at wwwfercfedus <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947222222222\n",
      "0.00807291666667\n",
      "global_step: 5951\n",
      "learning rate 0.000630909\n",
      "epoch 50\n",
      "batch 0\n",
      "training minibatch loss: 0.6703788638114929\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [5438 1821 1384  208 3929 2374    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > elizabeth here is the revised draft <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4622 1728  208 4017 4533 7091 5505 2207 5984 2634 5490 4931 5490 4786 2615\n",
      " 4027  818 3409 5878 5281 7136    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > secretary has the name and address of ike not admissible in evidence in that litigation pursuant to fed r civ evid <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4622 1728  208 4017 4533 7091 5505 2207 5984 2634 5490 4931 5490 4786 2615\n",
      " 4027  818 3409 5878 5281 7136    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > secretary has the name and address of ike not admissible in evidence in that litigation pursuant to fed r civ evid <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.962355324074\n",
      "0.0143494743104\n",
      "global_step: 6070\n",
      "learning rate 0.000625124\n",
      "epoch 51\n",
      "batch 0\n",
      "training minibatch loss: 0.5528444051742554\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [7045 7196 2720 4533 6151 7045 1264  818 3358    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    enc input           > barry please review and contact barry directly to discuss <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 175 2222 2826 1384  208 1529 2222 2126  307 4837 2364 4880 3837 3576   86\n",
      " 2126  307 4837 2364 2126  307 4837 2364 7045 7196 2720 4533 6151 7045 1264\n",
      "  818 3358    1    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > this ? what is the status ? subject spread value calc enron north america corp subject spread value calc subject spread value calc barry please review and contact barry directly to discuss <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 175 2222 2826 1384  208 1529 2222 2126  307 4837 2364 4880 3837 3576   86\n",
      " 2126  307 4837 2364 2126  307 4837 2364 7045 7196 2720 4533 6151 7045 1264\n",
      "  818 3358    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > this ? what is the status ? subject spread value calc enron north america corp subject spread value calc subject spread value calc barry please review and contact barry directly to discuss <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.995052083333\n",
      "0.003125\n",
      "global_step: 6189\n",
      "learning rate 0.000619393\n",
      "epoch 52\n",
      "batch 0\n",
      "training minibatch loss: 0.6166160702705383\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 823 2508 4134  875  208 1944 2374  850    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > indemnification agreement marked against the prior draft distributed <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4134  875  208 4828 2373 2579    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > marked against the most recent drafts <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4134  875  208 4828 2373 2579    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > marked against the most recent drafts <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.97446904872\n",
      "0.00203804347826\n",
      "global_step: 6308\n",
      "learning rate 0.000613715\n",
      "epoch 53\n",
      "batch 0\n",
      "training minibatch loss: 0.5195707082748413\n",
      "  sample 1:\n",
      "    Index 549\n",
      "    enc input           > [6681 2222 2222    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > me ? ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6359 4402 6826 2407 2589 4880 1654  208  658 6996  439 1179 3266  290 6371\n",
      "  439 2230 2388 6404  818 1741 4526 4017 7220  439 4170 5505 3234 3266 6681\n",
      " 5490 3782 2881 3234 3887 1597 6057    1    0    0    0    0    0    0    0]\n",
      "    dec input           > hpl people are staying with enron on the trading side i ll keep you posted i don t want to mention your name unless i hear of something keep me in mind for something up there buddy <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6359 4402 6826 2407 2589 4880 1654  208  658 6996  439 1179 3266  290 6371\n",
      "  439 2230 2388 6404  818 1741 4526 4017 7220  439 4170 5505 3234 3266 6681\n",
      " 5490 3782 2881 3234 3887 1597 6057    1    1    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > hpl people are staying with enron on the trading side i ll keep you posted i don t want to mention your name unless i hear of something keep me in mind for something up there buddy <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.980218705548\n",
      "0.00470976209463\n",
      "global_step: 6427\n",
      "learning rate 0.000608088\n",
      "epoch 54\n",
      "batch 0\n",
      "training minibatch loss: 0.48271942138671875\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2126 1156 4780 2732 4690 5490  208  759 6784 2222 4294   63 6681 2132 3350\n",
      " 1384  290 1156 1397 2228    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > subject have we got employees in the right company ? structured call me at ext is you have any questions <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 2126 1156 4780 2732 4690 5490  208  759 6784 2222 6362\n",
      " 5257 2881 5934  284 4288 1654  208 5856 5707  742 6355 4294    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > enron north america corp subject have we got employees in the right company ? see below for a brief description on the meeting from felecia acevedo structured <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 2126 1156 4780 2732 4690 5490  208  759 6784 2222 6362\n",
      " 5257 2881 5934  284 4288 1654  208 5856 5707  742 6355 4294    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > enron north america corp subject have we got employees in the right company ? see below for a brief description on the meeting from felecia acevedo structured <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00737847222222\n",
      "global_step: 6546\n",
      "learning rate 0.000602513\n",
      "epoch 55\n",
      "batch 0\n",
      "training minibatch loss: 0.42794519662857056\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1221 4533 4371 3249  130 2589 4028 4737  386 6261 5490 2546 3400  818 1356\n",
      "  844 3432  175 5198    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > facilities and would be helpful with background issues involved thanks in my responding to emails sent during this period <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5812 7196 2764  818  208 4831 4136 4786  290 5265 3249  537 1427    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > fyi please add to the distribution list that you will be circulating regards <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5812 7196 2764  818  208 4831 4136 4786  290 5265 3249  537 1427    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > fyi please add to the distribution list that you will be circulating regards <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.9875\n",
      "0.0101667429792\n",
      "global_step: 6665\n",
      "learning rate 0.000596989\n",
      "epoch 56\n",
      "batch 0\n",
      "training minibatch loss: 0.3856368958950043\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5313 7097  492 1397 4725 2222 5934   63 2589 1397 2228 7196 6362 1970    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > financial pulp paper any problems ? a call with any questions please see attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 2881  208  339 4880 7230   86 6551 2223 2897  925 5313 7097  492 1397\n",
      " 4725 2222 5934   63 2589 1397 2228 7196 6362 1970    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks for the info enron japan corp otemachi st square bldg financial pulp paper any problems ? a call with any questions please see attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 2881  208  339 4880 7230   86 6551 2223 2897  925 5313 7097  492 1397\n",
      " 4725 2222 5934   63 2589 1397 2228 7196 6362 1970    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > thanks for the info enron japan corp otemachi st square bldg financial pulp paper any problems ? a call with any questions please see attached <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00679754273504\n",
      "global_step: 6784\n",
      "learning rate 0.000591516\n",
      "epoch 57\n",
      "batch 0\n",
      "training minibatch loss: 0.4311221241950989\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 1179 1141  290 3832 6818 1650    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > i ll let you know these discrepancies <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 542 5984 1595  439 1179 1141  290 3832 6818 1650    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > morgan not merrill i ll let you know these discrepancies <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 542 5984 1595  439 1179 1141  290 3832 6818 1650    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > morgan not merrill i ll let you know these discrepancies <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00261801861702\n",
      "global_step: 6903\n",
      "learning rate 0.000586093\n",
      "epoch 58\n",
      "batch 0\n",
      "training minibatch loss: 0.36061719059944153\n",
      "  sample 1:\n",
      "    Index 67\n",
      "    enc input           > [6826  290 3470 5915 2637 1388 2222 4880 3837 3576   86    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > are you free tomorrow or fri ? enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6806 1384 6583 2881 6681 4880 3837 3576   86    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > it is good for me enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6806 1384 6583 2881 6681 4880 3837 3576   86    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > it is good for me enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.98502654635\n",
      "0.00078125\n",
      "global_step: 7022\n",
      "learning rate 0.000580719\n",
      "epoch 59\n",
      "batch 0\n",
      "training minibatch loss: 0.3458271026611328\n",
      "  sample 1:\n",
      "    Index 693\n",
      "    enc input           > [2545  439 1450 5564  290  208 2374 2222 4880 3837 3576   86    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > can i e mail you the draft ? enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2287 4696 4780 5632 2245  844 2110 7005    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > per kevin we ve already sent our requests <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2287 4696 4780 5632 2245  844 2110 7005    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > per kevin we ve already sent our requests <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957910730258\n",
      "0.00520085009579\n",
      "global_step: 7141\n",
      "learning rate 0.000575395\n",
      "epoch 60\n",
      "batch 0\n",
      "training minibatch loss: 0.3061274588108063\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4780 1156 6973 5505 3786 2255 5490  851 2589 4811 2150 5471 2222 3150 6412\n",
      " 4780 1156 1397 5914 5490  851 2589 2150 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > we have lots of isda s in place with southerns southern who ? tana do we have any isdas in place with southern ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1234 2637  587 6806 2589 5934 4067 2508 4780 1156 6973 5505 3786 2255 5490\n",
      "  851 2589 4811 2150 5471 2222 3150 6412 4780 1156 1397 5914 5490  851 2589\n",
      " 2150 2222    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > confirmation or replacing it with a multicurrency agreement we have lots of isda s in place with southerns southern who ? tana do we have any isdas in place with southern ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1234 2637  587 6806 2589 5934 4067 2508 4780 1156 6973 5505 3786 2255 5490\n",
      "  851 2589 4811 2150 5471 2222 3150 6412 4780 1156 1397 5914 5490  851 2589\n",
      " 2150 2222    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > confirmation or replacing it with a multicurrency agreement we have lots of isda s in place with southerns southern who ? tana do we have any isdas in place with southern ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00597319347319\n",
      "global_step: 7260\n",
      "learning rate 0.00057012\n",
      "epoch 61\n",
      "batch 0\n",
      "training minibatch loss: 0.2812386155128479\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5707  208 3211 6996  595  208 3591 4399 3249 5091 2881 4237 7196 5590 4526\n",
      " 5687 4533  439 1179 4333  836  393 4705  308 1412    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > from the wholesale side but the titles should be correct for enw please provide your comments and i ll make sure they get included correctly <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4533 2764 4786 1357 4394 3306 1821    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > and add that as well authorship here <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4533 2764 4786 1357 4394 3306 1821    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > and add that as well authorship here <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00852272727273\n",
      "global_step: 7379\n",
      "learning rate 0.000564893\n",
      "epoch 62\n",
      "batch 0\n",
      "training minibatch loss: 0.268874853849411\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3297 3665 6983  818 3102  290 5490 5664 5075  439 2545 6616 5490 4526  443\n",
      " 7196   63 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > congratulations look forward to seeing you in houston if i can help in your transition please call relocate to houston and report to me in his new role <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3297 4533 5563 4519 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > congratulations and best wishes relocate to houston and report to me in his new role <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3297 4533 5563 4519 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > congratulations and best wishes relocate to houston and report to me in his new role <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00730519480519\n",
      "global_step: 7498\n",
      "learning rate 0.000559714\n",
      "epoch 63\n",
      "batch 0\n",
      "training minibatch loss: 0.2732155919075012\n",
      "  sample 1:\n",
      "    Index 6\n",
      "    enc input           > [ 439  516  818 3832 2826  132 1819  290 6826  658 2222  439 6412 1156 5934\n",
      "  132  658  912 4880 3837 3576   86 1349  291 4027  818 4915 2637 4749 2508\n",
      " 6480  912  175 2578    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > i need to know what futures products you are trading ? i do have a futures trading account enron north america corp another person pursuant to express or implied agreement affiliate account this request <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4533 4635 1908 4602 4533 6497 5328  172 5505  658 1415 1384 4742 2545 2179\n",
      " 6616 6681 2222 4880 3447 3619 4536   86 1349  291 4027  818 4915 2637 4749\n",
      " 2508 6480  912  175 2578    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > and mark taylor vp and assistant general counsel of trading message is about can u help me ? enron capital trade resources corp another person pursuant to express or implied agreement affiliate account this request <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4533 4635 1908 4602 4533 6497 5328  172 5505  658 1415 1384 4742 2545 2179\n",
      " 6616 6681 2222 4880 3447 3619 4536   86 1349  291 4027  818 4915 2637 4749\n",
      " 2508 6480  912  175 2578    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > and mark taylor vp and assistant general counsel of trading message is about can u help me ? enron capital trade resources corp another person pursuant to express or implied agreement affiliate account this request <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.000868055555556\n",
      "global_step: 7617\n",
      "learning rate 0.000554583\n",
      "epoch 64\n",
      "batch 0\n",
      "training minibatch loss: 0.3221070468425751\n",
      "  sample 1:\n",
      "    Index 132\n",
      "    enc input           > [ 439 2006  318  175 1654  818 4635 1908 2881 2720 3694 2508  818  803 2110\n",
      " 2199  818  208 3421 3450 5505 4253 5075  290 1156 1397 2228 7196   63 6681\n",
      " 2132 5514    1    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i m passing this on to mark taylor for review nondisclosure agreement to take our discussions to the next level of detail if you have any questions please call me at x <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1384 4786 3174 2637  248 2222    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > is that hugs or kisses ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1384 4786 3174 2637  248 2222    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > is that hugs or kisses ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795198444112\n",
      "0.00173611111111\n",
      "global_step: 7736\n",
      "learning rate 0.000549498\n",
      "epoch 65\n",
      "batch 0\n",
      "training minibatch loss: 0.2953128218650818\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 724 6610 3816 1384 5183 3392 6024  818 4639  922    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > deals everyday eol is only booking them to one leg <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2642 5091  818 6681 3573    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > looks correct to me dawnie <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2642 5091  818 6681 3573    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > looks correct to me dawnie <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.696728919162\n",
      "0.00332633053221\n",
      "global_step: 7855\n",
      "learning rate 0.000544461\n",
      "epoch 66\n",
      "batch 0\n",
      "training minibatch loss: 0.21989545226097107\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [ 626  818 3329  175  595 6806 6015 3249 5934  674 5496 3887 4533 6806 1384\n",
      " 2915 5239 5934 1557 6261    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > try to change this but it might be a minute doubled up and it is running hours a day thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3692 4533 3355 6115 5496 3887 4533 6806 1384 2915 5239 5934 1557 6261    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > term and volume now doubled up and it is running hours a day thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3692 4533 3355 6115 5496 3887 4533 6806 1384 2915 5239 5934 1557 6261    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > term and volume now doubled up and it is running hours a day thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00191735347985\n",
      "global_step: 7974\n",
      "learning rate 0.000539469\n",
      "epoch 67\n",
      "batch 0\n",
      "training minibatch loss: 0.22986525297164917\n",
      "  sample 1:\n",
      "    Index 33\n",
      "    enc input           > [5893 6107 4524  971 4399 1156 5091 4695 1894 6115    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > all jeff richter trades should have correct total mw now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6164 1537 3997 5505 6818 7027 6826 5091 1384 5702 4745  402 6024 2222 6261\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > chris says both of these prices are correct is broker still disputing them ? thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6164 1537 3997 5505 6818 7027 6826 5091 1384 5702 4745  402 6024 2222 6261\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > chris says both of these prices are correct is broker still disputing them ? thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.9725\n",
      "0.00943813131313\n",
      "global_step: 8093\n",
      "learning rate 0.000534523\n",
      "epoch 68\n",
      "batch 0\n",
      "training minibatch loss: 0.18839684128761292\n",
      "  sample 1:\n",
      "    Index 143\n",
      "    enc input           > [6826  290 1683 2222 4880 3837 3576   86  748 1384 2418 5934 4442 1552 4742\n",
      " 4667    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > are you irritated ? enron north america corp thing is getting a little ridiculous about mine <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261  439 1156  290 5441 7196 3365 6681 2881 5934 4538 1654 2132 5265 3249\n",
      " 4761 3432 6818 3245 5239 3238 5505 2981 4533 2917 2132 6376 1989 4152  265\n",
      " 2611 2881 3771  175  253    1]\n",
      "    dec input           > thanks i have you scheduled please register me for a session on at will be reviewed during these two hours sessions of september and end at mid october recruiting teams given for attending this workshop <EOS>\n",
      "    dec train predicted > [6261  439 1156  290 5441 7196 3365 6681 2881 5934 4538 1654 2132 5265 3249\n",
      " 4761 3432 6818 3245 5239 3238 5505 2981 4533 2917 2132 6376 1989 4152  265\n",
      " 2611 2881 3771  175  253    1    1]\n",
      "    dec train predicted > thanks i have you scheduled please register me for a session on at will be reviewed during these two hours sessions of september and end at mid october recruiting teams given for attending this workshop <EOS> <EOS>\n",
      "1.0\n",
      "0.0163778623337\n",
      "global_step: 8212\n",
      "learning rate 0.000529623\n",
      "epoch 69\n",
      "batch 0\n",
      "training minibatch loss: 0.17482773959636688\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4880 3837 3576   86 1397 6770  290 1179 1156 1069  818 2720 6681 2222    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp any chance you ll have time to review me ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2589 2834 5655  292 1694 2546 4982 5125 4371 4786 3249 6042 2222    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > with pleasure could contribute towards my prc evaluation would that be okay ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2589 2834 5655  292 1694 2546 4982 5125 4371 4786 3249 6042 2222    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > with pleasure could contribute towards my prc evaluation would that be okay ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999335106383\n",
      "0.0081164950714\n",
      "global_step: 8331\n",
      "learning rate 0.000524767\n",
      "epoch 70\n",
      "batch 0\n",
      "training minibatch loss: 0.16737984120845795\n",
      "  sample 1:\n",
      "    Index 672\n",
      "    enc input           > [6261 6475  439 1179 6156 2589  804  905 1654  208 6433 6107 5655  290 6156\n",
      " 2589  804  818 4705  208 1069 4533  851 4964 6415 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > thanks steve i ll coordinate with rosie morning on the third jeff could you coordinate with rosie to get the time and place nailed down ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 516 5483  722 5707 6475 2985 6681 5934   63 2132    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > need yesterday assignment from steve give me a call at <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 516 5483  722 5707 6475 2985 6681 5934   63 2132    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > need yesterday assignment from steve give me a call at <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0157310520362\n",
      "global_step: 8450\n",
      "learning rate 0.000519956\n",
      "epoch 71\n",
      "batch 0\n",
      "training minibatch loss: 0.15219829976558685\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 4649 5984 5934 2623 2932  203 5389 4371 3249 5563 3832 2826  290 5675\n",
      " 4742 6818 3737 6261    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i am not a big soussan fan zimmerman would be best know what you think about these three thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5427 1210 1384 6068 2651 4533  439 3832  413  559 4394 5675 2222    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > yes she is ex bracewell and i know her pretty well think ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5427 1210 1384 6068 2651 4533  439 3832  413  559 4394 5675 2222    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > yes she is ex bracewell and i know her pretty well think ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00744047619048\n",
      "global_step: 8569\n",
      "learning rate 0.000515189\n",
      "epoch 72\n",
      "batch 0\n",
      "training minibatch loss: 0.1585690826177597\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 479 5934 5004 2508 5490  208 5266 3577 2222  175 2589 2106 4533 4780 5265\n",
      " 3499 1361 2255 5505  985 5623  208 4248 4533 1292  208  214 1832 2589 1349\n",
      "  277  884  393 4705  985 2644 6361 4786 1384  208 4828 7019  931    1]\n",
      "    enc input           > contemplating a binding agreement in the near future ? this with carlos and we will advise k s of their role the spa and transferring the member interests with another buyer before they get their act together that is the most efficient approach <EOS>\n",
      "    dec input           > [6873  585 2388 4780 1212  175 4505  208 1186 4738 2508 2222  208 4248 4533\n",
      " 1292  208  214 1832 2589 1349  277  884  393 4705  985 2644 6361 4786 1384\n",
      "  208 4828 7019  931    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > why wouldn t we structure this like the aes calvert agreement ? the spa and transferring the member interests with another buyer before they get their act together that is the most efficient approach <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6873  585 2388 4780 1212  175 4505  208 1186 4738 2508 2222  208 4248 4533\n",
      " 1292  208  214 1832 2589 1349  277  884  393 4705  985 2644 6361 4786 1384\n",
      "  208 4828 7019  931    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > why wouldn t we structure this like the aes calvert agreement ? the spa and transferring the member interests with another buyer before they get their act together that is the most efficient approach <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.960459183673\n",
      "0.00619334795322\n",
      "global_step: 8688\n",
      "learning rate 0.000510466\n",
      "epoch 73\n",
      "batch 0\n",
      "training minibatch loss: 0.14497819542884827\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7214 4533 4602 2255 4786 6826 4665 2881 5834 4526 6907 4058 4371 3249 4647\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > directors and vp s that are eligible for bonus your prompt response would be appreciated <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7214 4533 4602 2255 4786 6826 4665 2881 5834  818  175  592 4533 4297  175\n",
      " 2057 4526 6907 4058 4371 3249 4647    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > directors and vp s that are eligible for bonus to this email and confirm this information your prompt response would be appreciated <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7214 4533 4602 2255 4786 6826 4665 2881 5834  818  175  592 4533 4297  175\n",
      " 2057 4526 6907 4058 4371 3249 4647    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > directors and vp s that are eligible for bonus to this email and confirm this information your prompt response would be appreciated <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0118348665224\n",
      "global_step: 8807\n",
      "learning rate 0.000505786\n",
      "epoch 74\n",
      "batch 0\n",
      "training minibatch loss: 0.119642473757267\n",
      "  sample 1:\n",
      "    Index 340\n",
      "    enc input           > [4361 1930  208 7109 1810 4243 2222    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > how did the pattened move work ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1384 2973 4780 2545 6412    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > is anything we can do <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1384 2973 4780 2545 6412    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > is anything we can do <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989914849974\n",
      "0.0106671824344\n",
      "global_step: 8926\n",
      "learning rate 0.000501148\n",
      "epoch 75\n",
      "batch 0\n",
      "training minibatch loss: 0.12523847818374634\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [2826 6850  208 5686 3034 1654  208 5124 4786  290  844  818 6681 2222 1667\n",
      " 5490 3431  912 2589 6024  208  912 1384 7151 2132  175 1069 1141 2255 2720\n",
      " 2110 3421  373 5190  290 1156 3431 4249    1    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > what were the dollar amounts on the printout that you sent to me ? sitting in an account with them the account is inactive at this time let s review our next step when you have an opportunity <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1621  208 6295 4771  595 5265 1460    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > received the replacements yet but will ask <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1621  208 6295 4771  595 5265 1460    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > received the replacements yet but will ask <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.979166666667\n",
      "0.0106192162552\n",
      "global_step: 9045\n",
      "learning rate 0.000496554\n",
      "epoch 76\n",
      "batch 0\n",
      "training minibatch loss: 0.1185566708445549\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1397 6742 2222 4371 4505 6681  818 6151 1397 3969  163 4149 1141 6681 3832\n",
      " 1156 5934 6985 1150    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > any ideas ? would like me to contact any other hopefuls just let me know have a wonderful weekend <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1397 1327 2222 4297 3544  290    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > any recruits ? confirm reservations you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1397 1327 2222 4297 3544  290    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > any recruits ? confirm reservations you <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0161931803794\n",
      "global_step: 9164\n",
      "learning rate 0.000492001\n",
      "epoch 77\n",
      "batch 0\n",
      "training minibatch loss: 0.10892707854509354\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3142 2058 5490 2110 1394  818  932 5882 2589  208 3969 5814 6799  818 6650\n",
      " 5801  530    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > same page in our price to delta contract with the other units going to ca w intergen <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6908 4505 3997  516  818 1931 6404  818 2219  371 1654 4786 3291 6485 6024\n",
      " 2881 5893  208 1882 2132 1190 5882 2589  208 3969 5814 6799  818 6650 5801\n",
      "  530    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > sounds like both need to stabilizers want to stay silent on that issue obtaining them for all the generators at lvcii contract with the other units going to ca w intergen <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6908 4505 3997  516  818 1931 6404  818 2219  371 1654 4786 3291 6485 6024\n",
      " 2881 5893  208 1882 2132 1190 5882 2589  208 3969 5814 6799  818 6650 5801\n",
      "  530    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > sounds like both need to stabilizers want to stay silent on that issue obtaining them for all the generators at lvcii contract with the other units going to ca w intergen <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.987967013871\n",
      "0.00152529761905\n",
      "global_step: 9283\n",
      "learning rate 0.000487491\n",
      "epoch 78\n",
      "batch 0\n",
      "training minibatch loss: 0.11427430808544159\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5893 5505  208 5149 1654  175 4136 6826 6701 2881 5313    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > all of the counterparties on this list are ok for financial <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2545  290 2769 6024 6415 6261 5893 5505  208 5149 1654  175 4136 6826 6701\n",
      " 2881 5313    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > can you shut them down thanks all of the counterparties on this list are ok for financial <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2545  290 2769 6024 6415 6261 5893 5505  208 5149 1654  175 4136 6826 6701\n",
      " 2881 5313    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > can you shut them down thanks all of the counterparties on this list are ok for financial <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00739690320573\n",
      "global_step: 9402\n",
      "learning rate 0.000483021\n",
      "epoch 79\n",
      "batch 0\n",
      "training minibatch loss: 0.10696063935756683\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4763 5490 6762  290  516 6450 2255 4083  439 4649 6422 6806 2881 4526 5781\n",
      " 4081 5490 4673 4120 4191 5313 1094    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > michael in case you need ken s bio i am attaching it for your use close in q summary outside financial analysis <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4763  439 5675  500 5265 3249 4987 4895 5265 2058 6681 5490  208 3521  818\n",
      " 4333 2697 1390 4763 5490 6762  290  516 6450 2255 4083  439 4649 6422 6806\n",
      " 2881 4526 5781 4081 5490 4673 4120 4191 5313 1094    1    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > michael i think monday will be fine lety will page me in the field to make alternative arrangements michael in case you need ken s bio i am attaching it for your use close in q summary outside financial analysis <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4763  439 5675  500 5265 3249 4987 4895 5265 2058 6681 5490  208 3521  818\n",
      " 4333 2697 1390 4763 5490 6762  290  516 6450 2255 4083  439 4649 6422 6806\n",
      " 2881 4526 5781 4081 5490 4673 4120 4191 5313 1094    1    1    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > michael i think monday will be fine lety will page me in the field to make alternative arrangements michael in case you need ken s bio i am attaching it for your use close in q summary outside financial analysis <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996717087766\n",
      "0.0101823922136\n",
      "global_step: 9521\n",
      "learning rate 0.000478593\n",
      "epoch 80\n",
      "batch 0\n",
      "training minibatch loss: 0.10372764617204666\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5250  290  592 6806  818 6681 2222    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > hi you email it to me ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3872 4871 6806  818 6681 2222  439 1179  592 2546 4871 6460  818  290 5250\n",
      "  290  592 6806  818 6681 2222    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > someone fax it to me ? i ll email my fax number to you hi you email it to me ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3872 4871 6806  818 6681 2222  439 1179  592 2546 4871 6460  818  290 5250\n",
      "  290  592 6806  818 6681 2222    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > someone fax it to me ? i ll email my fax number to you hi you email it to me ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.966836734694\n",
      "0.0130519347891\n",
      "global_step: 9640\n",
      "learning rate 0.000474205\n",
      "epoch 81\n",
      "batch 0\n",
      "training minibatch loss: 0.09755955636501312\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5123  818 4851  413 3455 4149 1141 6681 3832    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > happy to include her too just let me know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 2006 6246 3699 1357 4780 5679    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > i m calling marcie as we speak <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 2006 6246 3699 1357 4780 5679    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > i m calling marcie as we speak <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.982316790353\n",
      "0.00925245098039\n",
      "global_step: 9759\n",
      "learning rate 0.000469858\n",
      "epoch 82\n",
      "batch 0\n",
      "training minibatch loss: 0.08990949392318726\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [1821 1384  208 4900 5882  290 1975 5490 4526  592 3334  208 1354 6291 4533\n",
      " 3285 5505 2884 3168 4880 3837 3576   86 6826 3614 1654    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > here is the abb contract you referenced in your email environment the balance sheet and worthy of further discussion enron north america corp are working on <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2593 3995 4880 3837 3576   86 6826 3614 1654    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > ta da enron north america corp are working on <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2593 3995 4880 3837 3576   86 6826 3614 1654    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > ta da enron north america corp are working on <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.998697916667\n",
      "0.0073474702381\n",
      "global_step: 9878\n",
      "learning rate 0.00046555\n",
      "epoch 83\n",
      "batch 0\n",
      "training minibatch loss: 0.08710822463035583\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3832 4526 4030 5265 3606 3249 4331 5183 1331  439 5036  290 5934 6336 5505\n",
      "  208 2939 4533 3723 4288 2881 3816  439 5675 4786 4780 4399 6126 5934 1069\n",
      " 5911 4786 4780 2545 3358  208 2939    1    0    0    0    0    0    0]\n",
      "    enc input           > know your thoughts will initially be traded only internally i send you a presentation of the product and its description for eol i think that we should schedule a time so that we can discuss the product <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6989 2881 3421 5079  818 3387 4742  175 5265 3606 3249 4331 5183 1331  439\n",
      " 5036  290 5934 6336 5505  208 2939 4533 3723 4288 2881 3816  439 5675 4786\n",
      " 4780 4399 6126 5934 1069 5911 4786 4780 2545 3358  208 2939    1    0    0\n",
      "    0    0    0]\n",
      "    dec input           > hansen for next wednesday to meet about this will initially be traded only internally i send you a presentation of the product and its description for eol i think that we should schedule a time so that we can discuss the product <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6989 2881 3421 5079  818 3387 4742  175 5265 3606 3249 4331 5183 1331  439\n",
      " 5036  290 5934 6336 5505  208 2939 4533 3723 4288 2881 3816  439 5675 4786\n",
      " 4780 4399 6126 5934 1069 5911 4786 4780 2545 3358  208 2939    1    1    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > hansen for next wednesday to meet about this will initially be traded only internally i send you a presentation of the product and its description for eol i think that we should schedule a time so that we can discuss the product <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00745907738095\n",
      "global_step: 9997\n",
      "learning rate 0.000461282\n",
      "epoch 84\n",
      "batch 0\n",
      "training minibatch loss: 0.09564586728811264\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4533  724 2589  208 3703 7134 5384 3602 5131  725 1277 4533 6131    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > and deals with the utility solutions business anyway pitney bowes praxair and sprint <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6650 2255  559 7157 4786 4780 2545  803 6289 1160 1393  818   48 2540 5142\n",
      " 3887 2222 3044  575 2700  577 3044  243    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > ca s pretty quickly that we can take off without needing to put additional names up ? gas niagara mohawk washington gas light <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6650 2255  559 7157 4786 4780 2545  803 6289 1160 1393  818   48 2540 5142\n",
      " 3887 2222 3044  575 2700  577 3044  243    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > ca s pretty quickly that we can take off without needing to put additional names up ? gas niagara mohawk washington gas light <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981050531915\n",
      "0.0152295152295\n",
      "global_step: 10116\n",
      "learning rate 0.000457053\n",
      "epoch 85\n",
      "batch 0\n",
      "training minibatch loss: 0.10212704539299011\n",
      "  sample 1:\n",
      "    Index 7\n",
      "    enc input           > [ 439 6404  818 1810  818  208 5740 4076 1141 6681 3832 2826  439  516  818\n",
      " 6412 6261  208 4880 3301 4076 5265 3249 2259 4567 3973 4335 5934 6813 4273\n",
      " 5490  208 5740 4880 3301 4076 3883 3197 5505 4076    1]\n",
      "    enc input           > i want to move to the new garage let me know what i need to do thanks the enron center garage will be opening very soon offered a parking space in the new enron center garage employee cost of garage <EOS>\n",
      "    dec input           > [7074 4880 3837 3576   86  208 4880 3301 4076 5265 3249 2259 4567 3973 4335\n",
      " 5934 6813 4273 5490  208 5740 4880 3301 4076 3883 3197 5505 4076    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > availability enron north america corp the enron center garage will be opening very soon offered a parking space in the new enron center garage employee cost of garage <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7074 4880 3837 3576   86  208 4880 3301 4076 5265 3249 2259 4567 3973 4335\n",
      " 5934 6813 4273 5490  208 5740 4880 3301 4076 3883 3197 5505 4076    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > availability enron north america corp the enron center garage will be opening very soon offered a parking space in the new enron center garage employee cost of garage <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.965665849673\n",
      "0.0173126913936\n",
      "global_step: 10235\n",
      "learning rate 0.000452863\n",
      "epoch 86\n",
      "batch 0\n",
      "training minibatch loss: 0.09887857735157013\n",
      "  sample 1:\n",
      "    Index 520\n",
      "    enc input           > [2826 3706  175 2613 2222    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > what does this mean ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 4495 1141 6681 3832 2826  290 5675 1930  290  311  660\n",
      "  279 2826 6293 2362 2222    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > enron north america corp excellent let me know what you think did you ever find out what tom wanted ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 4495 1141 6681 3832 2826  290 5675 1930  290  311  660\n",
      "  279 2826 6293 2362 2222 2826    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > enron north america corp excellent let me know what you think did you ever find out what tom wanted ? what <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.94586038961\n",
      "0.00385416666667\n",
      "global_step: 10354\n",
      "learning rate 0.000448711\n",
      "epoch 87\n",
      "batch 0\n",
      "training minibatch loss: 0.09374209493398666\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [ 818 7058 1916    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > to each asap <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7058 1916    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > each asap <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7058 1916    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > each asap <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.905595357352\n",
      "0.00662364130435\n",
      "global_step: 10473\n",
      "learning rate 0.000444597\n",
      "epoch 88\n",
      "batch 0\n",
      "training minibatch loss: 0.06950660049915314\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [1923  175 5265 6616 1227  290 3887  439 3832 4361  703  290 4130 5489 2126\n",
      " 5001  972 6356 2126 5001  972 6356 2126  972 6356 4149 5934  604  818 1227\n",
      "  290 3887 3476 6708 6251 5893  571 4077 3095 2025 4942    1]\n",
      "    enc input           > maybe this will help cheer you up i know how much you love cats subject fw cat clip subject fw cat clip subject cat clip just a thought to cheer you up after hauling around all those plans spawglass contractors inc <EOS>\n",
      "    dec input           > [ 512  175 5265 1227  290 4149 5934 4442 2126 5001  972 6356 2126 5001  972\n",
      " 6356 2126  972 6356 4149 5934  604  818 1227  290 3887 3476 6708 6251 5893\n",
      "  571 4077 3095 2025 4942    1    0    0    0    0    0]\n",
      "    dec input           > hopefully this will cheer you just a little subject fw cat clip subject fw cat clip subject cat clip just a thought to cheer you up after hauling around all those plans spawglass contractors inc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 512  175 5265 1227  290 4149 5934 4442 2126 5001  972 6356 2126 5001  972\n",
      " 6356 2126  972 6356 4149 5934  604  818 1227  290 3887 3476 6708 6251 5893\n",
      "  571 4077 3095 2025 4942    1    1    0    0    0    0    0]\n",
      "    dec train predicted > hopefully this will cheer you just a little subject fw cat clip subject fw cat clip subject cat clip just a thought to cheer you up after hauling around all those plans spawglass contractors inc <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0102786847762\n",
      "global_step: 10592\n",
      "learning rate 0.000440521\n",
      "epoch 89\n",
      "batch 0\n",
      "training minibatch loss: 0.07454739511013031\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [ 289 4533  289 4786 1557 6826  290 2222    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > th and th that day are you ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 5675 7132 2642 6583 3969 4819  500 3665 2881 1972 2222    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > i think tuesday looks good other than monday look for lunch ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 5675 7132 2642 6583 3969 4819  500 3665 2881 1972 2222    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > i think tuesday looks good other than monday look for lunch ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n",
      "0.00379025981801\n",
      "global_step: 10711\n",
      "learning rate 0.000436482\n",
      "epoch 90\n",
      "batch 0\n",
      "training minibatch loss: 0.06763505935668945\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4505  818 4170 4526 3886 4880 3837 3576   86    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > like to hear your perspective enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2132  439 6412  516  818 1810 2110 5856  439 3645 3249 5490 5524  818 6521\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > at i do need to move our meeting i lll be in touch to reschedule <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2132  439 6412  516  818 1810 2110 5856  439 3645 3249 5490 5524  818 6521\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > at i do need to move our meeting i lll be in touch to reschedule <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999362244898\n",
      "0.0134333025532\n",
      "global_step: 10830\n",
      "learning rate 0.00043248\n",
      "epoch 91\n",
      "batch 0\n",
      "training minibatch loss: 0.05605555698275566\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5720 1654 1906 5540  502    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > approved on january history approval <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1654 1906 5540  502    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > on january history approval <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1654 1906 5540  502    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > on january history approval <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0040255912712\n",
      "global_step: 10949\n",
      "learning rate 0.000428515\n",
      "epoch 92\n",
      "batch 0\n",
      "training minibatch loss: 0.06713730096817017\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [6145 4487 4786  290 6404 1654  208 2058    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > dot points that you want on the page <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 1131 4786 1026 5265 1156  208 3520 4533 3336    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > i assume that rac will have the resolutions and dash <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 1131 4786 1026 5265 1156  208 3520 4533 3336    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > i assume that rac will have the resolutions and dash <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.979166666667\n",
      "0.00520156574844\n",
      "global_step: 11068\n",
      "learning rate 0.000424587\n",
      "epoch 93\n",
      "batch 0\n",
      "training minibatch loss: 0.056608881801366806\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2315 6261    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > office thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6681 3832 5075  290  516 2973 5707 5674 6261 2541 5616 5793 1917 4533 4696\n",
      " 2859 2929 1141 6681 3832 5075  290 1156 1397 2228 1427    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > me know if you need anything from us thanks dick vass brian barth and kevin mcconville memo let me know if you have any questions regards <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6681 3832 5075  290  516 2973 5707 5674 6261 2541 5616 5793 1917 4533 4696\n",
      " 2859 2929 1141 6681 3832 5075  290 1156 1397 2228 1427    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > me know if you need anything from us thanks dick vass brian barth and kevin mcconville memo let me know if you have any questions regards <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00625676406926\n",
      "global_step: 11187\n",
      "learning rate 0.000420694\n",
      "epoch 94\n",
      "batch 0\n",
      "training minibatch loss: 0.050268832594156265\n",
      "  sample 1:\n",
      "    Index 311\n",
      "    enc input           > [ 724 4533 1141  290 3832 6681 3832 4168 4639 1384 5091 4533 5075  393 4399\n",
      " 3997 3249  208 3142 5091 6115    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > deals and let you know me know which one is correct and if they should both be the same correct now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 3129  818   48 5490 5934 4135 2635 1423 6806 2642 6583  142 2589  208\n",
      " 2057 4780  573 5490 1165  290    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > i forgot to put in a signature block otherwise it looks good approve with the information we filled in thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 3129  818   48 5490 5934 4135 2635 1423 6806 2642 6583  142 2589  208\n",
      " 2057 4780  573 5490 1165  290    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > i forgot to put in a signature block otherwise it looks good approve with the information we filled in thank you <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00926302812792\n",
      "global_step: 11306\n",
      "learning rate 0.000416837\n",
      "epoch 95\n",
      "batch 0\n",
      "training minibatch loss: 0.04809175804257393\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4482 3974 4334  290 5265  660 1970  208 1926 1368 4533 3277 3188 6074 5081\n",
      " 1654 4227 5505 6507 1500    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > exception being granted you will find attached the recommendation letter and his resume tammie schoppe on behalf of john lavorato <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6507 6450 6822 4786 1648 3706 3827  290 2030  208  295  290 5265  660 1970\n",
      "  208 1926 1368 4533 3277 3188 6074 5081 1654 4227 5505 6507 1500    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > john ken said that he does support you extending the offer you will find attached the recommendation letter and his resume tammie schoppe on behalf of john lavorato <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6507 6450 6822 4786 1648 3706 3827  290 2030  208  295  290 5265  660 1970\n",
      "  208 1926 1368 4533 3277 3188 6074 5081 1654 4227 5505 6507 1500    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > john ken said that he does support you extending the offer you will find attached the recommendation letter and his resume tammie schoppe on behalf of john lavorato <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00183823529412\n",
      "global_step: 11425\n",
      "learning rate 0.000413016\n",
      "epoch 96\n",
      "batch 0\n",
      "training minibatch loss: 0.04588994383811951\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 208 5791 5265 6548 6022 5698 4880 3837 3576   86 6362  208 6106    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > the demand will come through better enron north america corp see the numbers <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5097 3249  279 5505  208 2315 1654  500 6849 1654 7132    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    dec input           > probably be out of the office on monday returning on tuesday <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5097 3249  279 5505  208 2315 1654  500 6849 1654 7132    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > probably be out of the office on monday returning on tuesday <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00788543194037\n",
      "global_step: 11544\n",
      "learning rate 0.000409229\n",
      "epoch 97\n",
      "batch 0\n",
      "training minibatch loss: 0.042145781219005585\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2826 1980 5505 1069 1323 6826 4780 4429 2132 2222  439 6628 3938 5427  439\n",
      " 1257  818 1344 4533 6822 4780 6850 6799  279 3277 3887 2881 6806    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > what kind of time frame are we looking at ? i was thinking yes i talked to him and said we were going out his up for it <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6226 4533 4526 1654    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > say and your on <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6226 4533 4526 1654    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > say and your on <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0227746212121\n",
      "global_step: 11663\n",
      "learning rate 0.000405477\n",
      "epoch 98\n",
      "batch 0\n",
      "training minibatch loss: 0.03955705836415291\n",
      "  sample 1:\n",
      "    Index 326\n",
      "    enc input           > [ 439 2006 6799  818 5527 4835 2255 1908 2132 2365 1923 3476 1384 3402 4306\n",
      " 5674 5934 4461 5915 2222    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i m going to jay blaine s taylor at pm maybe after is meredith buying us a drink tomorrow ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 1156  818  885 5539  818 4243  279 2881 5934 3370 5239 5505 6509 5075\n",
      " 6806 1384 7132 4780 2545  659 6557  439 5762 5911  703 1421  813 3312 5190\n",
      " 2545 4780 6412 6806 2426 2222    1    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > i have to head home to work out for a few hours of course if it is tuesday we can watch frasier i had so much fun last night when can we do it again ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 1156  818  885 5539  818 4243  279 2881 5934 3370 5239 5505 6509 5075\n",
      " 6806 1384 7132 4780 2545  659 6557  439 5762 5911  703 1421  813 3312 5190\n",
      " 2545 4780 6412 6806 2426 2222    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > i have to head home to work out for a few hours of course if it is tuesday we can watch frasier i had so much fun last night when can we do it again ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.971097275951\n",
      "0.00300343249428\n",
      "global_step: 11782\n",
      "learning rate 0.00040176\n",
      "epoch 99\n",
      "batch 0\n",
      "training minibatch loss: 0.04031224176287651\n",
      "  sample 1:\n",
      "    Index 8\n",
      "    enc input           > [4998  439 2006 1821  818 4975  290 3486 6681 3432 2720 1069 6261 5620    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > anytime i m here to serve you remeber me during review time thanks man <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5655 1230  175 4072  748 5915  439 4371 4999 6806    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > could rerun this first thing tomorrow i would appreciate it <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5655 1230  175 4072  748 5915  439 4371 4999 6806    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > could rerun this first thing tomorrow i would appreciate it <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997421841077\n",
      "0.00173611111111\n",
      "global_step: 11901\n",
      "learning rate 0.000398076\n",
      "epoch 100\n",
      "batch 0\n",
      "training minibatch loss: 0.03661435469985008\n",
      "  sample 1:\n",
      "    Index 8\n",
      "    enc input           > [4394 1747 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > well done relocate to houston and report to me in his new role <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6527 5934 3370 6289  208 4716 5659  175 1637  857 5895  175 1637 6583 7198\n",
      " 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > bounce a few off the ole shack this summer back windows this summer good luck relocate to houston and report to me in his new role <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6527 5934 3370 6289  208 4716 5659  175 1637  857 5895  175 1637 6583 7198\n",
      " 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > bounce a few off the ole shack this summer back windows this summer good luck relocate to houston and report to me in his new role <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00444240196078\n",
      "global_step: 12020\n",
      "learning rate 0.000394427\n",
      "epoch 101\n",
      "batch 0\n",
      "training minibatch loss: 0.03486314415931702\n",
      "  sample 1:\n",
      "    Index 518\n",
      "    enc input           > [1747 2881  290 2973    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > done for you anything <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1413 2222    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > huh ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1413 2222    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > huh ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.997367527174\n",
      "0.00316976264501\n",
      "global_step: 12139\n",
      "learning rate 0.000390811\n",
      "epoch 102\n",
      "batch 0\n",
      "training minibatch loss: 0.04184146970510483\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [1141 6681 3832 2826  208 1338 1384 2222  856 4533  439 1156 5253  851  818\n",
      "  816 6024 6261 1357  812 2881 4526 6616 3781 4533 4843 2869 5139  681 5385\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > let me know what the scoop is ? documents and i have no place to record them thanks as usual for your help moran and veronica espinoza access cheryl nelson <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 6681 5934 5514 5075  290 1156 1397 4725    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > enron north america corp me a x if you have any problems <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 6681 5934 5514 5075  290 1156 1397 4725    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > enron north america corp me a x if you have any problems <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0200436989911\n",
      "global_step: 12258\n",
      "learning rate 0.000387228\n",
      "epoch 103\n",
      "batch 0\n",
      "training minibatch loss: 0.03468434140086174\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [6806 1384 4567 5600 4786  175 3663 6415 6618 1412 1384  252 6004  208 6048\n",
      " 1384  779 4880 3837 3576   86 1384 5934 4567 4994 1998  687 6254  290 6792\n",
      " 3556 1856 4880 3837 3576   86  687 5490  208 7226  296 2508 3081 6261    1]\n",
      "    enc input           > it is very critical that this drop down works correctly is currently designed the system is confusing enron north america corp is a very bad idea entry hope you re enjoying canada enron north america corp entry in the master swap agreement database thanks <EOS>\n",
      "    dec input           > [1747 4456  687 5490  208 7226  296 2508 3081 6261    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > done thanx entry in the master swap agreement database thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1747 4456  687 5490  208 7226  296 2508 3081 6261    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > done thanx entry in the master swap agreement database thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00418803418803\n",
      "global_step: 12377\n",
      "learning rate 0.000383678\n",
      "epoch 104\n",
      "batch 0\n",
      "training minibatch loss: 0.04141785576939583\n",
      "  sample 1:\n",
      "    Index 10\n",
      "    enc input           > [ 132  658  912 2637 5984 1384 4786 6873  290 3016  818 4635 2255  592 2222\n",
      " 1349  291 4027  818 4915 2637 4749 2508 6480  912  175 2578    1    0    0\n",
      "    0    0    0    0    0]\n",
      "    enc input           > futures trading account or not is that why you responded to mark s email ? another person pursuant to express or implied agreement affiliate account this request <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6681 2132 5514 5660 2132  175 1069  439  516  818 3832 2826  132 1819  290\n",
      " 6826  658 2222  439 6412 1156 5934  132  658  912 4880 3837 3576   86 1349\n",
      "  291 4027  818 4915 2637 4749 2508 6480  912  175 2578    1    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > me at x none at this time i need to know what futures products you are trading ? i do have a futures trading account enron north america corp another person pursuant to express or implied agreement affiliate account this request <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6681 2132 5514 5660 2132  175 1069  439  516  818 3832 2826  132 1819  290\n",
      " 6826  658 2222  439 6412 1156 5934  132  658  912 4880 3837 3576   86 1349\n",
      "  291 4027  818 4915 2637 4749 2508 6480  912  175 2578    1    1    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > me at x none at this time i need to know what futures products you are trading ? i do have a futures trading account enron north america corp another person pursuant to express or implied agreement affiliate account this request <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991390306122\n",
      "0.000744047619048\n",
      "global_step: 12496\n",
      "learning rate 0.00038016\n",
      "epoch 105\n",
      "batch 0\n",
      "training minibatch loss: 0.03433245047926903\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3748 3446 4533 6848 5603 2057    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > reporting agency and data source information <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3447 3619 4536   86 3748 3446 4533 6848 5603 2057    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > enron capital trade resources corp reporting agency and data source information <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3447 3619 4536   86 3748 3446 4533 6848 5603 2057    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > enron capital trade resources corp reporting agency and data source information <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00183823529412\n",
      "global_step: 12615\n",
      "learning rate 0.000376675\n",
      "epoch 106\n",
      "batch 0\n",
      "training minibatch loss: 0.030541477724909782\n",
      "  sample 1:\n",
      "    Index 19\n",
      "    enc input           > [4371 4505  818 6362  290 2881 1972 4880 3837 3576   86    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > would like to see you for lunch enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5934 2476 3470 2529 1649 4786 3706  593 6583 5190 6412  290 6404 6806 2222\n",
      " 6115 2222 6412  290 1156 5934 2529 1649 2222 3234 1972 2222  439 2006 3377\n",
      " 1654  175   63    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > a caffeine free diet coke that does sound good when do you want it ? now ? do you have a diet coke ? something lunch ? i m stuck on this call <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5934 2476 3470 2529 1649 4786 3706  593 6583 5190 6412  290 6404 6806 2222\n",
      " 6115 2222 6412  290 1156 5934 2529 1649 2222 3234 1972 2222  439 2006 3377\n",
      " 1654  175   63    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > a caffeine free diet coke that does sound good when do you want it ? now ? do you have a diet coke ? something lunch ? i m stuck on this call <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.990908597482\n",
      "0.0073505438725\n",
      "global_step: 12734\n",
      "learning rate 0.000373221\n",
      "epoch 107\n",
      "batch 0\n",
      "training minibatch loss: 0.036495476961135864\n",
      "  sample 1:\n",
      "    Index 356\n",
      "    enc input           > [ 559 3091 5384 1821 3974 4160 2637 4580 2394 2222    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > pretty risky business here being short or long eh ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 208 3577 5816  790 3048 3334 5218 5505  208 1006 2704 6115 3545 3113   51\n",
      " 3237 1437 4533 6201 4362    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > the future lower interest rate environment instead of the mediocre past now between financials tech drugs energy and consumer wmt <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 208 3577 5816  790 3048 3334 5218 5505  208 1006 2704 6115 3545 3113   51\n",
      " 3237 1437 4533 6201 4362    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > the future lower interest rate environment instead of the mediocre past now between financials tech drugs energy and consumer wmt <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999335106383\n",
      "0.00472285067873\n",
      "global_step: 12853\n",
      "learning rate 0.0003698\n",
      "epoch 108\n",
      "batch 0\n",
      "training minibatch loss: 0.043861862272024155\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1970 5934  481 5505 2373  724 2589 3227 4533 6073 4708  830    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > attached a copy of recent deals with aquila and el paso inormation <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5655  290 7196  162 6818  279 2881 6681 5915 2222 6261 1970 5934  481 5505\n",
      " 2373  724 2589 3227 4533 6073 4708  830    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > could you please print these out for me tomorrow ? thanks attached a copy of recent deals with aquila and el paso inormation <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5655  290 7196  162 6818  279 2881 6681 5915 2222 6261 1970 5934  481 5505\n",
      " 2373  724 2589 3227 4533 6073 4708  830    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > could you please print these out for me tomorrow ? thanks attached a copy of recent deals with aquila and el paso inormation <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.96362888756\n",
      "0.00531567617165\n",
      "global_step: 12972\n",
      "learning rate 0.000366409\n",
      "epoch 109\n",
      "batch 0\n",
      "training minibatch loss: 0.04048096761107445\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2546 3353    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > my apologies <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2642 4505  592 7091 2881  290 6628 1255 2732 2300 2546 3353    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > looks like email address for you was wrong got returned my apologies <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2642 4505  592 7091 2881  290 6628 1255 2732 2300 2546 3353    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > looks like email address for you was wrong got returned my apologies <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987254025045\n",
      "0.00463822421059\n",
      "global_step: 13091\n",
      "learning rate 0.00036305\n",
      "epoch 110\n",
      "batch 0\n",
      "training minibatch loss: 0.03173276036977768\n",
      "  sample 1:\n",
      "    Index 164\n",
      "    enc input           > [1501 5707 5924  439 2006 5490 4880 2255 5146 5911  439 2545 2467 3887  592\n",
      " 1164 4742 4361  818 4705 6507  987  208 1514 6850  175 1069  813 6895  695\n",
      " 3329    1    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > hello from chicago i m in enron s offices so i can pick up email talk about how to get john into the program were this time last year things change <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5707  208  691  595  208 4880 5935 5240  648 3722    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > from the canadian but the enron coverage seems quite comprehensive <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5707  208  691  595  208 4880 5935 5240  648 3722    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > from the canadian but the enron coverage seems quite comprehensive <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.996717087766\n",
      "0.0122499283804\n",
      "global_step: 13210\n",
      "learning rate 0.000359722\n",
      "epoch 111\n",
      "batch 0\n",
      "training minibatch loss: 0.02690538950264454\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [5522 2637 6374  987 1397 3629 5562 3407 2881 7033 3829 5265 5638 6806 7031\n",
      " 1357 3973 1357 3069    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > materials or enter into any services agreements except for studies etc will pass it along as soon as possible <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3971  468 4371 3249 6701 4649  439  746 1821 2222    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > geotechnical survey would be ok am i safe here ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3971  468 4371 3249 6701 4649  439  746 1821 2222    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > geotechnical survey would be ok am i safe here ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0128724319861\n",
      "global_step: 13329\n",
      "learning rate 0.000356424\n",
      "epoch 112\n",
      "batch 0\n",
      "training minibatch loss: 0.026772094890475273\n",
      "  sample 1:\n",
      "    Index 11\n",
      "    enc input           > [ 439 5265  803 5934 6892  208 4880 3301 4076 1728 6785 3974 4335 5934 6813\n",
      " 4273 5490  208 5740 4880 3301 4076 3883 3197 5505 4076 6569    1    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > i will take a spot the enron center garage has opened being offered a parking space in the new enron center garage employee cost of garage spaces <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 4371 4505  818 1810  818  208 5740 4076 1141 6681 3832 2826  439  516\n",
      "  818 6412  208 4880 3301 4076 1728 6785 3974 4335 5934 6813 4273 5490  208\n",
      " 5740 4880 3301 4076 3883 3197 5505 4076 6569    1    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > i would like to move to the new garage let me know what i need to do the enron center garage has opened being offered a parking space in the new enron center garage employee cost of garage spaces <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 4371 4505  818 1810  818  208 5740 4076 1141 6681 3832 2826  439  516\n",
      "  818 6412  208 4880 3301 4076 1728 6785 3974 4335 5934 6813 4273 5490  208\n",
      " 5740 4880 3301 4076 3883 3197 5505 4076 6569    1    1    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > i would like to move to the new garage let me know what i need to do the enron center garage has opened being offered a parking space in the new enron center garage employee cost of garage spaces <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.995149772497\n",
      "0.00533498759305\n",
      "global_step: 13448\n",
      "learning rate 0.000353156\n",
      "epoch 113\n",
      "batch 0\n",
      "training minibatch loss: 0.023208245635032654\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2531 6806 5265  611 4580 4371 3249 5698 6261 2881 1870  175 3887 3832 5075\n",
      "  175 1069 1718 6042 2589  290 4533  439 5265   63 1344  818 4297 6806 6261\n",
      "    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > risk it will run long would be better thanks for setting this up know if this time isa okay with you and i will call him to confirm it thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6618 2881 6681 5219 1728 5934 5856 4361 4742 2222 2531 6806 5265  611 4580\n",
      " 4371 3249 5698 6261 2881 1870  175 3887 3832 5075  175 1069 1718 6042 2589\n",
      "  290 4533  439 5265   63 1344  818 4297 6806 6261    1    0    0    0    0]\n",
      "    dec input           > works for me herman has a meeting how about ? risk it will run long would be better thanks for setting this up know if this time isa okay with you and i will call him to confirm it thanks <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6618 2881 6681 5219 1728 5934 5856 4361 4742 2222 2531 6806 5265  611 4580\n",
      " 4371 3249 5698 6261 2881 1870  175 3887 3832 5075  175 1069 1718 6042 2589\n",
      "  290 4533  439 5265   63 1344  818 4297 6806 6261    1    1    0    0    0\n",
      "    0]\n",
      "    dec train predicted > works for me herman has a meeting how about ? risk it will run long would be better thanks for setting this up know if this time isa okay with you and i will call him to confirm it thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0127469091085\n",
      "global_step: 13567\n",
      "learning rate 0.000349918\n",
      "epoch 114\n",
      "batch 0\n",
      "training minibatch loss: 0.02339242212474346\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2826 6412  290 5675 5505  175 2738 2222 4371 3249 4872 5075 4780 5655 4705\n",
      " 6361 3421 1306  818 4705 4526 2181 3741 3014 4942    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > what do you think of this language ? would be great if we could get together next week to get your feedback software architects inc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4371 3249 4872 5075 4780 5655 4705 6361 3421 1306  818 4705 4526 2181 3741\n",
      " 3014 4942    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > would be great if we could get together next week to get your feedback software architects inc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4371 3249 4872 5075 4780 5655 4705 6361 3421 1306  818 4705 4526 2181 3741\n",
      " 3014 4942    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > would be great if we could get together next week to get your feedback software architects inc <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997448979592\n",
      "0.0184450933483\n",
      "global_step: 13686\n",
      "learning rate 0.00034671\n",
      "epoch 115\n",
      "batch 0\n",
      "training minibatch loss: 0.021223392337560654\n",
      "  sample 1:\n",
      "    Index 7\n",
      "    enc input           > [4880 3837 3576   86  439 1179 2291 1479 4533 4372 3312 4361 3706 4786  593\n",
      " 2222 6155 5646 4780 6362 7058 3969 4941 5431 4775 1141 6681 3832 2826  290\n",
      " 1618 5675 1923 4780 4399  626 5934 1150 1972 2222    1    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > enron north america corp i ll cook thursday and saturday night how does that sound ? rushed considering we see each other once every months let me know what you girls think maybe we should try a weekend lunch ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 2881  208 4006 2545 4780 6521  208 6346 2222  439 4691 3249 5490  400\n",
      " 2257 1654  325  325  208  289 6826 1597 1397 2201 4786  290 5301 2222    1\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks for the invitation can we reschedule the dinner ? i shall be in san antonio on friday friday the th are there any foods that you avoid ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 2881  208 4006 2545 4780 6521  208 6346 2222  439 4691 3249 5490  400\n",
      " 2257 1654  325  325  208  289 6826 1597 1397 2201 4786  290 5301 2222    1\n",
      "    1    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > thanks for the invitation can we reschedule the dinner ? i shall be in san antonio on friday friday the th are there any foods that you avoid ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0117881811816\n",
      "global_step: 13805\n",
      "learning rate 0.000343531\n",
      "epoch 116\n",
      "batch 0\n",
      "training minibatch loss: 0.020076876506209373\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [ 167 1781  494  290 4371 5097 4505 4786 5665 1854 5014 5505 5635 4526 2694\n",
      " 1597 2545  290  592 6681 6111 2255  339 5911  439 2545 5036 1344  208 2776\n",
      "  481 2222  439 3186 2110 1069 6361 4533 3665 6983  818 2088  332    1]\n",
      "    enc input           > processing plant hey you would probably like that nj mississippi point of spending your vacation there can you email me glenn s info so i can send him the hard copy ? i enjoyed our time together and look forward to more adventures <EOS>\n",
      "    dec input           > [5005 2254 6261 5014 5505 5635 4526 2694 1597 2545  290  592 6681 6111 2255\n",
      "  339 5911  439 2545 5036 1344  208 2776  481 2222  439 3186 2110 1069 6361\n",
      " 4533 3665 6983  818 2088  332    1    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > opps convenience thanks point of spending your vacation there can you email me glenn s info so i can send him the hard copy ? i enjoyed our time together and look forward to more adventures <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5005 2254 6261 5014 5505 5635 4526 2694 1597 2545  290  592 6681 6111 2255\n",
      "  339 5911  439 2545 5036 1344  208 2776  481 2222  439 3186 2110 1069 6361\n",
      " 4533 3665 6983  818 2088  332    1    1    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > opps convenience thanks point of spending your vacation there can you email me glenn s info so i can send him the hard copy ? i enjoyed our time together and look forward to more adventures <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0239452030812\n",
      "global_step: 13924\n",
      "learning rate 0.000340382\n",
      "epoch 117\n",
      "batch 0\n",
      "training minibatch loss: 0.02218313328921795\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [1164  818 1765 5490  208  905  818 2500 6818 4533  439 1179 1141  290 3832\n",
      " 1916    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > talk to tfs in the morning to verify these and i ll let you know asap <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 571  971 5490  208 6048 3973 5702  105 6681 5483 1648 3129  818 4378 4671\n",
      " 1164  818 1765 5490  208  905  818 2500 6818 4533  439 1179 1141  290 3832\n",
      " 1916    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > those trades in the system soon broker told me yesterday he forgot to tell bob talk to tfs in the morning to verify these and i ll let you know asap <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 571  971 5490  208 6048 3973 5702  105 6681 5483 1648 3129  818 4378 4671\n",
      " 1164  818 1765 5490  208  905  818 2500 6818 4533  439 1179 1141  290 3832\n",
      " 1916    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > those trades in the system soon broker told me yesterday he forgot to tell bob talk to tfs in the morning to verify these and i ll let you know asap <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00989583333333\n",
      "global_step: 14043\n",
      "learning rate 0.000337261\n",
      "epoch 118\n",
      "batch 0\n",
      "training minibatch loss: 0.024271585047245026\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [7196 2985 6681 5934   63 6792 2597 6261 4880 3837 3576   86    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > please give me a call re oneok thanks enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4568 4533  481 1178 6704 4880 3837 3576   86    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > attention and copy russell diamond enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4568 4533  481 1178 6704 4880 3837 3576   86    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > attention and copy russell diamond enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.966145833333\n",
      "0.00927197802198\n",
      "global_step: 14162\n",
      "learning rate 0.000334169\n",
      "epoch 119\n",
      "batch 0\n",
      "training minibatch loss: 0.016511496156454086\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [4072 2146 1384 6107 4524 2986  175 2169 1624 4388 4786  759 6115    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > first deal is jeff richter entered this awhile ago adding that right now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 687 5617 4072 2146 1384 6107 4524 2986  175 2169 1624 4388 4786  759 6115\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    dec input           > entry sorry first deal is jeff richter entered this awhile ago adding that right now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 687 5617 4072 2146 1384 6107 4524 2986  175 2169 1624 4388 4786  759 6115\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > entry sorry first deal is jeff richter entered this awhile ago adding that right now <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0051299452862\n",
      "global_step: 14281\n",
      "learning rate 0.000331106\n",
      "epoch 120\n",
      "batch 0\n",
      "training minibatch loss: 0.023873036727309227\n",
      "  sample 1:\n",
      "    Index 252\n",
      "    enc input           > [5075 6806 1384 6701 2589  290  439 1179 1141  290 3832 5490 5934 4442 7163\n",
      " 5321 4149 1141 6681 3832  439 4649    2 5750  844  279 5911 4780 2545 4705\n",
      " 5518 4243 1747    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > if it is ok with you i ll let you know in a little bit son just let me know i am flexible today sent out so we can get some work done <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4585 2426  985 2569 2222 4816 1384 2418 5934 4442 2846    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > acknowledged again their commitment ? iec is getting a little nervous <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4585 2426  985 2569 2222 4816 1384 2418 5934 4442 2846    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > acknowledged again their commitment ? iec is getting a little nervous <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.991709183673\n",
      "0.0106587998102\n",
      "global_step: 14400\n",
      "learning rate 0.00032807\n",
      "epoch 121\n",
      "batch 0\n",
      "training minibatch loss: 0.018536357209086418\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 290 6826  906 5577 5467 5253 3471  208 5563 6575 5740 4839    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > you are absolutely by far no comparisons the best voila new starters <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5707 2546 5604  818 3277 3105 1397 6770 5505 4526  318 4786 1654  818 6107\n",
      " 1888 2222  290 6826  906 5577 5467 5253 3471  208 5563 6575 5740 4839    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > from my mouth to his ear any chance of your passing that on to jeff skilling ? you are absolutely by far no comparisons the best voila new starters <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5707 2546 5604  818 3277 3105 1397 6770 5505 4526  318 4786 1654  818 6107\n",
      " 1888 2222  290 6826  906 5577 5467 5253 3471  208 5563 6575 5740 4839    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > from my mouth to his ear any chance of your passing that on to jeff skilling ? you are absolutely by far no comparisons the best voila new starters <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.000919117647059\n",
      "global_step: 14519\n",
      "learning rate 0.000325062\n",
      "epoch 122\n",
      "batch 0\n",
      "training minibatch loss: 0.016690999269485474\n",
      "  sample 1:\n",
      "    Index 7\n",
      "    enc input           > [ 818  754 4168 1384 1654 2724 1010 2637 5075 3604 6326  208 5920  987  754\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > to spain which is on subs until or if adaro sells the coal into spain <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4533 6362  290 3421 6895    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > and see you next year <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4533 6362  290 3421 6895    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > and see you next year <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0118456757703\n",
      "global_step: 14638\n",
      "learning rate 0.000322082\n",
      "epoch 123\n",
      "batch 0\n",
      "training minibatch loss: 0.01589607633650303\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1940 1335 1654  208  955 6996 1717 5707 1103 4857 6179 1384 3245 2370 2222\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > second floor on the left side across from mi luna where is two rows ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 5075 4079 1384 6799  818 3249 1597  439 1179  626  818  464 2745    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > thanks if tim is going to be there i ll try to go tonight <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 5075 4079 1384 6799  818 3249 1597  439 1179  626  818  464 2745    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > thanks if tim is going to be there i ll try to go tonight <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.996573067633\n",
      "0.00581597222222\n",
      "global_step: 14757\n",
      "learning rate 0.000319129\n",
      "epoch 124\n",
      "batch 0\n",
      "training minibatch loss: 0.017495833337306976\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4635 2637 2442  818 3358    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > mark or myself to discuss <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4437 2881  413 2720    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > susan for her review <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4437 2881  413 2720    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > susan for her review <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995442708333\n",
      "0.00419292717087\n",
      "global_step: 14876\n",
      "learning rate 0.000316203\n",
      "epoch 125\n",
      "batch 0\n",
      "training minibatch loss: 0.016309507191181183\n",
      "  sample 1:\n",
      "    Index 55\n",
      "    enc input           > [5934 4485 2589 6024    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > a gisb with them <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 2881 4526 4044    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks for your assistance <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 2881 4526 4044    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > thanks for your assistance <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0142639785523\n",
      "global_step: 14995\n",
      "learning rate 0.000313304\n",
      "epoch 126\n",
      "batch 0\n",
      "training minibatch loss: 0.014497688040137291\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [1955 2255 1743 4402 4786 6446 2139  818 5543  818 3277  853 6446 1728 6806\n",
      " 2132 4742    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > gov s finance people that hertzberg used to present to his caucusthanks hertzberg has it at about <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1821 2255  208 2269 4786  439  844 4533  208 4136 5505 2314 4786  439  844\n",
      " 6806  818 4786 6446 2139  818 5543  818 3277  853 6446 1728 6806 2132 4742\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > here s the document that i sent and the list of folks that i sent it to that hertzberg used to present to his caucusthanks hertzberg has it at about <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1821 2255  208 2269 4786  439  844 4533  208 4136 5505 2314 4786  439  844\n",
      " 6806  818 4786 6446 2139  818 5543  818 3277  853 6446 1728 6806 2132 4742\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > here s the document that i sent and the list of folks that i sent it to that hertzberg used to present to his caucusthanks hertzberg has it at about <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.993512613379\n",
      "0.00671040774033\n",
      "global_step: 15114\n",
      "learning rate 0.000310432\n",
      "epoch 127\n",
      "batch 0\n",
      "training minibatch loss: 0.016481870785355568\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [3124 1821 2255 1349 2058 4786 1728 5934 3044  510 5699    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > tony here s another page that has a gas quality section <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 3832    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > enron north america corp know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 3832    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > enron north america corp know <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0161611519608\n",
      "global_step: 15233\n",
      "learning rate 0.000307586\n",
      "epoch 128\n",
      "batch 0\n",
      "training minibatch loss: 0.016093632206320763\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 153  208 3245 1975 5562 4880 3837 3576   86    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > over the two referenced agreements enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2033 2545  290 7196 4871 5934 4297 2881 6681 2222 6806 2255 5490 2546 2315\n",
      " 6261 4880 3837 3576   86    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > kaye can you please fax a confirm for me ? it s in my office thanks enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2033 2545  290 7196 4871 5934 4297 2881 6681 2222 6806 2255 5490 2546 2315\n",
      " 6261 4880 3837 3576   86    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > kaye can you please fax a confirm for me ? it s in my office thanks enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999362244898\n",
      "0.0\n",
      "global_step: 15352\n",
      "learning rate 0.000304766\n",
      "epoch 129\n",
      "batch 0\n",
      "training minibatch loss: 0.016444677487015724\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86 5707  439 5265 3266  290 1736    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp from i will keep you informed <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1168 5490  208 5674 1397 5274 2222    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > counterpart in the us any news ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1168 5490  208 5674 1397 5274 2222    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > counterpart in the us any news ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992756159015\n",
      "0.00373442082111\n",
      "global_step: 15471\n",
      "learning rate 0.000301972\n",
      "epoch 130\n",
      "batch 0\n",
      "training minibatch loss: 0.014962979592382908\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [2751 1378 6621 4533 3687 1047 2149 6256    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > south american countries and carribean tax shelter islands <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3524  695 6826 5984 4567 6474  818 6681 4533  439  516  818  611 6024 5577\n",
      "  290 5313 1435  142  208  503 2906 5149 4780 5265 1156  818 5590 5431 6784\n",
      " 6460  818  208 5664 1234 2040    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > several things are not very clear to me and i need to run them by you financial power approve the london based counterparties we will have to provide every company number to the houston confirmation desk <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3524  695 6826 5984 4567 6474  818 6681 4533  439  516  818  611 6024 5577\n",
      "  290 5313 1435  142  208  503 2906 5149 4780 5265 1156  818 5590 5431 6784\n",
      " 6460  818  208 5664 1234 2040    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > several things are not very clear to me and i need to run them by you financial power approve the london based counterparties we will have to provide every company number to the houston confirmation desk <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00500801282051\n",
      "global_step: 15590\n",
      "learning rate 0.000299203\n",
      "epoch 131\n",
      "batch 0\n",
      "training minibatch loss: 0.018200766295194626\n",
      "  sample 1:\n",
      "    Index 7\n",
      "    enc input           > [ 439 2230 2388 3832 5075  175 5856 1384 4745 1654  439 1179 1141  290 3832\n",
      " 4880 3837 3576   86  851 4533 1069 2126 4257  385 2234 2883 3887 5801 5284\n",
      " 1165  290    1    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i don t know if this meeting is still on i ll let you know enron north america corp place and time subject december pre bidweek set up w logistics thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 595  439 5265 4333 6806 4243  564 2637 3421 5079 2222 7196 1141 6681 3832\n",
      " 1916 5911 4780 2545 6126 5934 2387 5490 6604  818 3358 4133 2079 3044    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > but i will make it work afternoon or next wednesday ? please let me know asap so we can schedule a room in eba to discuss tenaska iv gas <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 595  439 5265 4333 6806 4243  564 2637 3421 5079 2222 7196 1141 6681 3832\n",
      " 1916 5911 4780 2545 6126 5934 2387 5490 6604  818 3358 4133 2079 3044    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > but i will make it work afternoon or next wednesday ? please let me know asap so we can schedule a room in eba to discuss tenaska iv gas <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00130208333333\n",
      "global_step: 15709\n",
      "learning rate 0.00029646\n",
      "epoch 132\n",
      "batch 0\n",
      "training minibatch loss: 0.018192356452345848\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [2018 7035 6826  290 3120 2222    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > yeah waht are you offering ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4361 4742 6400 5796 4533 3193 5304    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > how about jacques green and mike alstot <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4361 4742 6400 5796 4533 3193 5304    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > how about jacques green and mike alstot <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.994897959184\n",
      "0.00599190072303\n",
      "global_step: 15828\n",
      "learning rate 0.000293742\n",
      "epoch 133\n",
      "batch 0\n",
      "training minibatch loss: 0.016835492104291916\n",
      "  sample 1:\n",
      "    Index 514\n",
      "    enc input           > [6873 5984 1027 2222  208 4136    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > why not bitch ? the list <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 2230 2388 6404  818  464 4880 3837 3576   86 6873 5984 1027 2222  208\n",
      " 4136    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "    dec input           > i don t want to go enron north america corp why not bitch ? the list <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 2230 2388 6404  818  464 4880 3837 3576   86 6873 5984 1027 2222  208\n",
      " 4136    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    dec train predicted > i don t want to go enron north america corp why not bitch ? the list <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.98828125\n",
      "0.00934829059829\n",
      "global_step: 15947\n",
      "learning rate 0.000291049\n",
      "epoch 134\n",
      "batch 0\n",
      "training minibatch loss: 0.014087632298469543\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1165  290 2642 4505  208 1955 2255 2315 4371 2246 5707 5847 1320 2126 6792\n",
      " 5856 2274 2849 3545  208 3357 4533 1888 4771 2222 1955 2255 2315 5697 6822\n",
      " 2230 2388   63 5674 4780 1179   63  290    1    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > thank you looks like the gov s office would benefit from charm school subject re meeting been rescheduled between the governor and skilling yet ? gov s office bascially said don t call us we ll call you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2732 3914  857 4072 1069 6436 2426 2126 6792 5856 2274 2849 3545  208 3357\n",
      " 4533 1888 4771 2222 5812 2126 6792 5856 2274 2849 3545  208 3357 4533 1888\n",
      " 4771 2222 1955 2255 2315 5697 6822 2230 2388   63 5674 4780 1179   63  290\n",
      "    1    0    0]\n",
      "    dec input           > got bounced back first time trying again subject re meeting been rescheduled between the governor and skilling yet ? fyi subject re meeting been rescheduled between the governor and skilling yet ? gov s office bascially said don t call us we ll call you <EOS> <PAD> <PAD>\n",
      "    dec train predicted > [2732 3914  857 4072 1069 6436 2426 2126 6792 5856 2274 2849 3545  208 3357\n",
      " 4533 1888 4771 2222 5812 2126 6792 5856 2274 2849 3545  208 3357 4533 1888\n",
      " 4771 2222 1955 2255 2315 5697 6822 2230 2388   63 5674 4780 1179   63  290\n",
      "    1    1    0    0]\n",
      "    dec train predicted > got bounced back first time trying again subject re meeting been rescheduled between the governor and skilling yet ? fyi subject re meeting been rescheduled between the governor and skilling yet ? gov s office bascially said don t call us we ll call you <EOS> <EOS> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0195292075163\n",
      "global_step: 16066\n",
      "learning rate 0.000288381\n",
      "epoch 135\n",
      "batch 0\n",
      "training minibatch loss: 0.012745179235935211\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4987 4533 6261    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > fine and thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6214 7092 4898 2881 3013 6172    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > slightly edited version for small typo <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6214 7092 4898 2881 3013 6172    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > slightly edited version for small typo <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0043804270778\n",
      "global_step: 16185\n",
      "learning rate 0.000285737\n",
      "epoch 136\n",
      "batch 0\n",
      "training minibatch loss: 0.013733924366533756\n",
      "  sample 1:\n",
      "    Index 23\n",
      "    enc input           > [ 439 5265  501  818 1344 1150 1069 1384 2915  279 4533 4780  516  290 1325\n",
      " 3662 1344 5718 3277 6811 2222 6261 2881 4526 1340  439 3665 6983  818 7070\n",
      " 5707  290 5915    1    0    0    0    0    0    0]\n",
      "    enc input           > i will pledge to him weekend time is running out and we need you consider helping him reach his goal ? thanks for your consideration i look forward to hearing from you tomorrow <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3839  439 2006 2517 3764 1357 4394 3163 3764  695 3887 3075 5820 1357 4394\n",
      " 1357 5062 5257 5655  290  592 6681  208  813 4898 5505  208 2168 5882 2222\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > suspect i m creating confusion as well eliminate confusion things up kay mann as well as requested below could you email me the last version of the turbine contract ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3839  439 2006 2517 3764 1357 4394 3163 3764  695 3887 3075 5820 1357 4394\n",
      " 1357 5062 5257 5655  290  592 6681  208  813 4898 5505  208 2168 5882 2222\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > suspect i m creating confusion as well eliminate confusion things up kay mann as well as requested below could you email me the last version of the turbine contract ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.96556122449\n",
      "0.00631009615385\n",
      "global_step: 16304\n",
      "learning rate 0.000283117\n",
      "epoch 137\n",
      "batch 0\n",
      "training minibatch loss: 0.010962185449898243\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [5427  275 3927 1728 3708 3723 3547  818 2261  803 1360 5505 3882  883 7139\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > yes wsj department has changed its focus to research take care of payment expire shortly <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5812  439 1414 4505  818 5922 4793 2881 4073 6872  208 4073    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > fyi i d like to renew due for renewal regarding the renewal <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5812  439 1414 4505  818 5922 4793 2881 4073 6872  208 4073    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > fyi i d like to renew due for renewal regarding the renewal <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00906537750602\n",
      "global_step: 16423\n",
      "learning rate 0.000280522\n",
      "epoch 138\n",
      "batch 0\n",
      "training minibatch loss: 0.011893742717802525\n",
      "  sample 1:\n",
      "    Index 8\n",
      "    enc input           > [3829 6254  818 1164  818  290 3973    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > etc hope to talk to you soon <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6080  439 2006 6583 4645  439 2006 5287 4645 4533 4287 1660 4402 4505 6681\n",
      "  897  208 1840 1654 4880    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > because i m good enough i m smart enough and dog gonnit people like me highlights the effect on enron <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6080  439 2006 6583 4645  439 2006 5287 4645 4533 4287 1660 4402 4505 6681\n",
      "  897  208 1840 1654 4880    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > because i m good enough i m smart enough and dog gonnit people like me highlights the effect on enron <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.976785714286\n",
      "0.00366327751196\n",
      "global_step: 16542\n",
      "learning rate 0.00027795\n",
      "epoch 139\n",
      "batch 0\n",
      "training minibatch loss: 0.014283980242908001\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3069 2222 7076 5740  981 7196 1141 6681 3832 5075  290 1156 1397 2228 2637\n",
      " 5687 1935 4124 4691 3249 7040 1357 2010 2611 4674 1280 5577 6806    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > possible ? gd new book please let me know if you have any questions or comments anyone firm shall be understood as neither given nor endorsed by it <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 3069 2222 7076 5740  981 7196 1141 6681 3832 5075  290\n",
      " 1156 1397 2228 2637 5687 1935 4124 4691 3249 7040 1357 2010 2611 4674 1280\n",
      " 5577 6806    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > enron north america corp possible ? gd new book please let me know if you have any questions or comments anyone firm shall be understood as neither given nor endorsed by it <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 3069 2222 7076 5740  981 7196 1141 6681 3832 5075  290\n",
      " 1156 1397 2228 2637 5687 1935 4124 4691 3249 7040 1357 2010 2611 4674 1280\n",
      " 5577 6806    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > enron north america corp possible ? gd new book please let me know if you have any questions or comments anyone firm shall be understood as neither given nor endorsed by it <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960416666667\n",
      "0.0133661355199\n",
      "global_step: 16661\n",
      "learning rate 0.000275402\n",
      "epoch 140\n",
      "batch 0\n",
      "training minibatch loss: 0.008541742339730263\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 208 6343 5505 1758 2728 5265 3249 5490 2315 1010  398    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > the mayor of tupelo craven will be in office until may <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5490  208 6271 1970 5257 7196   63 6681 2589 1397 2228 2637 5687 2545 4780\n",
      " 6277 6024 3887 2222  439 4371 4505 1156 6024 6277 2881 5893 5674  556 1435\n",
      " 6261 2881 4526 4044 2388    1    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > in the form attached below please call me with any questions or comments can we open them up ? i would like have them open for all us east power thanks for your assistance t <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5490  208 6271 1970 5257 7196   63 6681 2589 1397 2228 2637 5687 2545 4780\n",
      " 6277 6024 3887 2222  439 4371 4505 1156 6024 6277 2881 5893 5674  556 1435\n",
      " 6261 2881 4526 4044 2388    1    1    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > in the form attached below please call me with any questions or comments can we open them up ? i would like have them open for all us east power thanks for your assistance t <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00584437959631\n",
      "global_step: 16780\n",
      "learning rate 0.000272877\n",
      "epoch 141\n",
      "batch 0\n",
      "training minibatch loss: 0.010107520967721939\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [ 208 5183 3329 4399 3249  208 2040 7196 1141 6681 3832  987  208 5459  899\n",
      " 2881 7058 2146 6261    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > the only change should be the desk please let me know into the audit viewer for each deal thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5617 5075  439 6144  290 2881 5934  674 1597 4872 5075 6806 6628 4149 5934\n",
      " 2040 3329  439 2545  803 1360 5505 4786 4567 2982 6261  208 5183 3329 4399\n",
      " 3249  208 2040 7196 1141 6681 3832  987  208 5459  899 2881 7058 2146 6261\n",
      "    1    0    0]\n",
      "    dec input           > sorry if i scared you for a minute there great if it was just a desk change i can take care of that very easily thanks the only change should be the desk please let me know into the audit viewer for each deal thanks <EOS> <PAD> <PAD>\n",
      "    dec train predicted > [5617 5075  439 6144  290 2881 5934  674 1597 4872 5075 6806 6628 4149 5934\n",
      " 2040 3329  439 2545  803 1360 5505 4786 4567 2982 6261  208 5183 3329 4399\n",
      " 3249  208 2040 7196 1141 6681 3832  987  208 5459  899 2881 7058 2146 6261\n",
      "    1    1    0    0]\n",
      "    dec train predicted > sorry if i scared you for a minute there great if it was just a desk change i can take care of that very easily thanks the only change should be the desk please let me know into the audit viewer for each deal thanks <EOS> <EOS> <PAD> <PAD>\n",
      "1.0\n",
      "0.00721950151298\n",
      "global_step: 16899\n",
      "learning rate 0.000270375\n",
      "epoch 142\n",
      "batch 0\n",
      "training minibatch loss: 0.009717624634504318\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [ 439 5265  592  290  413 4784 6460 2132 3119 5941  175 1614    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i will email you her phone number at mount holyoke this evening <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4742 2325 6379  108 2132 1757    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > about pursuing doctoral study at uh <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4742 2325 6379  108 2132 1757    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > about pursuing doctoral study at uh <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00625\n",
      "global_step: 17018\n",
      "learning rate 0.000267896\n",
      "epoch 143\n",
      "batch 0\n",
      "training minibatch loss: 0.009680720046162605\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5253 1415 6628 1970    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > no message was attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2826 5010  290 5675  439 1164  818  413 2132 5893  439 4149 1156  818 3141\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > what makes you think i talk to her at all i just have to listen <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2826 5010  290 5675  439 1164  818  413 2132 5893  439 4149 1156  818 3141\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > what makes you think i talk to her at all i just have to listen <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0031512605042\n",
      "global_step: 17137\n",
      "learning rate 0.00026544\n",
      "epoch 144\n",
      "batch 0\n",
      "training minibatch loss: 0.009256313554942608\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 818  208 4053  113    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > to the template spreadsheet <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2159 6261 5911  703 2881 4526 6616    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > tardiness thanks so much for your help <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2159 6261 5911  703 2881 4526 6616    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > tardiness thanks so much for your help <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00347222222222\n",
      "global_step: 17256\n",
      "learning rate 0.000263006\n",
      "epoch 145\n",
      "batch 0\n",
      "training minibatch loss: 0.008292234502732754\n",
      "  sample 1:\n",
      "    Index 10\n",
      "    enc input           > [5617 1156 5253 1998    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > sorry have no idea <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 2881  208 3537  439 4796 6806 1654  413 2040 2826 2255  208 4017 5505\n",
      "  208 4223 4786 4371 1156  844  208 6271 5490 2222 4742 6806  439 6628  125\n",
      " 3341 5934 1944  950 6015 1156  844 6024 5490 7196 1141 6681 3832    1    0\n",
      "    0    0    0]\n",
      "    dec input           > thanks for the reply i found it on her desk what s the name of the organization that would have sent the form in ? about it i was wondering whether a prior temp might have sent them in please let me know <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 2881  208 3537  439 4796 6806 1654  413 2040 2826 2255  208 4017 5505\n",
      "  208 4223 4786 4371 1156  844  208 6271 5490 2222 4742 6806  439 6628  125\n",
      " 3341 5934 1944  950 6015 1156  844 6024 5490 7196 1141 6681 3832    1    1\n",
      "    0    0    0    0]\n",
      "    dec train predicted > thanks for the reply i found it on her desk what s the name of the organization that would have sent the form in ? about it i was wondering whether a prior temp might have sent them in please let me know <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0109746238507\n",
      "global_step: 17375\n",
      "learning rate 0.000260595\n",
      "epoch 146\n",
      "batch 0\n",
      "training minibatch loss: 0.007377547677606344\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [3682 5014 5505 5404 1023  724 4533 4837    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > orig point of view ie deals and value <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 601 2545  290 2985 6681 5934 5404 1654 4673 2555 1023  724 4533 4837    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > guys can you give me a view on q earnings ie deals and value <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 601 2545  290 2985 6681 5934 5404 1654 4673 2555 1023  724 4533 4837    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > guys can you give me a view on q earnings ie deals and value <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00537035949248\n",
      "global_step: 17494\n",
      "learning rate 0.000258206\n",
      "epoch 147\n",
      "batch 0\n",
      "training minibatch loss: 0.007581143174320459\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [3193  200 2589 6568  175 6628 5934 1894 2146 2589 5253 5702 6378  208 5702\n",
      " 1728 1357 4695 5757 4533 4415 1728 5934 6378 5505    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > mike confirmed with natsource this was a mw deal with no broker fee the broker has as total mws and also has a fee of <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4155 3832 5505  208 4683  393 2986  208 4057 1255 2545  290  179 2390 1654\n",
      " 4786 3193  200 2589 6568  175 6628 5934 1894 2146 2589 5253 5702 6378  208\n",
      " 5702 1728 1357 4695 5757 4533 4415 1728 5934 6378 5505    1    0    0    0]\n",
      "    dec input           > luu know of the problem they entered the strips wrong can you pls check on that mike confirmed with natsource this was a mw deal with no broker fee the broker has as total mws and also has a fee of <EOS> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4155 3832 5505  208 4683  393 2986  208 4057 1255 2545  290  179 2390 1654\n",
      " 4786 3193  200 2589 6568  175 6628 5934 1894 2146 2589 5253 5702 6378  208\n",
      " 5702 1728 1357 4695 5757 4533 4415 1728 5934 6378 5505    1    1    0    0\n",
      "    0]\n",
      "    dec train predicted > luu know of the problem they entered the strips wrong can you pls check on that mike confirmed with natsource this was a mw deal with no broker fee the broker has as total mws and also has a fee of <EOS> <EOS> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00396634615385\n",
      "global_step: 17613\n",
      "learning rate 0.000255839\n",
      "epoch 148\n",
      "batch 0\n",
      "training minibatch loss: 0.0065942807123064995\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86  291 5520 5490 2222    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp person anybody in ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4371 4505 3033 5253 4784 4972 7196    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > would like tickets no phone calls please <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4371 4505 3033 5253 4784 4972 7196    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > would like tickets no phone calls please <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0096756815918\n",
      "global_step: 17732\n",
      "learning rate 0.000253493\n",
      "epoch 149\n",
      "batch 0\n",
      "training minibatch loss: 0.006716450676321983\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [6908 6583 5911 5467 4880 3837 3576   86 4786 4399 4243 7036 2110 1384 3974\n",
      " 6561 5577 2110 3499 6003 4481 5514 2637  592 1916 6261 5505 6506 5934 3676\n",
      " 2387 5911  208 2002 1384 2017 2826 4780  813  844 6024    1]\n",
      "    enc input           > sounds good so far enron north america corp that should work since our is being obviated by our advise via telephone x or email asap thanks of locating a conference room so the location is tbd what we last sent them <EOS>\n",
      "    dec input           > [5471 1384 5286 2222 4954  290   63 1344  818 4297 3499 6003 4481 5514 2637\n",
      "  592 1916 6261 5505 6506 5934 3676 2387 5911  208 2002 1384 2017 2826 4780\n",
      "  813  844 6024    1    0    0    0    0    0    0]\n",
      "    dec input           > who is jeffrey ? suggest you call him to confirm advise via telephone x or email asap thanks of locating a conference room so the location is tbd what we last sent them <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5471 1384 5286 2222 4954  290   63 1344  818 4297 3499 6003 4481 5514 2637\n",
      "  592 1916 6261 5505 6506 5934 3676 2387 5911  208 2002 1384 2017 2826 4780\n",
      "  813  844 6024    1    1    0    0    0    0    0    0]\n",
      "    dec train predicted > who is jeffrey ? suggest you call him to confirm advise via telephone x or email asap thanks of locating a conference room so the location is tbd what we last sent them <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0009765625\n",
      "global_step: 17851\n",
      "learning rate 0.000251169\n",
      "epoch 150\n",
      "batch 0\n",
      "training minibatch loss: 0.006194181274622679\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2365 2365 1550 4880   86    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > pm pm successful enron corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6507 1384 3867  595 5984 4786 3867 1648 5265 6548 1821 1384 6507 1678 1821\n",
      " 2637 6826  393 6799 1597 2222 2365 2365 1550 4880   86    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > john is important but not that important he will come here is john coming here or are they going there ? pm pm successful enron corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6507 1384 3867  595 5984 4786 3867 1648 5265 6548 1821 1384 6507 1678 1821\n",
      " 2637 6826  393 6799 1597 2222 2365 2365 1550 4880   86    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > john is important but not that important he will come here is john coming here or are they going there ? pm pm successful enron corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00482434640523\n",
      "global_step: 17970\n",
      "learning rate 0.000248866\n",
      "epoch 151\n",
      "batch 0\n",
      "training minibatch loss: 0.007741657551378012\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 1156 5934 5775 4399  208 6467 1654  175 3619 3249 4311 1437 2222    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i have a question should the counterparty on this trade be peco energy ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6806 2146 6261 5934 4171 2881 4526   39  625  439 1156 5934 5775 4399  208\n",
      " 6467 1654  175 3619 3249 4311 1437 2222    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > it deal thanks a lot for your patience stephanie i have a question should the counterparty on this trade be peco energy ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6806 2146 6261 5934 4171 2881 4526   39  625  439 1156 5934 5775 4399  208\n",
      " 6467 1654  175 3619 3249 4311 1437 2222    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > it deal thanks a lot for your patience stephanie i have a question should the counterparty on this trade be peco energy ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.998724489796\n",
      "0.01617886716\n",
      "global_step: 18089\n",
      "learning rate 0.000246585\n",
      "epoch 152\n",
      "batch 0\n",
      "training minibatch loss: 0.007959170266985893\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1821  290  464  175 1384  208 7007 3561 4780 3783 1357 5505 1141 6681 3832\n",
      " 5075  290 1156 1397 2228 4786  290  844  813  434 1384 4987  175 1384 2826\n",
      " 2110 3711 4399 3249    1    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > here you go this is the p l we reported as of let me know if you have any questions that you sent last month is fine this is what our income should be <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4082 4371  290 3249  306  818 5036 6681  208 5364 2881 2498  289 1821  290\n",
      "  464  175 1384  208 7007 3561 4780 3783 1357 5505 1141 6681 3832 5075  290\n",
      " 1156 1397 2228 4786  290  844  813  434 1384 4987  175 1384 2826 2110 3711\n",
      " 4399 3249    1]\n",
      "    dec input           > robin would you be able to send me the file for feb th here you go this is the p l we reported as of let me know if you have any questions that you sent last month is fine this is what our income should be <EOS>\n",
      "    dec train predicted > [4082 4371  290 3249  306  818 5036 6681  208 5364 2881 2498  289 1821  290\n",
      "  464  175 1384  208 7007 3561 4780 3783 1357 5505 1141 6681 3832 5075  290\n",
      " 1156 1397 2228 4786  290  844  813  434 1384 4987  175 1384 2826 2110 3711\n",
      " 4399 3249    1    1]\n",
      "    dec train predicted > robin would you be able to send me the file for feb th here you go this is the p l we reported as of let me know if you have any questions that you sent last month is fine this is what our income should be <EOS> <EOS>\n",
      "0.96875\n",
      "0.0111979166667\n",
      "global_step: 18208\n",
      "learning rate 0.000244324\n",
      "epoch 153\n",
      "batch 0\n",
      "training minibatch loss: 0.006949873641133308\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3832 5190  439 4170 2826  208 5091  331 5014 1384 1384  993 6806 1384 4278\n",
      " 4880 1435 6736 4942    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    enc input           > know when i hear what the correct delivery point is is saying it is cob enron power marketing inc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 2881  208 6363 3749    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > thanks for the explanation diana <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 2881  208 6363 3749    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > thanks for the explanation diana <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.985012755102\n",
      "0.0122767857143\n",
      "global_step: 18327\n",
      "learning rate 0.000242084\n",
      "epoch 154\n",
      "batch 0\n",
      "training minibatch loss: 0.006152019836008549\n",
      "  sample 1:\n",
      "    Index 102\n",
      "    enc input           > [1641 2426    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > thnx again <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 1475    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks kristin <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 1475    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > thanks kristin <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.001953125\n",
      "global_step: 18446\n",
      "learning rate 0.000239865\n",
      "epoch 155\n",
      "batch 0\n",
      "training minibatch loss: 0.006395817268639803\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [5364 5815 2589 1397 2228 6261    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > file shout with any questions thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4780 5265  803  175 3512  818  208 2040 4801  136 2388 5541 5364 5815 2589\n",
      " 1397 2228 6261    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > we will take this variance to the desk then didn t happen file shout with any questions thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4780 5265  803  175 3512  818  208 2040 4801  136 2388 5541 5364 5815 2589\n",
      " 1397 2228 6261    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > we will take this variance to the desk then didn t happen file shout with any questions thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0127055889924\n",
      "global_step: 18565\n",
      "learning rate 0.000237666\n",
      "epoch 156\n",
      "batch 0\n",
      "training minibatch loss: 0.0061551714316010475\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [4671 1728 4149   92 4098 3277  724 6818 4399 3249 5490 6115    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > bob has just finished inputting his deals these should be in now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6628 1747 2589 6824  439 4149 3708 6806 6628 2589 2919 4786 2255 3708 1357\n",
      " 4394 6996  595 5984  208 3969 4168 4639 4399 3249 2881 6824 2222 3997 6826\n",
      "  211 5253 5702  439 4952 4639 2589 6824    1    0    0    0]\n",
      "    dec input           > was done with apb i just changed it was with prebon that s changed as well side but not the other which one should be for apb ? both are under no broker i show one with apb <EOS> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6628 1747 2589 6824  439 4149 3708 6806 6628 2589 2919 4786 2255 3708 1357\n",
      " 4394 6996  595 5984  208 3969 4168 4639 4399 3249 2881 6824 2222 3997 6826\n",
      "  211 5253 5702  439 4952 4639 2589 6824    1    1    0    0    0]\n",
      "    dec train predicted > was done with apb i just changed it was with prebon that s changed as well side but not the other which one should be for apb ? both are under no broker i show one with apb <EOS> <EOS> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0014880952381\n",
      "global_step: 18684\n",
      "learning rate 0.000235487\n",
      "epoch 157\n",
      "batch 0\n",
      "training minibatch loss: 0.005797339137643576\n",
      "  sample 1:\n",
      "    Index 218\n",
      "    enc input           > [4361 2255  208 5740 1329 2222 2826 6412  290 6412 2589 1874 5490  208  124\n",
      " 6115 2222 5934 4171 2222 1923 4780 2545  464  818 3601 2255 3421 1306    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > how s the new job ? what do you do with yourself in the evenings now ? a lot ? maybe we can go to barnaby s next week <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7055 5934 7163 5505 2386 3289 3663 5934 3307 4533 2985 6681  208 3005    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > suffering a bit of jet lag drop a note and give me the dirt <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7055 5934 7163 5505 2386 3289 3663 5934 3307 4533 2985 6681  208 3005    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > suffering a bit of jet lag drop a note and give me the dirt <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0094090925844\n",
      "global_step: 18803\n",
      "learning rate 0.000233328\n",
      "epoch 158\n",
      "batch 0\n",
      "training minibatch loss: 0.011731395497918129\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 5265  626  818 4705 5915 5075 5984 1384 1349 1557 6042 2222 1210 2255\n",
      " 3808 2274  818 5934 6758 4533 4371  123 4999 6806    1    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > i will try to get tomorrow if not is another day okay ? she s never been to a game and would really appreciate it <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6507 1397 1557 4371 3249 4872    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > john any day would be great <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6507 1397 1557 4371 3249 4872    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > john any day would be great <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.935281385281\n",
      "0.00848214285714\n",
      "global_step: 18922\n",
      "learning rate 0.000231189\n",
      "epoch 159\n",
      "batch 0\n",
      "training minibatch loss: 0.006513051688671112\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4361 4742  500 6232 2223 2881 6346 2222 2222 6412 4780 1001 1200  175 2426\n",
      " 1141 6681 3832 5518 5491    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > how about monday jan st for dinner ? ? do we dare start this again let me know some dates <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3665 6983  818 3102  290 4533 6508 4800 5505  208 1813 3476 4243 1141 6681\n",
      " 3832    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > look forward to seeing you and scott direction of the galeria after work let me know <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3665 6983  818 3102  290 4533 6508 4800 5505  208 1813 3476 4243 1141 6681\n",
      " 3832    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > look forward to seeing you and scott direction of the galeria after work let me know <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0125069630125\n",
      "global_step: 19041\n",
      "learning rate 0.000229069\n",
      "epoch 160\n",
      "batch 0\n",
      "training minibatch loss: 0.009193114936351776\n",
      "  sample 1:\n",
      "    Index 424\n",
      "    enc input           > [6261  290 6792  208 5563    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > thanks you re the best <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6654 6806 5265 1156  818 3002  439 5265 3249  857 5490 1521 1906    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > dan it will have to wait i will be back in early january <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6654 6806 5265 1156  818 3002  439 5265 3249  857 5490 1521 1906    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > dan it will have to wait i will be back in early january <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00612983655\n",
      "global_step: 19160\n",
      "learning rate 0.000226969\n",
      "epoch 161\n",
      "batch 0\n",
      "training minibatch loss: 0.014416531659662724\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [5471 1384 2401  175 2222 6736 4942 5577 3752 5564 1654 7196 3499 5075 5984\n",
      " 1621 5106 5384 1557    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > who is handling this ? marketing inc by regular mail on please advise if not received within business day <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5791  818 5664 2813 3162 6784 5577 5504  274 1654 7196 3499 5075  290 6412\n",
      " 5984 3017 5106 5384 1557 1165  290    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > demand to houston pipe line company by process server on please advise if you do not receive within business day thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5791  818 5664 2813 3162 6784 5577 5504  274 1654 7196 3499 5075  290 6412\n",
      " 5984 3017 5106 5384 1557 1165  290    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > demand to houston pipe line company by process server on please advise if you do not receive within business day thank you <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.994791666667\n",
      "0.00619882366509\n",
      "global_step: 19279\n",
      "learning rate 0.000224888\n",
      "epoch 162\n",
      "batch 0\n",
      "training minibatch loss: 0.006433616857975721\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6818 3665 6701  818 6681  856 1165  290    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > these look ok to me documents thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1821 6826 5518 1521 2579  439 7190 1654 6818 3665 6701  818 6681  856 1165\n",
      "  290    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > here are some early drafts i worked on these look ok to me documents thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1821 6826 5518 1521 2579  439 7190 1654 6818 3665 6701  818 6681  856 1165\n",
      "  290    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > here are some early drafts i worked on these look ok to me documents thank you <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0128235479798\n",
      "global_step: 19398\n",
      "learning rate 0.000222826\n",
      "epoch 163\n",
      "batch 0\n",
      "training minibatch loss: 0.006456603761762381\n",
      "  sample 1:\n",
      "    Index 658\n",
      "    enc input           > [1331 5750    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > internally today <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5471 5893 1384 6799  818 1855 4533 2826 1069 2222 6826  290 6799  818 3249\n",
      " 2132  208 6758 2745 2222    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > who all is going to sierra and what time ? are you going to be at the game tonight ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5471 5893 1384 6799  818 1855 4533 2826 1069 2222 6826  290 6799  818 3249\n",
      " 2132  208 6758 2745 2222    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > who all is going to sierra and what time ? are you going to be at the game tonight ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.998611111111\n",
      "0.0130272952854\n",
      "global_step: 19517\n",
      "learning rate 0.000220783\n",
      "epoch 164\n",
      "batch 0\n",
      "training minibatch loss: 0.005343653727322817\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [5939 5687  875 4090 5939 1199 5325 7027 5640 5490 1558  818  803 1824 5505\n",
      " 1397 6692 3721 4990  208 3421 6500 1654 2110 6048 4885 5326 4533 2729 6834\n",
      " 2748 2881 3136 5198 6021 5810 4533 4331 2589 1686 4533 1950 1654 4697 1357\n",
      " 4394    1]\n",
      "    enc input           > strong comments against continued strong crude oil prices built in options to take advantage of any sudden market changes the next days on our system rapid growth and clever insights rotterdam for similar period panamaxes routes and traded with jinhui and conagra on panaamxes as well <EOS>\n",
      "    dec input           > [ 979  164 2705 3860 3421 6895 2637 6327  164 2110 6445  818 4164 2881 4673\n",
      " 5707 2784  818  208 2236    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > pananamx cargoes world wide next year or panamax cargoes our option to glencore for q from rbct to the uk <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 979  164 2705 3860 3421 6895 2637 6327  164 2110 6445  818 4164 2881 4673\n",
      " 5707 2784  818  208 2236    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > pananamx cargoes world wide next year or panamax cargoes our option to glencore for q from rbct to the uk <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00431779358017\n",
      "global_step: 19636\n",
      "learning rate 0.000218759\n",
      "epoch 165\n",
      "batch 0\n",
      "training minibatch loss: 0.005353786516934633\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [  63 6681 5075  290 1156 1397 2884 2228    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > call me if you have any further questions <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2204 3307 7142  818   56 1223 5803 1654  490 6314 7196 4297 4786  208 4515\n",
      "  439  308 6826 6950  290 7142  818  851 4515 1654  208 6119  759  818 4597\n",
      " 2222 4394 7196   63 6681 2132 6872  208 5952    1    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > promissory note wish to impose burdensome obligations on emw provision please confirm that the limitations i included are acceptable you wish to place limitations on the lenders right to assign ? well please call me at regarding the foregoing <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2204 3307 7142  818   56 1223 5803 1654  490 6314 7196 4297 4786  208 4515\n",
      "  439  308 6826 6950  290 7142  818  851 4515 1654  208 6119  759  818 4597\n",
      " 2222 4394 7196   63 6681 2132 6872  208 5952    1    1    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > promissory note wish to impose burdensome obligations on emw provision please confirm that the limitations i included are acceptable you wish to place limitations on the lenders right to assign ? well please call me at regarding the foregoing <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00676039646628\n",
      "global_step: 19755\n",
      "learning rate 0.000216754\n",
      "epoch 166\n",
      "batch 0\n",
      "training minibatch loss: 0.004537550732493401\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4786 2255 4987  464 2385 4533 3329  208 2146 5075  290  516  818    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > that s fine go ahead and change the deal if you need to <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2594 1357 6595 5978 2594 2110 2160  818 2143 2589 5978    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > adjust as necessary vintage adjust our nom to tie with vintage <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2594 1357 6595 5978 2594 2110 2160  818 2143 2589 5978    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > adjust as necessary vintage adjust our nom to tie with vintage <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00383139155052\n",
      "global_step: 19874\n",
      "learning rate 0.000214766\n",
      "epoch 167\n",
      "batch 0\n",
      "training minibatch loss: 0.004704100079834461\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6469 1384 5961  884 6815  953 5750  963 2222 5240 4505 4780  516 4639 5327\n",
      " 5075 3723 4745 4567 1739  290    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > everything is addressed before filing beginning today estimate ? seems like we need one even if its still very speculative you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 884 5490 5499 5505 6815 5075 5911 4361 1930 4780  464 4742 6806 2222  489\n",
      " 3676 2589 2060 2222 6469 1384 5961  884 6815  953 5750  963 2222 5240 4505\n",
      " 4780  516 4639 5327 5075 3723 4745 4567 1739  290    1    0    0    0    0]\n",
      "    dec input           > before in advance of filing if so how did we go about it ? prefiling conference with ferc ? everything is addressed before filing beginning today estimate ? seems like we need one even if its still very speculative you <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 884 5490 5499 5505 6815 5075 5911 4361 1930 4780  464 4742 6806 2222  489\n",
      " 3676 2589 2060 2222 6469 1384 5961  884 6815  953 5750  963 2222 5240 4505\n",
      " 4780  516 4639 5327 5075 3723 4745 4567 1739  290    1    1    0    0    0\n",
      "    0]\n",
      "    dec train predicted > before in advance of filing if so how did we go about it ? prefiling conference with ferc ? everything is addressed before filing beginning today estimate ? seems like we need one even if its still very speculative you <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "0.998611111111\n",
      "0.0208333333333\n",
      "global_step: 19993\n",
      "learning rate 0.000212797\n",
      "epoch 168\n",
      "batch 0\n",
      "training minibatch loss: 0.00473555875942111\n",
      "  sample 1:\n",
      "    Index 5\n",
      "    enc input           > [2589 1357 1582 1357 3069 2132 4941  818  208 2295 1397 3969 6742 2222 3706\n",
      " 1397 1651 1285  516  818 3249   34  818 1760  175 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > with as many as possible at once to the reports any other ideas ? does any formal documentation need to be prepared to accomplish this ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2973  818 4705 4639  748 6289  208  818 6412 4136 6908 4505  290 1156 5934\n",
      " 6583  259    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > anything to get one thing off the to do list sounds like you have a good plan <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2973  818 4705 4639  748 6289  208  818 6412 4136 6908 4505  290 1156 5934\n",
      " 6583  259    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > anything to get one thing off the to do list sounds like you have a good plan <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999335106383\n",
      "0.0\n",
      "global_step: 20112\n",
      "learning rate 0.000210846\n",
      "epoch 169\n",
      "batch 0\n",
      "training minibatch loss: 0.004586044233292341\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3447 3619 4536   86 5226 1624 5308  393 5265 3249 6386 6818  818 5674\n",
      " 5915    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron capital trade resources corp weeks ago however they will be sending these to us tomorrow <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3447 3619 4536   86 4058  884 4801 4880 3447 3619 4536   86 5226 1624\n",
      " 5308  393 5265 3249 6386 6818  818 5674 5915    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > enron capital trade resources corp response before then enron capital trade resources corp weeks ago however they will be sending these to us tomorrow <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3447 3619 4536   86 4058  884 4801 4880 3447 3619 4536   86 5226 1624\n",
      " 5308  393 5265 3249 6386 6818  818 5674 5915    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > enron capital trade resources corp response before then enron capital trade resources corp weeks ago however they will be sending these to us tomorrow <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998579545455\n",
      "0.00734308226496\n",
      "global_step: 20231\n",
      "learning rate 0.000208913\n",
      "epoch 170\n",
      "batch 0\n",
      "training minibatch loss: 0.005713061895221472\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1930  208 2146 2589 2222    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > did the deal with ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3211 4971 1930  208 2146 2589 2222 6261    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > wholesale transaction did the deal with ? thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3211 4971 1930  208 2146 2589 2222 6261    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > wholesale transaction did the deal with ? thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.96875\n",
      "0.0101413753907\n",
      "global_step: 20350\n",
      "learning rate 0.000206998\n",
      "epoch 171\n",
      "batch 0\n",
      "training minibatch loss: 0.0046239555813372135\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5812  439 2006 1030  208 3828 4971 7196 3499 5505 1397 5687 6261 5893 3462\n",
      " 5505  208 1415    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > fyi i m reviewing the salmon transaction please advise of any comments thanks all copies of the message <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5005  439 4170  439 4399 1156  844  175  818  290 5812  439 2006 1030  208\n",
      " 3828 4971 7196 3499 5505 1397 5687 6261 5893 3462 5505  208 1415    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > opps i hear i should have sent this to you fyi i m reviewing the salmon transaction please advise of any comments thanks all copies of the message <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5005  439 4170  439 4399 1156  844  175  818  290 5812  439 2006 1030  208\n",
      " 3828 4971 7196 3499 5505 1397 5687 6261 5893 3462 5505  208 1415    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > opps i hear i should have sent this to you fyi i m reviewing the salmon transaction please advise of any comments thanks all copies of the message <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999335106383\n",
      "0.0103856646825\n",
      "global_step: 20469\n",
      "learning rate 0.0002051\n",
      "epoch 172\n",
      "batch 0\n",
      "training minibatch loss: 0.005100178997963667\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4533 6983  818 1397  439 2575    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > and forward to any i missed <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 836 5075 1269 5505  290 1156 2274 5934 3956 5505  208 3043 2057 2345 4124\n",
      " 2198 4371 1604 2132   98 1414    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > sure if either of you have been a part of the test information lateral firm capacity would remain at mmcf d <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 836 5075 1269 5505  290 1156 2274 5934 3956 5505  208 3043 2057 2345 4124\n",
      " 2198 4371 1604 2132   98 1414    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > sure if either of you have been a part of the test information lateral firm capacity would remain at mmcf d <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.989234524975\n",
      "0.0108506944444\n",
      "global_step: 20588\n",
      "learning rate 0.00020322\n",
      "epoch 173\n",
      "batch 0\n",
      "training minibatch loss: 0.004718910437077284\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2637 6369 2066 6826 6595  818 1760  175 2917 6878 2222 6728   36    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > or systems enhancements are necessary to accomplish this end result ? population efforts <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 4536 1654 1913 2222  439 4649 2418 5700 1654  208 3970\n",
      " 2228 7196 6616 4880 3837 3576   86 2637 6369 2066 6826 6595  818 1760  175\n",
      " 2917 6878 2222 6728   36    1    0    0    0    0    0    0    0    0]\n",
      "    dec input           > enron north america corp resources on gcp ? i am getting hammered on the exposure questions please help enron north america corp or systems enhancements are necessary to accomplish this end result ? population efforts <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 4536 1654 1913 2222  439 4649 2418 5700 1654  208 3970\n",
      " 2228 7196 6616 4880 3837 3576   86 2637 6369 2066 6826 6595  818 1760  175\n",
      " 2917 6878 2222 6728   36    1    1    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > enron north america corp resources on gcp ? i am getting hammered on the exposure questions please help enron north america corp or systems enhancements are necessary to accomplish this end result ? population efforts <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.981774682804\n",
      "0.0218916933761\n",
      "global_step: 20707\n",
      "learning rate 0.000201357\n",
      "epoch 174\n",
      "batch 0\n",
      "training minibatch loss: 0.004202111158519983\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7196   48 6806 1654 2546 6126 2110 4072 5856 5265 3249 7132 1906 2132 2365\n",
      " 5490 5994    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > please put it on my schedule our first meeting will be tuesday january at pm in eb <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 748 3455 2110 4072 5856 5265 3249 7132 1906 2132 2365 5490 5994    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > thing too our first meeting will be tuesday january at pm in eb <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 748 3455 2110 4072 5856 5265 3249 7132 1906 2132 2365 5490 5994    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > thing too our first meeting will be tuesday january at pm in eb <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998086734694\n",
      "0.00549564270153\n",
      "global_step: 20826\n",
      "learning rate 0.000199511\n",
      "epoch 175\n",
      "batch 0\n",
      "training minibatch loss: 0.007184911053627729\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86  290 1156 1397 2228 4742  208 2057 2564 5490  208 3081\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp you have any questions about the information contained in the database <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86 4880 3837 3576   86  290 1156 1397 2228 4742  208 2057\n",
      " 2564 5490  208 3081    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > enron north america corp enron north america corp you have any questions about the information contained in the database <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86 4880 3837 3576   86  290 1156 1397 2228 4742  208 2057\n",
      " 2564 5490  208 3081    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > enron north america corp enron north america corp you have any questions about the information contained in the database <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.983324230623\n",
      "0.027827480424\n",
      "global_step: 20945\n",
      "learning rate 0.000197682\n",
      "epoch 176\n",
      "batch 0\n",
      "training minibatch loss: 0.0038106527645140886\n",
      "  sample 1:\n",
      "    Index 4\n",
      "    enc input           > [6261  290 5287  601 2545 3185 4072 4415    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > thanks you smart guys can finish first also <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 1141 2255  464  279 4639 3312 4533 1156 5934 3370 5535  818 1108  175\n",
      " 6864 3124    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > thanks let s go out one night and have a few drinks to celebrate this sometime tony <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 1141 2255  464  279 4639 3312 4533 1156 5934 3370 5535  818 1108  175\n",
      " 6864 3124    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > thanks let s go out one night and have a few drinks to celebrate this sometime tony <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00100806451613\n",
      "global_step: 21064\n",
      "learning rate 0.000195869\n",
      "epoch 177\n",
      "batch 0\n",
      "training minibatch loss: 0.003340618684887886\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5617  136 2388 2613  818 1116  290 4880 3837 3576   86  818 4961 2222    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > sorry didn t mean to forget you enron north america corp to ge ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4786  175 1384 3493 2255  212 5911  439 2006 6386 1344 5934  481 5075 6806\n",
      " 2642 6701  818  290  439 5265 5551 6806 3887 4533 5036 6806  818 4961 2881\n",
      "  985 2720 4880 3837 3576   86  818 4961 2222    1    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > that this is dale s project so i m sending him a copy if it looks ok to you i will clean it up and send it to ge for their review enron north america corp to ge ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4786  175 1384 3493 2255  212 5911  439 2006 6386 1344 5934  481 5075 6806\n",
      " 2642 6701  818  290  439 5265 5551 6806 3887 4533 5036 6806  818 4961 2881\n",
      "  985 2720 4880 3837 3576   86  818 4961 2222    1    1    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > that this is dale s project so i m sending him a copy if it looks ok to you i will clean it up and send it to ge for their review enron north america corp to ge ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.99266870471\n",
      "0.00838913690476\n",
      "global_step: 21183\n",
      "learning rate 0.000194074\n",
      "epoch 178\n",
      "batch 0\n",
      "training minibatch loss: 0.0034039290621876717\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6254 5893 1384 4394 4533   63 1234 4168 1210 2545 4705 5707 2110 1285 1974\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > hope all is well and call confirmation which she can get from our documentation group <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 290 4705  857  818  208 2315 2222  289    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > you get back to the office ? th <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 290 4705  857  818  208 2315 2222  289    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > you get back to the office ? th <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0159884029369\n",
      "global_step: 21302\n",
      "learning rate 0.000192294\n",
      "epoch 179\n",
      "batch 0\n",
      "training minibatch loss: 0.004196376074105501\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [4134  875  208 4828 2373 2579    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > marked against the most recent drafts <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1384 4635 6386  290 6818 2637 6826  290 1654 5934 2081 5564 2222 4134  875\n",
      "  208 4828 2373 2579    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > is mark sending you these or are you on a direct mail ? marked against the most recent drafts <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1384 4635 6386  290 6818 2637 6826  290 1654 5934 2081 5564 2222 4134  875\n",
      "  208 4828 2373 2579    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > is mark sending you these or are you on a direct mail ? marked against the most recent drafts <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996173469388\n",
      "0.00486111111111\n",
      "global_step: 21421\n",
      "learning rate 0.000190531\n",
      "epoch 180\n",
      "batch 0\n",
      "training minibatch loss: 0.0034294931683689356\n",
      "  sample 1:\n",
      "    Index 629\n",
      "    enc input           > [5183 4639 2088  434  818  464    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > only one more month to go <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196 2230 2388  439 6756  208  431  439 6628 4149 4666 6799 6983  420    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > please don t i enjoy the laughter i was just jealous going forward basis <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196 2230 2388  439 6756  208  431  439 6628 4149 4666 6799 6983  420    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > please don t i enjoy the laughter i was just jealous going forward basis <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0287212481146\n",
      "global_step: 21540\n",
      "learning rate 0.000188785\n",
      "epoch 181\n",
      "batch 0\n",
      "training minibatch loss: 0.0032657382544130087\n",
      "  sample 1:\n",
      "    Index 598\n",
      "    enc input           > [6825  593 5707 1344    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > notch sound from him <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 3832 6806 5240 1357 4110  764 3354 1384 5490 4130 5911  572  208 3311\n",
      " 4009 6799 2222    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > i know it seems as though mr rudy is in love so damned the consequences application going ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 3832 6806 5240 1357 4110  764 3354 1384 5490 4130 5911  572  208 3311\n",
      " 4009 6799 2222    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > i know it seems as though mr rudy is in love so damned the consequences application going ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0122992443716\n",
      "global_step: 21659\n",
      "learning rate 0.000187054\n",
      "epoch 182\n",
      "batch 0\n",
      "training minibatch loss: 0.009933032095432281\n",
      "  sample 1:\n",
      "    Index 21\n",
      "    enc input           > [4880 3837 3576   86 5490  208 4596 5505  208 4880 2096    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp in the lobby of the enron building <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261  500 1384 6583 2881 6681 4880 3837 3576   86    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks monday is good for me enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261  500 1384 6583 2881 6681 4880 3837 3576   86    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > thanks monday is good for me enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.990451388889\n",
      "0.00344202898551\n",
      "global_step: 21778\n",
      "learning rate 0.000185339\n",
      "epoch 183\n",
      "batch 0\n",
      "training minibatch loss: 0.0037367609329521656\n",
      "  sample 1:\n",
      "    Index 449\n",
      "    enc input           > [3997  290 1156  818 7085 5893 4526  971    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > both you have to schd all your trades <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5190 6107 2238  857    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > when jeff gets back <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5190 6107 2238  857    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > when jeff gets back <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00470994008532\n",
      "global_step: 21897\n",
      "learning rate 0.00018364\n",
      "epoch 184\n",
      "batch 0\n",
      "training minibatch loss: 0.0068808188661932945\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4526 6616 6261 2881 4526 6616    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > your help thanks for your help <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 5911  703  439 1179 5638  175 7031  818  208 4393 2103  595 4780 5265\n",
      " 5984 1156  818 5649 4374 6254  175 4569 4526 6616 6261 2881 4526 6616    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks so much i ll pass this along to the traders pinnacle but we will not have to revise confirms hope this helps your help thanks for your help <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 5911  703  439 1179 5638  175 7031  818  208 4393 2103  595 4780 5265\n",
      " 5984 1156  818 5649 4374 6254  175 4569 4526 6616 6261 2881 4526 6616    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > thanks so much i ll pass this along to the traders pinnacle but we will not have to revise confirms hope this helps your help thanks for your help <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950892857143\n",
      "0.00642163825758\n",
      "global_step: 22016\n",
      "learning rate 0.000181956\n",
      "epoch 185\n",
      "batch 0\n",
      "training minibatch loss: 0.004418423864990473\n",
      "  sample 1:\n",
      "    Index 12\n",
      "    enc input           > [ 367 4136 6261 4786  439 4649 5740 5490  175 5623 6261 6773 5385    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > interviewer list thanks that i am new in this role thanks bonnie nelson <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3160 6154 6261 2881  657  175 2881 6681  439 2006 4745 5934 2557    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > rob walls thanks for doing this for me i m still a hostage <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3160 6154 6261 2881  657  175 2881 6681  439 2006 4745 5934 2557    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > rob walls thanks for doing this for me i m still a hostage <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.978698979592\n",
      "0.013353005676\n",
      "global_step: 22135\n",
      "learning rate 0.000180288\n",
      "epoch 186\n",
      "batch 0\n",
      "training minibatch loss: 0.00388948037289083\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [1384  175 5091 2222    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > is this correct ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6412  290 1156 3431  361 1529 1654  175 3291 2222 6261 3476  393 2883 3887\n",
      "  208 2002 4801 4780 2545 1235  208 3000 4399 3249 6274 1864 2658 7196 5815\n",
      " 2589 1397 2228 6261 2881 4526 6616  734 2498    1    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > do you have an updated status on this issue ? thanks after they set up the location then we can map the curves should be ngi chi nipsco please shout with any questions thanks for your help effective feb <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6412  290 1156 3431  361 1529 1654  175 3291 2222 6261 3476  393 2883 3887\n",
      "  208 2002 4801 4780 2545 1235  208 3000 4399 3249 6274 1864 2658 7196 5815\n",
      " 2589 1397 2228 6261 2881 4526 6616  734 2498    1    1    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > do you have an updated status on this issue ? thanks after they set up the location then we can map the curves should be ngi chi nipsco please shout with any questions thanks for your help effective feb <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00773041474654\n",
      "global_step: 22254\n",
      "learning rate 0.000178635\n",
      "epoch 187\n",
      "batch 0\n",
      "training minibatch loss: 0.004066655412316322\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3614 1654  244 6291    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > working on thei sheet <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 192 4415  208 4338 4533 2197  192 6826 3895 4533  208 6729  192 6826 6980\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > volumes also the tetco and trco volumes are monthly and the cgas volumes are daily <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 192 4415  208 4338 4533 2197  192 6826 3895 4533  208 6729  192 6826 6980\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > volumes also the tetco and trco volumes are monthly and the cgas volumes are daily <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.998086734694\n",
      "0.00257759353741\n",
      "global_step: 22373\n",
      "learning rate 0.000176997\n",
      "epoch 188\n",
      "batch 0\n",
      "training minibatch loss: 0.003430595388635993\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3832 1141 6681 3832 5075  290 1156 1397 2884 1650 2589 6818  724    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > know let me know if you have any further discrepancies with these deals <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 208 5091 3692 5505 5183 5218 5505 6261 3832 1141 6681 3832 5075  290 1156\n",
      " 1397 2884 1650 2589 6818  724    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > the correct term of only instead of thanks know let me know if you have any further discrepancies with these deals <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 208 5091 3692 5505 5183 5218 5505 6261 3832 1141 6681 3832 5075  290 1156\n",
      " 1397 2884 1650 2589 6818  724    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > the correct term of only instead of thanks know let me know if you have any further discrepancies with these deals <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00946687113174\n",
      "global_step: 22492\n",
      "learning rate 0.000175374\n",
      "epoch 189\n",
      "batch 0\n",
      "training minibatch loss: 0.0074179647490382195\n",
      "  sample 1:\n",
      "    Index 465\n",
      "    enc input           > [3872 2255 2040 1171 2881 6024  818 6362 6681 4533 4705 6289  208 4784    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > someone s desk waiting for them to see me and get off the phone <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5586 2088  818 2110 3938 4819  818 3193 2255 7118 2255 2637 4600 1925 3277\n",
      " 1601 1654  208 5441 3676   63    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > considerably more to our thinking than to mike s roger s or stoness encourage his participation on the scheduled conference call <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5586 2088  818 2110 3938 4819  818 3193 2255 7118 2255 2637 4600 1925 3277\n",
      " 1601 1654  208 5441 3676   63    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > considerably more to our thinking than to mike s roger s or stoness encourage his participation on the scheduled conference call <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992456896552\n",
      "0.0055010497416\n",
      "global_step: 22611\n",
      "learning rate 0.000173767\n",
      "epoch 190\n",
      "batch 0\n",
      "training minibatch loss: 0.003140981774777174\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 5265   63  290 3588 5655  290 7196 1450 5564  818 6681  208 3464 1061\n",
      " 2222    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i will call you later could you please e mail to me the credit worksheet ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 208 3464 1061 1357 5518 5505  208 6106 6850 1218 7196 3499    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > the credit worksheet as some of the numbers were different please advise <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 208 3464 1061 1357 5518 5505  208 6106 6850 1218 7196 3499    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > the credit worksheet as some of the numbers were different please advise <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0115953307921\n",
      "global_step: 22730\n",
      "learning rate 0.000172174\n",
      "epoch 191\n",
      "batch 0\n",
      "training minibatch loss: 0.004104773048311472\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 836 6873  208  217 5984 4880 3447 3619 4536   86 7131 2132  842 2255 1654\n",
      " 5801 1473    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > sure why the heck not enron capital trade resources corp honor at teala s on w dallas <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5750 2222 6179 1384  175  851 2222 4880 3837 3576   86    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > today ? where is this place ? enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5750 2222 6179 1384  175  851 2222 4880 3837 3576   86    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > today ? where is this place ? enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.964900914634\n",
      "0.00541125541126\n",
      "global_step: 22849\n",
      "learning rate 0.000170595\n",
      "epoch 192\n",
      "batch 0\n",
      "training minibatch loss: 0.00285541545599699\n",
      "  sample 1:\n",
      "    Index 332\n",
      "    enc input           > [6826  279 2222    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > are out ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5984  818 1156 2546 1117  211  413 4017 1903    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > not to have my mistakes under her name anymore <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5984  818 1156 2546 1117  211  413 4017 1903    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > not to have my mistakes under her name anymore <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00582978219697\n",
      "global_step: 22968\n",
      "learning rate 0.000169031\n",
      "epoch 193\n",
      "batch 0\n",
      "training minibatch loss: 0.004983039572834969\n",
      "  sample 1:\n",
      "    Index 11\n",
      "    enc input           > [1647 5490 2546 1974    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > specialists in my group <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 595 4844 4621 2388 4952 4533  290 1156 6806 1957 4880 3837 3576   86    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > but yours doesn t show and you have it removed enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 595 4844 4621 2388 4952 4533  290 1156 6806 1957 4880 3837 3576   86    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > but yours doesn t show and you have it removed enron north america corp <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.977678571429\n",
      "0.00203518907563\n",
      "global_step: 23087\n",
      "learning rate 0.000167481\n",
      "epoch 194\n",
      "batch 0\n",
      "training minibatch loss: 0.0026463817339390516\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2245 4087 6126 5253 2623 2146 4149 2362  818 1141  290 3832 6184  818 1156\n",
      " 3261 3887 1357 4639 5505 4526  409    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > already loaded schedule no big deal just wanted to let you know surprised to have ended up as one of your reviewers <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6837 2255 1728  818 3249 1747 5577 6232    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > sherry s has to be done by jan <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6837 2255 1728  818 3249 1747 5577 6232    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > sherry s has to be done by jan <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00264756944444\n",
      "global_step: 23206\n",
      "learning rate 0.000165946\n",
      "epoch 195\n",
      "batch 0\n",
      "training minibatch loss: 0.004496516194194555\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [ 594 5490 1450 6772    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > degree in e commerce <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196  803 5934 3665 2132  208 3188  439 2732 5707 2546 3814 4249 6251 1874\n",
      " 2132 4880 5890 2589 4884 3386 2958 5490 3076 4671 4256 2261 5490  208 3521\n",
      " 5505 1437 3510    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > please take a look at the resume i got from my friend opportunity around yourself at enron corporation with albert friedberg laureate in economics bob merton research in the field of energy markets <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196  803 5934 3665 2132  208 3188  439 2732 5707 2546 3814 4249 6251 1874\n",
      " 2132 4880 5890 2589 4884 3386 2958 5490 3076 4671 4256 2261 5490  208 3521\n",
      " 5505 1437 3510    1    1    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > please take a look at the resume i got from my friend opportunity around yourself at enron corporation with albert friedberg laureate in economics bob merton research in the field of energy markets <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.947916666667\n",
      "0.00574448529412\n",
      "global_step: 23325\n",
      "learning rate 0.000164424\n",
      "epoch 196\n",
      "batch 0\n",
      "training minibatch loss: 0.002369810128584504\n",
      "  sample 1:\n",
      "    Index 130\n",
      "    enc input           > [6661 5073 2239 2110    7 2881 5674 6115 5911  439 2230 2388  516  175  113\n",
      " 6610    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > ryan watt runs our model for us now so i don t need this spreadsheet everyday <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1721 4533  439 1156 5934 4243 6346  818  464  818  595 4780 6826 1654  818\n",
      " 4705 4087 5915 5520 3887 2881 5934 6366 3476 4243 2222  439 2772  439 5265\n",
      " 4952 3887    1    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > bryan and i have a work dinner to go to but we are on to get loaded tomorrow anybody up for a beer after work ? i promise i will show up <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1721 4533  439 1156 5934 4243 6346  818  464  818  595 4780 6826 1654  818\n",
      " 4705 4087 5915 5520 3887 2881 5934 6366 3476 4243 2222  439 2772  439 5265\n",
      " 4952 3887    1    1    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > bryan and i have a work dinner to go to but we are on to get loaded tomorrow anybody up for a beer after work ? i promise i will show up <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00179893092105\n",
      "global_step: 23444\n",
      "learning rate 0.000162917\n",
      "epoch 197\n",
      "batch 0\n",
      "training minibatch loss: 0.0022556225303560495\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6616 6681  279 2222    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > help me out ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4860 1948 6681 3072 6629 4017 6616 6681  279 2222    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > flynn gave me zulie flores name help me out ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4860 1948 6681 3072 6629 4017 6616 6681  279 2222    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > flynn gave me zulie flores name help me out ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0129914630326\n",
      "global_step: 23563\n",
      "learning rate 0.000161423\n",
      "epoch 198\n",
      "batch 0\n",
      "training minibatch loss: 0.00201748451218009\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4786  208 6284 1654 6818 1384 2287  981 5984 5577  208 7098 2637 4710 3416\n",
      " 2132    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > that the quantity on these is per book not by the box or ruby kinsfather at <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196 3569 4645 2338 2881  208 2586 1974 4533 5934 3370  634 4880 3837 3576\n",
      "   86 4786  208 6284 1654 6818 1384 2287  981 5984 5577  208 7098 2637 4710\n",
      " 3416 2132    1    0    0    0    0    0    0    0    0]\n",
      "    dec input           > please order enough books for the swaps group and a few extras enron north america corp that the quantity on these is per book not by the box or ruby kinsfather at <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196 3569 4645 2338 2881  208 2586 1974 4533 5934 3370  634 4880 3837 3576\n",
      "   86 4786  208 6284 1654 6818 1384 2287  981 5984 5577  208 7098 2637 4710\n",
      " 3416 2132    1    1    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > please order enough books for the swaps group and a few extras enron north america corp that the quantity on these is per book not by the box or ruby kinsfather at <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0118790064103\n",
      "global_step: 23682\n",
      "learning rate 0.000159943\n",
      "epoch 199\n",
      "batch 0\n",
      "training minibatch loss: 0.002871148521080613\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4780 1156 5253  790 6412  290 5675  439  516  818 1858 5934   33 1368 2222\n",
      " 2110 4152 4365 5911 1821 6806 1384    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > we have no interest do you think i need to write a rejection letter ? our recruiting coordinator so here it is <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6703  439 5265 1141 2546 2660 3814 3832 6261 4780 1156 5253  790 6412  290\n",
      " 5675  439  516  818 1858 5934   33 1368 2222 2110 4152 4365 5911 1821 6806\n",
      " 1384    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > submittal i will let my associate friend know thanks we have no interest do you think i need to write a rejection letter ? our recruiting coordinator so here it is <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6703  439 5265 1141 2546 2660 3814 3832 6261 4780 1156 5253  790 6412  290\n",
      " 5675  439  516  818 1858 5934   33 1368 2222 2110 4152 4365 5911 1821 6806\n",
      " 1384    1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > submittal i will let my associate friend know thanks we have no interest do you think i need to write a rejection letter ? our recruiting coordinator so here it is <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n",
      "0.00685876623377\n",
      "global_step: 23801\n",
      "learning rate 0.000158477\n",
      "epoch 200\n",
      "batch 0\n",
      "training minibatch loss: 0.0019451319240033627\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86 2435  165 4533 2637 4243 2939 5426 6762 1357 4394    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > enron north america corp attorney client and or work product privileges case as well <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 734 4935 4745 2545 3249 7238 4371  290 7196 4333 4786 3329 4533  611 1714\n",
      " 2222 6261 4880 3837 3576   86 2435  165 4533 2637 4243 2939 5426 2637 6412\n",
      " 4780  516  818 6412 5934 6996 1368  818 4635 2222    1    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > effective date still can be twanda would you please make that change and run executables ? thanks enron north america corp attorney client and or work product privileges or do we need to do a side letter to mark ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 734 4935 4745 2545 3249 7238 4371  290 7196 4333 4786 3329 4533  611 1714\n",
      " 2222 6261 4880 3837 3576   86 2435  165 4533 2637 4243 2939 5426 2637 6412\n",
      " 4780  516  818 6412 5934 6996 1368  818 4635 2222    1    1    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > effective date still can be twanda would you please make that change and run executables ? thanks enron north america corp attorney client and or work product privileges or do we need to do a side letter to mark ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0129305046642\n",
      "global_step: 23920\n",
      "learning rate 0.000157024\n",
      "epoch 201\n",
      "batch 0\n",
      "training minibatch loss: 0.0021188801620155573\n",
      "  sample 1:\n",
      "    Index 535\n",
      "    enc input           > [6469 5703 6799 2222 6583  439 6254    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > everything else going ? good i hope <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5265 6412 5655 3249  844  818  208 2060 6024  818 4586 2222 5474 5490  208\n",
      " 5966 4055  295  818 3387  818 3358 2884 3829    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > will do could be sent to the ferc them to linda ? identified in the written testimony offer to meet to discuss further etc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5265 6412 5655 3249  844  818  208 2060 6024  818 4586 2222 5474 5490  208\n",
      " 5966 4055  295  818 3387  818 3358 2884 3829    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > will do could be sent to the ferc them to linda ? identified in the written testimony offer to meet to discuss further etc <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00454545454545\n",
      "global_step: 24039\n",
      "learning rate 0.000155585\n",
      "epoch 202\n",
      "batch 0\n",
      "training minibatch loss: 0.002224890748038888\n",
      "  sample 1:\n",
      "    Index 8\n",
      "    enc input           > [6362 5075  290 2545 6412  175 6115  464  857 4533  326  208 6433 1245 5490\n",
      " 7058 3162 5707  208 5902  118  290 2545 2388  242  318 6806 1654    1    0\n",
      "    0    0    0    0    0]\n",
      "    enc input           > see if you can do this now go back and read the third word in each line from the top betcha you can t resist passing it on <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6628 3187 4371  290 6548 2222 3948  595  439 5183 6663 2881  208 2754  439\n",
      " 2006 5984 5766 4742  942 6908 1421 2222    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > was served would you come ? party but i only went for the food i m not crazy about football sounds fun ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6628 3187 4371  290 6548 2222 3948  595  439 5183 6663 2881  208 2754  439\n",
      " 2006 5984 5766 4742  942 6908 1421 2222    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > was served would you come ? party but i only went for the food i m not crazy about football sounds fun ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.987526762187\n",
      "0.0\n",
      "global_step: 24158\n",
      "learning rate 0.000154158\n",
      "epoch 203\n",
      "batch 0\n",
      "training minibatch loss: 0.004227151162922382\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1285 2881  208 2150  818 4613 1437 5882 4154 2228 6872  175  722 7196   63\n",
      " 6681 2132    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > documentation for the southern to bp energy contract assignments questions regarding this assignment please call me at <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5812  722 2637 2198 2488 2222 2228 6872  175  722 7196   63 6681 2132    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > fyi assignment or capacity release ? questions regarding this assignment please call me at <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5812  722 2637 2198 2488 2222 2228 6872  175  722 7196   63 6681 2132    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > fyi assignment or capacity release ? questions regarding this assignment please call me at <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.979166666667\n",
      "0.00573118149581\n",
      "global_step: 24277\n",
      "learning rate 0.000152745\n",
      "epoch 204\n",
      "batch 0\n",
      "training minibatch loss: 0.004643059801310301\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [4442  814  439 1179 1141  290 3832 5190 1648 2238  279 5505  208 5856 2560\n",
      " 5014 1384 2245 5490 1357 6376 1149 5911 4149  208 1394 1384 1255 2222 5893\n",
      "  724 4739  279 4987    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > little suspicious i ll let you know when he gets out of the meeting del point is already in as mid c so just the price is wrong ? all deals checked out fine <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2815  208 5283 5505  208 5856 2881 1344  818 6548  279 6261 4442  814  439\n",
      " 1179 1141  290 3832 5190 1648 2238  279 5505  208 5856 2560 5014 1384 2245\n",
      " 5490 1357 6376 1149 5911 4149  208 1394 1384 1255 2222 5893  724 4739  279\n",
      " 4987    1    0    0]\n",
      "    dec input           > watching the door of the meeting for him to come out thanks little suspicious i ll let you know when he gets out of the meeting del point is already in as mid c so just the price is wrong ? all deals checked out fine <EOS> <PAD> <PAD>\n",
      "    dec train predicted > [2815  208 5283 5505  208 5856 2881 1344  818 6548  279 6261 4442  814  439\n",
      " 1179 1141  290 3832 5190 1648 2238  279 5505  208 5856 2560 5014 1384 2245\n",
      " 5490 1357 6376 1149 5911 4149  208 1394 1384 1255 2222 5893  724 4739  279\n",
      " 4987    1    1    0    0]\n",
      "    dec train predicted > watching the door of the meeting for him to come out thanks little suspicious i ll let you know when he gets out of the meeting del point is already in as mid c so just the price is wrong ? all deals checked out fine <EOS> <EOS> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991709183673\n",
      "0.00405377668309\n",
      "global_step: 24396\n",
      "learning rate 0.000151344\n",
      "epoch 205\n",
      "batch 0\n",
      "training minibatch loss: 0.004381811711937189\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 550 1839  208 5504 2132 4786 1069  851  818 1760 2483 2881 2342 3832 5075\n",
      "  290 1156 1397 5687 6261 2881 4526 6616 6415  208 5504 2132 4786 1069  851\n",
      "  818 1760 2483 2881 2342    1    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > unnecessarily complicate the process at that time place to accomplish control for tw know if you have any comments thanks for your help down the process at that time place to accomplish control for tw <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4786 4780 5136 6806  818 3249 4545 3832 5075  290 1156 1397 5687 6261 2881\n",
      " 4526 6616 6415  208 5504 2132 4786 1069  851  818 1760 2483 2881 2342    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > that we considered it to be confidential know if you have any comments thanks for your help down the process at that time place to accomplish control for tw <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4786 4780 5136 6806  818 3249 4545 3832 5075  290 1156 1397 5687 6261 2881\n",
      " 4526 6616 6415  208 5504 2132 4786 1069  851  818 1760 2483 2881 2342    1\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > that we considered it to be confidential know if you have any comments thanks for your help down the process at that time place to accomplish control for tw <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.977678571429\n",
      "0.00304015837104\n",
      "global_step: 24515\n",
      "learning rate 0.000149957\n",
      "epoch 206\n",
      "batch 0\n",
      "training minibatch loss: 0.0022805421613156796\n",
      "  sample 1:\n",
      "    Index 11\n",
      "    enc input           > [6261 2881  208 3537  439 4796 6806 1654  413 2040 2826 2255  208 4017 5505\n",
      "  208 4223 4786 4371 1156  844  208 6271 5490 2222 4742 6806  439 6628  125\n",
      " 3341 5934 1944  950 6015 1156  844 6024 5490 7196 1141 6681 3832    1]\n",
      "    enc input           > thanks for the reply i found it on her desk what s the name of the organization that would have sent the form in ? about it i was wondering whether a prior temp might have sent them in please let me know <EOS>\n",
      "    dec input           > [6507  439 4371 3249 5123  818 2720  290 5253 4683 6681 3832 2826  290 5675\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > john i would be happy to review you no problem me know what you think <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6507  439 4371 3249 5123  818 2720  290 5253 4683 6681 3832 2826  290 5675\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > john i would be happy to review you no problem me know what you think <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.001953125\n",
      "global_step: 24634\n",
      "learning rate 0.000148582\n",
      "epoch 207\n",
      "batch 0\n",
      "training minibatch loss: 0.0020421240478754044\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [1821 2255  208 3621 5364    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > here s the electronic file <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 208  530 2146 2545  290 6616 2222 4415 6412  290 1156 3431 7091 2881  208\n",
      " 2002 5505 2168 2222    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > the intergen deal can you help ? also do you have an address for the location of turbine ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 208  530 2146 2545  290 6616 2222 4415 6412  290 1156 3431 7091 2881  208\n",
      " 2002 5505 2168 2222    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > the intergen deal can you help ? also do you have an address for the location of turbine ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00589364035088\n",
      "global_step: 24753\n",
      "learning rate 0.00014722\n",
      "epoch 208\n",
      "batch 0\n",
      "training minibatch loss: 0.001895445166155696\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6015 3249  130 5075   93  416 6628 2998 1357 4394    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > might be helpful if nick palatin was available as well <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5911 4361 6826  290  657 2589  208 5174 4990 2222    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > so how are you doing with the eecc changes ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5911 4361 6826  290  657 2589  208 5174 4990 2222    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > so how are you doing with the eecc changes ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00384031329923\n",
      "global_step: 24872\n",
      "learning rate 0.00014587\n",
      "epoch 209\n",
      "batch 0\n",
      "training minibatch loss: 0.0019248477183282375\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4649 6672 7196 6983  818 6681 5577 2365 6672 5079 1989  289 6261 5490 5499\n",
      " 2881 4526 4044    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > am pdt please forward to me by pm pdt wednesday october th thanks in advance for your assistance <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 905 4649   40 7196 6983  818 6681 5577 2365   40 5079 1461 2223 6261 5490\n",
      " 5499 2881 4526 4044    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > morning am pst please forward to me by pm pst wednesday november st thanks in advance for your assistance <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 905 4649   40 7196 6983  818 6681 5577 2365   40 5079 1461 2223 6261 5490\n",
      " 5499 2881 4526 4044    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > morning am pst please forward to me by pm pst wednesday november st thanks in advance for your assistance <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.015625\n",
      "global_step: 24991\n",
      "learning rate 0.000144533\n",
      "epoch 210\n",
      "batch 0\n",
      "training minibatch loss: 0.0025931696873158216\n",
      "  sample 1:\n",
      "    Index 6\n",
      "    enc input           > [7181  439 4213 4526 3483 1435 2310 3814 6628  439 5984 5353  818 6412 4786\n",
      " 2222 3847    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    enc input           > oh i invited your rocket power dancer friend was i not supposed to do that ? experiences <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5471 1384 6799  818  208 5123  313 2222    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > who is going to the happy hour ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5471 1384 6799  818  208 5123  313 2222    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > who is going to the happy hour ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0193028453369\n",
      "global_step: 25110\n",
      "learning rate 0.000143208\n",
      "epoch 211\n",
      "batch 0\n",
      "training minibatch loss: 0.0020062208641320467\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 439 1179  626  818 1095 6806 6415    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i ll try to track it down <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 2006  105 4786 2357 5725  875 1861 1450 4533  646 2222 4415 5725  875\n",
      " 1861 1450 6107 2545 4780 2285  279 5471 5725  208 3969 5657 2222 2287 4526\n",
      " 2578 7196 6362  208 1970    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > i m told that aps filed against pg e and apec ? also filed against pg e jeff can we figure out who filed the other complaint ? per your request please see the attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 2006  105 4786 2357 5725  875 1861 1450 4533  646 2222 4415 5725  875\n",
      " 1861 1450 6107 2545 4780 2285  279 5471 5725  208 3969 5657 2222 2287 4526\n",
      " 2578 7196 6362  208 1970    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > i m told that aps filed against pg e and apec ? also filed against pg e jeff can we figure out who filed the other complaint ? per your request please see the attached <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.997395833333\n",
      "0.005110254329\n",
      "global_step: 25229\n",
      "learning rate 0.000141895\n",
      "epoch 212\n",
      "batch 0\n",
      "training minibatch loss: 0.0024012126959860325\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3888 5814 2826 6412  290 5675 4742 4786  931 2222 7196  660 1970 2546 4165\n",
      " 5505 3329 3569 4533 3329 3569    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > certain units what do you think about that approach ? please find attached my versions of change order and change order <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 564  439 1179  660  290 5915 3888 5814 2826 6412  290 5675 4742 4786  931\n",
      " 2222 7196  660 1970 2546 4165 5505 3329 3569 4533 3329 3569    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > afternoon i ll find you tomorrow certain units what do you think about that approach ? please find attached my versions of change order and change order <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 564  439 1179  660  290 5915 3888 5814 2826 6412  290 5675 4742 4786  931\n",
      " 2222 7196  660 1970 2546 4165 5505 3329 3569 4533 3329 3569    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > afternoon i ll find you tomorrow certain units what do you think about that approach ? please find attached my versions of change order and change order <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.992211246201\n",
      "0.0110197368421\n",
      "global_step: 25348\n",
      "learning rate 0.000140594\n",
      "epoch 213\n",
      "batch 0\n",
      "training minibatch loss: 0.0026898181531578302\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3337 5339 2132  208 2917 5505  985 4017 6412  290 2222 7196 6362 1970    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > crsp means at the end of their name do you ? please see attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3808 3782 6024 2881  658 5490  208 6893  439 2230 2388 3832 2826 3337 5339\n",
      " 1923 3464 3706 3337 5339 2132  208 2917 5505  985 4017 6412  290 2222 7196\n",
      " 6362 1970    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > never mind them for trading in the west i don t know what crsp means maybe credit does crsp means at the end of their name do you ? please see attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3808 3782 6024 2881  658 5490  208 6893  439 2230 2388 3832 2826 3337 5339\n",
      " 1923 3464 3706 3337 5339 2132  208 2917 5505  985 4017 6412  290 2222 7196\n",
      " 6362 1970    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > never mind them for trading in the west i don t know what crsp means maybe credit does crsp means at the end of their name do you ? please see attached <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.995302382054\n",
      "0.00440340909091\n",
      "global_step: 25467\n",
      "learning rate 0.000139305\n",
      "epoch 214\n",
      "batch 0\n",
      "training minibatch loss: 0.0020135852973908186\n",
      "  sample 1:\n",
      "    Index 436\n",
      "    enc input           > [ 836 6806 2255 1654 3723 4876 6562    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    enc input           > sure it s on its way slow <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3629 4974 6788 6289  208 1553 5483    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > services almost pulled off the tease yesterday <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3629 4974 6788 6289  208 1553 5483    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > services almost pulled off the tease yesterday <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00697508169935\n",
      "global_step: 25586\n",
      "learning rate 0.000138028\n",
      "epoch 215\n",
      "batch 0\n",
      "training minibatch loss: 0.0019972959998995066\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6164 6412  290 3832 5190  175 2146 4399 1300 2222 5251 2146 1728 5934 5791\n",
      " 6378 1010 4533 6806 4399 5984    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > chris do you know when this deal should terminate ? cng deal has a demand fee until and it should not <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1747 2826 2255 3421 2222  290  803  208 5791 3217 6289 5505  208 2146 2222\n",
      " 6164 6412  290 3832 5190  175 2146 4399 1300 2222 5251 2146 1728 5934 5791\n",
      " 6378 1010 4533 6806 4399 5984    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > done what s next ? you take the demand charge off of the deal ? chris do you know when this deal should terminate ? cng deal has a demand fee until and it should not <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1747 2826 2255 3421 2222  290  803  208 5791 3217 6289 5505  208 2146 2222\n",
      " 6164 6412  290 3832 5190  175 2146 4399 1300 2222 5251 2146 1728 5934 5791\n",
      " 6378 1010 4533 6806 4399 5984    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > done what s next ? you take the demand charge off of the deal ? chris do you know when this deal should terminate ? cng deal has a demand fee until and it should not <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.997448979592\n",
      "0.0137398602392\n",
      "global_step: 25705\n",
      "learning rate 0.000136762\n",
      "epoch 216\n",
      "batch 0\n",
      "training minibatch loss: 0.0018335231579840183\n",
      "  sample 1:\n",
      "    Index 3\n",
      "    enc input           > [4249  818 6695 2499    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > opportunity to begin archiving <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 439 5265  516  818 3294 5577    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > i will need to leave by <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 439 5265  516  818 3294 5577    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > i will need to leave by <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0\n",
      "global_step: 25824\n",
      "learning rate 0.000135508\n",
      "epoch 217\n",
      "batch 0\n",
      "training minibatch loss: 0.003532828064635396\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [ 542 5984 1595  439 1179 1141  290 3832 6818 1650    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > morgan not merrill i ll let you know these discrepancies <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4533 1156 2274 3708  818  765 1435 2287 3193 6969 6818 1650    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > and have been changed to nevada power per mike driscoll these discrepancies <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4533 1156 2274 3708  818  765 1435 2287 3193 6969 6818 1650    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > and have been changed to nevada power per mike driscoll these discrepancies <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.96875\n",
      "0.000664893617021\n",
      "global_step: 25943\n",
      "learning rate 0.000134266\n",
      "epoch 218\n",
      "batch 0\n",
      "training minibatch loss: 0.001692620338872075\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [1329 4780 5265  923  290 1821 5490 2213 4992  818 5664 4533 2211  818 6681\n",
      " 5490 3277 5740 5623    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "    enc input           > job we will miss you here in omaha relocate to houston and report to me in his new role <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1729 2178 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > expanded opportunities relocate to houston and report to me in his new role <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1729 2178 4992  818 5664 4533 2211  818 6681 5490 3277 5740 5623    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > expanded opportunities relocate to houston and report to me in his new role <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.987957178789\n",
      "0.00520833333333\n",
      "global_step: 26062\n",
      "learning rate 0.000133035\n",
      "epoch 219\n",
      "batch 0\n",
      "training minibatch loss: 0.0016523757949471474\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [2826 1384  208 5504  818  142  175 5490  208 6048 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > what is the process to approve this in the system ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2241  818 1121 2251 2826 6394 2222  502  818 2720 4533 2644 2753  175 2578\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > assigned to michelle cash what gives ? approval to review and act upon this request <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2241  818 1121 2251 2826 6394 2222  502  818 2720 4533 2644 2753  175 2578\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > assigned to michelle cash what gives ? approval to review and act upon this request <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00659722222222\n",
      "global_step: 26181\n",
      "learning rate 0.000131815\n",
      "epoch 220\n",
      "batch 0\n",
      "training minibatch loss: 0.0014246419304981828\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [5747   11 4533 2442 6261 1821 2255 3431 6978 6737 2881  290 2826 6412  290\n",
      " 5675 2222 3837   91 6259    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > dave errol and myself thanks here s an auburn boy for you what do you think ? north shepherd dr <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196 6362 5257 6261 2881 4526 6616 5747   11 4533 2442 6261 1821 2255 3431\n",
      " 6978 6737 2881  290 2826 6412  290 5675 2222 3837   91 6259    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > please see below thanks for your help dave errol and myself thanks here s an auburn boy for you what do you think ? north shepherd dr <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196 6362 5257 6261 2881 4526 6616 5747   11 4533 2442 6261 1821 2255 3431\n",
      " 6978 6737 2881  290 2826 6412  290 5675 2222 3837   91 6259    1    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > please see below thanks for your help dave errol and myself thanks here s an auburn boy for you what do you think ? north shepherd dr <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00710766344661\n",
      "global_step: 26300\n",
      "learning rate 0.000130607\n",
      "epoch 221\n",
      "batch 0\n",
      "training minibatch loss: 0.0015638674376532435\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [ 212  439 1179 2390 2881 3969 6138 1356  208 4260    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > project i ll check for other pertinent emails the latest <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6715  626 6254 6806 6618  212  439 1179 2390 2881 3969 6138 1356  208 4260\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > nd try hope it works project i ll check for other pertinent emails the latest <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6715  626 6254 6806 6618  212  439 1179 2390 2881 3969 6138 1356  208 4260\n",
      "    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > nd try hope it works project i ll check for other pertinent emails the latest <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00610795454545\n",
      "global_step: 26419\n",
      "learning rate 0.00012941\n",
      "epoch 222\n",
      "batch 0\n",
      "training minibatch loss: 0.0016037134919315577\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86 5812 2884 2057 6261 5490 1688 2589 2259  208  912    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp fyi further information thanks in connection with opening the account <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1940 1415 5707  407 4880 3837 3576   86 5812 4533 4082 3364 5490 1688 2589\n",
      " 2259  208  912    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > second message from bruce enron north america corp fyi and robin veariel in connection with opening the account <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1940 1415 5707  407 4880 3837 3576   86 5812 4533 4082 3364 5490 1688 2589\n",
      " 2259  208  912    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > second message from bruce enron north america corp fyi and robin veariel in connection with opening the account <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.992099152334\n",
      "0.0\n",
      "global_step: 26538\n",
      "learning rate 0.000128223\n",
      "epoch 223\n",
      "batch 0\n",
      "training minibatch loss: 0.0018012053333222866\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [2230 2388  290 5675 2222 2132 6092 6115 4780 3832 6806  511 5381 6826 5331\n",
      " 3190 1501 6386 6681 5934 5137 2881  208 6612 5934 1743 3217    1    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > don t you think ? at least now we know it matching gifts are paid quarterly hello sending me a bill for the plus a finance charge <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 175  851 1384 2088 1463 4819 6806 3618  818 3249  123  439  198 5984 1080\n",
      " 2057 2230 2388  290 5675 2222 2132 6092 6115 4780 3832 6806  511 5381 6826\n",
      " 5331 3190 1501 6386 6681 5934 5137 2881  208 6612 5934 1743 3217    1]\n",
      "    dec input           > this place is more difficult than it needs to be really i hate not having information don t you think ? at least now we know it matching gifts are paid quarterly hello sending me a bill for the plus a finance charge <EOS>\n",
      "    dec train predicted > [ 175  851 1384 2088 1463 4819 6806 3618  818 3249  123  439  198 5984 1080\n",
      " 2057 2230 2388  290 5675 2222 2132 6092 6115 4780 3832 6806  511 5381 6826\n",
      " 5331 3190 1501 6386 6681 5934 5137 2881  208 6612 5934 1743 3217    1    1]\n",
      "    dec train predicted > this place is more difficult than it needs to be really i hate not having information don t you think ? at least now we know it matching gifts are paid quarterly hello sending me a bill for the plus a finance charge <EOS> <EOS>\n",
      "0.997852801268\n",
      "0.0111607142857\n",
      "global_step: 26657\n",
      "learning rate 0.000127048\n",
      "epoch 224\n",
      "batch 0\n",
      "training minibatch loss: 0.0030666214879602194\n",
      "  sample 1:\n",
      "    Index 174\n",
      "    enc input           > [5075 4786 1384 6179  290 6404  818  464 1384 6701 2589 6681 4880 3837 3576\n",
      "   86    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > if that is where you want to go is ok with me enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4880 3837 3576   86  439 3189 5660 5505  208 5257 2589 6681 5750 1156 1397\n",
      "  634 2222 4880 3837 3576   86 2388 4301 1357 3431 3804    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > enron north america corp i brought none of the below with me today have any extras ? enron north america corp t shirt as an extra <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4880 3837 3576   86  439 3189 5660 5505  208 5257 2589 6681 5750 1156 1397\n",
      "  634 2222 4880 3837 3576   86 2388 4301 1357 3431 3804    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > enron north america corp i brought none of the below with me today have any extras ? enron north america corp t shirt as an extra <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982954545455\n",
      "0.00200892857143\n",
      "global_step: 26776\n",
      "learning rate 0.000125883\n",
      "epoch 225\n",
      "batch 0\n",
      "training minibatch loss: 0.0013789305230602622\n",
      "  sample 1:\n",
      "    Index 5\n",
      "    enc input           > [ 687 5617 4072 2146 1384 6107 4524 2986  175 2169 1624 4388 4786  759 6115\n",
      "    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > entry sorry first deal is jeff richter entered this awhile ago adding that right now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 3215 4786 2255 4567 4185 5505  290 4705 5934 6770  687 5617 4072 2146\n",
      " 1384 6107 4524 2986  175 2169 1624 4388 4786  759 6115    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > thanks kerri that s very nice of you get a chance entry sorry first deal is jeff richter entered this awhile ago adding that right now <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 3215 4786 2255 4567 4185 5505  290 4705 5934 6770  687 5617 4072 2146\n",
      " 1384 6107 4524 2986  175 2169 1624 4388 4786  759 6115    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > thanks kerri that s very nice of you get a chance entry sorry first deal is jeff richter entered this awhile ago adding that right now <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0100880264386\n",
      "global_step: 26895\n",
      "learning rate 0.000124729\n",
      "epoch 226\n",
      "batch 0\n",
      "training minibatch loss: 0.0013456331798806787\n",
      "  sample 1:\n",
      "    Index 6\n",
      "    enc input           > [6908 4987  818 6681 7196 6983  818 5284 5490 4526 6168  660  279 5075 6806\n",
      " 4371 3249 3234 2790 1274  987 4577 6261    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > sounds fine to me please forward to logistics in your region find out if it would be something worth putting into production thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 5934 4171    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > thanks a lot <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 5934 4171    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > thanks a lot <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.0\n",
      "global_step: 27014\n",
      "learning rate 0.000123585\n",
      "epoch 227\n",
      "batch 0\n",
      "training minibatch loss: 0.0014529003528878093\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4914 2222 1319 1384 4745 4732 5490  208 2811 5386 1875 4533 2132 2531 1366\n",
      "  605  208 3492 5504    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "    enc input           > halloween ? corn is still fresh in the air foster children and at risk youth throughout the court process <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 762 5215 1763 6049 5934 3829    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > black swan eu grope a etc <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 762 5215 1763 6049 5934 3829    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > black swan eu grope a etc <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.99660326087\n",
      "0.00761217948718\n",
      "global_step: 27133\n",
      "learning rate 0.000122452\n",
      "epoch 228\n",
      "batch 0\n",
      "training minibatch loss: 0.0031816577538847923\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1415 6628 6014 4017 5701 4969    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "    enc input           > message was directory name invalid reference <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4149 5934 3307  818 6226 6583  905 6362  290  175  564 2132 6203    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > just a note to say good morning see you this afternoon at eott <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4149 5934 3307  818 6226 6583  905 6362  290  175  564 2132 6203    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > just a note to say good morning see you this afternoon at eott <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.971377912867\n",
      "0.00707008406433\n",
      "global_step: 27252\n",
      "learning rate 0.000121329\n",
      "epoch 229\n",
      "batch 0\n",
      "training minibatch loss: 0.0020799587946385145\n",
      "  sample 1:\n",
      "    Index 426\n",
      "    enc input           > [ 439 2899 1910  818 4333 2546 6727 4683  464 1596    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > i cant seem to make my gambling problem go away <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4371 3249 4022    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > would be easier <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4371 3249 4022    1    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > would be easier <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96875\n",
      "0.00509672619048\n",
      "global_step: 27371\n",
      "learning rate 0.000120217\n",
      "epoch 230\n",
      "batch 0\n",
      "training minibatch loss: 0.0011029127053916454\n",
      "  sample 1:\n",
      "    Index 1\n",
      "    enc input           > [6261 5620    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    enc input           > thanks man <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [6261 5934 4171  439 4999 4526 1980 5637 3665 6983  818 5934 1550 1357 4780\n",
      " 5040 5740 5027 2881 6952 2255 4108    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > thanks a lot i appreciate your kind words look forward to a successful as we break new ground for et s kim <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [6261 5934 4171  439 4999 4526 1980 5637 3665 6983  818 5934 1550 1357 4780\n",
      " 5040 5740 5027 2881 6952 2255 4108    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > thanks a lot i appreciate your kind words look forward to a successful as we break new ground for et s kim <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00524597338936\n",
      "global_step: 27490\n",
      "learning rate 0.000119115\n",
      "epoch 231\n",
      "batch 0\n",
      "training minibatch loss: 0.0012154504656791687\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7196 5091 4935 1384 4786 4935  759 2222 2110 4072 5856 5265 3249 7132 1906\n",
      " 2132 2365 5490 5994    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    enc input           > please correct date is that date right ? our first meeting will be tuesday january at pm in eb <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5617 4072 4639 1384  208  289 1384 4786 4935  759 2222 2110 4072 5856 5265\n",
      " 3249 7132 1906 2132 2365 5490 5994    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > sorry first one is the th is that date right ? our first meeting will be tuesday january at pm in eb <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5617 4072 4639 1384  208  289 1384 4786 4935  759 2222 2110 4072 5856 5265\n",
      " 3249 7132 1906 2132 2365 5490 5994    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > sorry first one is the th is that date right ? our first meeting will be tuesday january at pm in eb <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.988753181605\n",
      "0.00763888888889\n",
      "global_step: 27609\n",
      "learning rate 0.000118023\n",
      "epoch 232\n",
      "batch 0\n",
      "training minibatch loss: 0.0013154919724911451\n",
      "  sample 1:\n",
      "    Index 540\n",
      "    enc input           > [6892 2826 5934 4171 5505 4990    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > spot what a lot of changes <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2881 3431 2507 6895 5490 6820    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > for an outstanding year in weather <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2881 3431 2507 6895 5490 6820    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > for an outstanding year in weather <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.019316887412\n",
      "global_step: 27728\n",
      "learning rate 0.000116941\n",
      "epoch 233\n",
      "batch 0\n",
      "training minibatch loss: 0.0013690534979104996\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4371  290 7196 2500  208 5313 5699 5505  208 1970 2211 2222 2808 1141 6681\n",
      " 3832 5075  290 1156 1397 4725 2589  208 2458 6817 6261 1149    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > would you please verify the financial section of the attached report ? agreed let me know if you have any problems with the following attachment thanks c <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [7196  660 1970  208 2269 5344 6585 1141 6681 3832 5075  290 1156 1397 4725\n",
      " 2589  208 5364 6261 1149    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > please find attached the document mentioned above let me know if you have any problems with the file thanks c <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [7196  660 1970  208 2269 5344 6585 1141 6681 3832 5075  290 1156 1397 4725\n",
      " 2589  208 5364 6261 1149    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > please find attached the document mentioned above let me know if you have any problems with the file thanks c <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.012171371379\n",
      "global_step: 27847\n",
      "learning rate 0.000115869\n",
      "epoch 234\n",
      "batch 0\n",
      "training minibatch loss: 0.0011880993843078613\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4747 5794 2737 6289 1654  208  931 2222 2826 4371 5541 5075 5934 4381 2155\n",
      " 4381 2249 6850 3382 1052 3395 5183   52 2985 6681 5934   63 5075  175 3706\n",
      " 5984 4333 2840    1    0    0]\n",
      "    enc input           > delainey whaley buy off on the approach ? what would happen if a core non core split were implemented selling gen only service give me a call if this does not make sense <EOS> <PAD> <PAD>\n",
      "    dec input           > [1561  290 4429 2132 6806 2222    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec input           > piece you looking at it ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1561  290 4429 2132 6806 2222    1    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec train predicted > piece you looking at it ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99349800896\n",
      "0.0124421296296\n",
      "global_step: 27966\n",
      "learning rate 0.000114806\n",
      "epoch 235\n",
      "batch 0\n",
      "training minibatch loss: 0.0012379541294649243\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [1397 5274 2222 6628  208 1234  844  818 1149 4187 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > any news ? was the confirmation sent to c puerto ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 914  818  208  192 1654 4786 1352 2222    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > addition to the volumes on that amendment ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 914  818  208  192 1654 4786 1352 2222    1    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > addition to the volumes on that amendment ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999335106383\n",
      "0.0100362872422\n",
      "global_step: 28085\n",
      "learning rate 0.000113754\n",
      "epoch 236\n",
      "batch 0\n",
      "training minibatch loss: 0.0014467674773186445\n",
      "  sample 1:\n",
      "    Index 7\n",
      "    enc input           > [2207 1384  208 4468 4533 2839 5505  797 7196 2985 6681 5934   63 2132 4526\n",
      "  421 2254    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > ike is the president and ceo of tva please give me a call at your earliest convenience <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 420 2611 2400 1048 1654 5175 5505 6081 4223 6752    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > basis given changing opinions on effectiveness of current organization lavo <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 420 2611 2400 1048 1654 5175 5505 6081 4223 6752    1    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > basis given changing opinions on effectiveness of current organization lavo <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.998697916667\n",
      "0.00818865740741\n",
      "global_step: 28204\n",
      "learning rate 0.000112711\n",
      "epoch 237\n",
      "batch 0\n",
      "training minibatch loss: 0.0010941255604848266\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4786 6618 2881 6681    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > that works for me <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2637 2467 6681 3887 2222 4635 5075  290 1156 1069  818 4491 7196 7073 5674\n",
      " 2205  818 4491 6261    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > or pick me up ? mark if you have time to attend please join us effort to attend thanks <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2637 2467 6681 3887 2222 4635 5075  290 1156 1069  818 4491 7196 7073 5674\n",
      " 2205  818 4491 6261    1    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec train predicted > or pick me up ? mark if you have time to attend please join us effort to attend thanks <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00563321280536\n",
      "global_step: 28323\n",
      "learning rate 0.000111678\n",
      "epoch 238\n",
      "batch 0\n",
      "training minibatch loss: 0.0046002515591681\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 3837 3576   86 6260 2211  439 5265   48  208  857 3887 5490 5564  818\n",
      " 5934 7007 1165  290    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > enron north america corp expense report i will put the back up in mail to a p thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [ 175 1384 2826 4780  844  818 5934 7007 1141 6681 3832 5075 4780  516  818\n",
      " 1642  667 4500 4880 3837 3576   86 4880 3837 3576   86 6260 2211  439 5265\n",
      "   48  208  857 3887 5490 5564  818 5934 7007 1165  290    1    0    0    0\n",
      "    0]\n",
      "    dec input           > this is what we sent to a p let me know if we need to resend thx g enron north america corp enron north america corp expense report i will put the back up in mail to a p thank you <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [ 175 1384 2826 4780  844  818 5934 7007 1141 6681 3832 5075 4780  516  818\n",
      " 1642  667 4500 4880 3837 3576   86 4880 3837 3576   86 6260 2211  439 5265\n",
      "   48  208  857 3887 5490 5564  818 5934 7007 1165  290    1    1    0    0\n",
      "    0    0]\n",
      "    dec train predicted > this is what we sent to a p let me know if we need to resend thx g enron north america corp enron north america corp expense report i will put the back up in mail to a p thank you <EOS> <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "0.984569099379\n",
      "0.0148296983267\n",
      "global_step: 28442\n",
      "learning rate 0.000110654\n",
      "epoch 239\n",
      "batch 0\n",
      "training minibatch loss: 0.0015566354850307107\n",
      "  sample 1:\n",
      "    Index 33\n",
      "    enc input           > [1713 1450 5564 2826 2255 4786 4742 2222 5058 2388  937 4645  818 5675 4786\n",
      " 6375 2388 4361 6806 6618 2589 6024    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > shit e mail what s that about ? aren t naive enough to think that isn t how it works with them <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4361 6628  208 4394  175 1150 2222 4880 3837 3576   86 4639 3969  748 2800\n",
      " 5984 3614  279  208 4876  290  604 6806 4371 1413 2222    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > how was the well this weekend ? enron north america corp one other thing bass not working out the way you thought it would huh ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [4361 6628  208 4394  175 1150 2222 4880 3837 3576   86 4639 3969  748 2800\n",
      " 5984 3614  279  208 4876  290  604 6806 4371 1413 2222    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > how was the well this weekend ? enron north america corp one other thing bass not working out the way you thought it would huh ? <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999335106383\n",
      "0.007454004329\n",
      "global_step: 28561\n",
      "learning rate 0.000109639\n",
      "epoch 240\n",
      "batch 0\n",
      "training minibatch loss: 0.001212151488289237\n",
      "  sample 1:\n",
      "    Index 2\n",
      "    enc input           > [4639 2088 6650 5775  506 6685 2313 6454 2222    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > one more ca question pollina corporate real estate ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [3075 7196 6362  208 1970    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > kay please see the attached <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [3075 7196 6362  208 1970    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > kay please see the attached <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.00376176749109\n",
      "global_step: 28680\n",
      "learning rate 0.000108634\n",
      "epoch 241\n",
      "batch 0\n",
      "training minibatch loss: 0.0012283395044505596\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7196 2883 3887 5934   63 2881  539 2110 3805 1397 5274 2222 3498 1384  279\n",
      " 1597 1450 5564 4821 3515 1384  591 4533  398 3249 4904    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > please set up a call for tommorning our setoffs any news ? possibility is out there e mail including attachments is prohibited and may be unlawful <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1165  290 6197 2110 3805 1397 5274 2222  208 3498 1384  279 1597 2057 1262\n",
      "  818 3249 1947 5183  818  208 5083  878 2255  591 4533  398 3249 4904 1450\n",
      " 5564 4821 3515 1384  591 4533  398 3249 4904    1    0    0    0]\n",
      "    dec input           > thank you challenge our setoffs any news ? the possibility is out there information intended to be conveyed only to the designated recipient s prohibited and may be unlawful e mail including attachments is prohibited and may be unlawful <EOS> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1165  290 6197 2110 3805 1397 5274 2222  208 3498 1384  279 1597 2057 1262\n",
      "  818 3249 1947 5183  818  208 5083  878 2255  591 4533  398 3249 4904 1450\n",
      " 5564 4821 3515 1384  591 4533  398 3249 4904    1    1    0    0    0]\n",
      "    dec train predicted > thank you challenge our setoffs any news ? the possibility is out there information intended to be conveyed only to the designated recipient s prohibited and may be unlawful e mail including attachments is prohibited and may be unlawful <EOS> <EOS> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.016558987377\n",
      "global_step: 28799\n",
      "learning rate 0.000107638\n",
      "epoch 242\n",
      "batch 0\n",
      "training minibatch loss: 0.0032389413099735975\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [7196 3365 6681 2881  175 1397 2228 7196 2230 2388 6622  818 6151 1613 4671\n",
      " 2637 2442 5518 3013  595  130 2198    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > please register me for this any questions please don t hesitate to contact sheridan bob or myself some small but helpful capacity <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2088 1654  208 4370 3676 1397 2228 7196 2230 2388 6622  818 6151 1613 4671\n",
      " 2637 2442 5518 3013  595  130 2198    1    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec input           > more on the cfos conference any questions please don t hesitate to contact sheridan bob or myself some small but helpful capacity <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2088 1654  208 4370 3676 1397 2228 7196 2230 2388 6622  818 6151 1613 4671\n",
      " 2637 2442 5518 3013  595  130 2198    1    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "    dec train predicted > more on the cfos conference any questions please don t hesitate to contact sheridan bob or myself some small but helpful capacity <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.986328125\n",
      "0.00827809343434\n",
      "global_step: 28918\n",
      "learning rate 0.000106651\n",
      "epoch 243\n",
      "batch 0\n",
      "training minibatch loss: 0.0014696992002427578\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [4880 2973 5703 2222  208 4935 5505 2506 5505  208 3610  668  818  208  612\n",
      " 2722 6095   63 6681 5075  290 7142  818 3358  208 3861 5505 5173 5454 1590\n",
      " 1397  481 5505  175 1450 5564 4533 1397 5124 1165  290    1    0    0    0\n",
      "    0    0    0]\n",
      "    enc input           > enron anything else ? the date of execution of the loi relative to the wizvest planned interconnect call me if you wish to discuss the queue of applicants fo interconnection any copy of this e mail and any printout thank you <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [4160 2924 4880 3837 3576   86 4880 2973 5703 2222  208 4935 5505 2506 5505\n",
      "  208 3610  668  818  208  612 2722 6095   63 6681 5075  290 7142  818 3358\n",
      "  208 3861 5505 5173 5454 1590 1397  481 5505  175 1450 5564 4533 1397 5124\n",
      " 1165  290    1]\n",
      "    dec input           > short fuse enron north america corp enron anything else ? the date of execution of the loi relative to the wizvest planned interconnect call me if you wish to discuss the queue of applicants fo interconnection any copy of this e mail and any printout thank you <EOS>\n",
      "    dec train predicted > [4160 2924 4880 3837 3576   86 4880 2973 5703 2222  208 4935 5505 2506 5505\n",
      "  208 3610  668  818  208  612 2722 6095   63 6681 5075  290 7142  818 3358\n",
      "  208 3861 5505 5173 5454 1590 1397  481 5505  175 1450 5564 4533 1397 5124\n",
      " 1165  290    1    1]\n",
      "    dec train predicted > short fuse enron north america corp enron anything else ? the date of execution of the loi relative to the wizvest planned interconnect call me if you wish to discuss the queue of applicants fo interconnection any copy of this e mail and any printout thank you <EOS> <EOS>\n",
      "1.0\n",
      "0.00381944444444\n",
      "global_step: 29037\n",
      "learning rate 0.000105674\n",
      "epoch 244\n",
      "batch 0\n",
      "training minibatch loss: 0.0012666372349485755\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [3180 2222    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > ruggles ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [5934 6902 2881 1269 2637 2881 4639 5505  571 1557 6335    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec input           > a gc for either or for one of those day spas <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [5934 6902 2881 1269 2637 2881 4639 5505  571 1557 6335    1    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    dec train predicted > a gc for either or for one of those day spas <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.00661151960784\n",
      "global_step: 29156\n",
      "learning rate 0.000104705\n",
      "epoch 245\n",
      "batch 0\n",
      "training minibatch loss: 0.0012068782234564424\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6261  279    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > thanks out <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1514  818 5992 2222  279    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "    dec input           > program to sign ? out <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1514  818 5992 2222  279    1    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec train predicted > program to sign ? out <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "0.999320652174\n",
      "0.0173335906332\n",
      "global_step: 29275\n",
      "learning rate 0.000103745\n",
      "epoch 246\n",
      "batch 0\n",
      "training minibatch loss: 0.0011691092513501644\n",
      "  sample 1:\n",
      "    Index 216\n",
      "    enc input           > [5984  703 4533  290 2222    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > not much and you ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [1821  290  464 5471 2255 2847 2222 5123 2951    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "    dec input           > here you go who s ugoretz ? happy yom <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [1821  290  464 5471 2255 2847 2222 5123 2951    1    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "    dec train predicted > here you go who s ugoretz ? happy yom <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.022966830896\n",
      "global_step: 29394\n",
      "learning rate 0.000102794\n",
      "epoch 247\n",
      "batch 0\n",
      "training minibatch loss: 0.0010768150677904487\n",
      "  sample 1:\n",
      "    Index 0\n",
      "    enc input           > [6908 1977 6375 2388 4786 2826  642 6822 1944  818 3112  208 3705 1329 2222\n",
      " 4880 3837 3576   86    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "    enc input           > sounds familiar isn t that what butch said prior to taking the browns job ? enron north america corp <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec input           > [2973 4771    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "    dec input           > anything yet <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "    dec train predicted > [2973 4771    1    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n",
      "    dec train predicted > anything yet <EOS> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "1.0\n",
      "0.017828525641\n"
     ]
    }
   ],
   "source": [
    "all_weights = []\n",
    "dev_test_results = []\n",
    "metric_results = []\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    #saver.restore(session, \\\n",
    "    #    './seq2seq_CornelMovies_encode_100_decode_200_vocab_13679_embedding_200_seq_5_15_batch_64_layers_3_v5-210')\n",
    "    #saver.restore(session, \\\n",
    "    #    './seq2seq_CornelMovies_encode_100_decode_200_vocab_13679_embedding_200_seq_5_15_batch_64_layers_3_v5-100')\n",
    "    #saver.restore(session, \\\n",
    "    #    'd:\\coding\\seq2seq_CornelMovies_encode_200_decode_400_vocab_13679_embedding_200_seq_5_15_batch_128_layers_6_v6-990')\n",
    "    #saver.restore(session, \\\n",
    "    #    './seq2seq_CornelMovies_encode_500_decode_1000_vocab_13679_embedding_1024_seq_5_15_batch_32_layers_6_v6-30')\n",
    "    #saver.restore(session, \\\n",
    "    #'d:\\coding\\chkpt\\seq2seq_Cornell_encode_128_decode_256_vocab_13679_embedding_256_seq_5_15_batch_32_layers_3_enkeep_10_dekeep_10-203320')\n",
    "   #saver.restore(session, \\\n",
    "   # 'd:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10-12019')\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        df_all_train = df_all_train.sample(frac=1, random_state=0)#tf.train.global_step(session, global_step))\n",
    "       \n",
    "        encoded_text = df_all_train['alpha_Pair_0_encoding'].values\n",
    "        decoded_text = df_all_train['alpha_Pair_1_encoding'].values\n",
    "        text_index = df_all_train['Index'].values\n",
    "\n",
    "        input_batches = ([encoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                  decoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                         text_index[block_idx*n_batch_size:(block_idx+1)*n_batch_size]]\\\n",
    "                    for block_idx in range(len(encoded_text)))\n",
    "        \n",
    "        for batch in range(int(batches_in_epoch)):\n",
    "            mean_metric_train = []\n",
    "            mean_metric_dev = []\n",
    "\n",
    "            if copy_task == False:\n",
    "                \n",
    "                epoch_batches = next(input_batches)\n",
    "                \n",
    "                #input_batch_data = next(encoding_batches)\n",
    "                #target_batch_data = next(decoding_batches)\n",
    "                \n",
    "                input_batch_data = epoch_batches[0]\n",
    "                target_batch_data = epoch_batches[1]\n",
    "                batch_data_index = epoch_batches[2]\n",
    "\n",
    "            else:\n",
    "                input_batch_data = next(copy_batches)\n",
    "                target_batch_data = input_batch_data\n",
    "            \n",
    "            fd = make_train_inputs(input_batch_data, target_batch_data)\n",
    "            #by randomizing the batches are not really comparable\n",
    "            df_all_dev_check = df_all_dev.sample(n=32, random_state=0)\n",
    "            \n",
    "            dev_encoded_text = df_all_dev_check['alpha_Pair_0_encoding'].values\n",
    "            dev_decoded_text = df_all_dev_check['alpha_Pair_1_encoding'].values\n",
    "            #Don't think this makes sense without masking?\n",
    "            #fd_dev = make_train_inputs([i for i in dev_encoded_text], [i for i in dev_decoded_text])\n",
    "\n",
    "            _, l = session.run([train_op, loss], fd)\n",
    "            loss_track.append(l)\n",
    "            \n",
    "            if batch % 500 == 0: \n",
    "                \n",
    "                print ('global_step: %s' % tf.train.global_step(session, global_step))\n",
    "                print ('learning rate', session.run(optimizer._lr))\n",
    "                \n",
    "                print ('epoch', epoch)\n",
    "                print ('batch {}'.format(batch))\n",
    "                #WHAT DOES THIS LOSS ACTUALLY MEAN? IS THIS TRAINING AGAINST GRAPH AGAIN? NO?\n",
    "                print ('training minibatch loss: {}'.format(session.run(loss, fd)))\n",
    "                #dev_loss = session.run(loss, fd_dev)\n",
    "                #print ('dev loss: {}'.format(dev_loss))\n",
    "                #dev_loss_track.append(dev_loss)\n",
    "                \n",
    "                for i, (e_in, dt_targ, dt_pred) in enumerate(zip(fd[encoder_inputs].T, \n",
    "                                                                 fd[decoder_targets].T, \n",
    "                                                                 session.run(decoder_prediction_train, fd).T)):\n",
    "\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    Index', batch_data_index[i])\n",
    "                    print('    enc input           > {}'.format(e_in))\n",
    "                    print('    enc input           > {}'.format(' '.join([inv_map[i] for i in e_in])))\n",
    "\n",
    "                    print('    dec input           > {}'.format(dt_targ))\n",
    "                    print('    dec input           > {}'.format(' '.join([inv_map[i] for i in dt_targ])))\n",
    "\n",
    "                    print('    dec train predicted > {}'.format(dt_pred))\n",
    "                    print('    dec train predicted > {}'.format(' '.join([inv_map[i] for i in dt_pred])))\n",
    "                \n",
    "                    if i >= 0: break\n",
    "                \n",
    "                fd_inf_train = make_inference_inputs(input_batch_data)\n",
    "                fd_inf_dev = make_inference_inputs(dev_encoded_text)\n",
    "\n",
    "                inf_train_out = session.run(decoder_prediction_inference, fd_inf_train)\n",
    "                inf_train_prob_out = session.run(decoder_prediction_prob_inference, fd_inf_train)\n",
    "             \n",
    "                inf_dev_out = session.run(decoder_prediction_inference, fd_inf_dev)\n",
    "                inf_dev_prob_out = session.run(decoder_prediction_prob_inference, fd_inf_dev)\n",
    "                \n",
    "                for i, (pred, pred_prob) in enumerate(zip(inf_train_out.T, inf_train_prob_out.T)):\n",
    "                #    print ('inference out', pred)\n",
    "                #    print ('inference text out', [inv_map[i] for i in pred])\n",
    "                #    print ('inference out prob', pred_prob)\n",
    "                    mean_metric_train.append([input_batch_data[i], target_batch_data[i], pred, pred_prob, epoch, batch])\n",
    "                                \n",
    "                for i, (pred, pred_prob) in enumerate(zip(inf_dev_out.T, inf_dev_prob_out.T)):\n",
    "                #    print ('inference out', pred)\n",
    "                #    print ('inference text out', [inv_map[i] for i in pred])\n",
    "                #    print ('inference out prob', pred_prob)\n",
    "                    mean_metric_dev.append([input_batch_data[i], target_batch_data[i], pred, pred_prob, epoch, batch])\n",
    "                \n",
    "                df_prediction_train = predictionCheck(mean_metric_train)\n",
    "                print (df_prediction_train['meanCheckList'].describe()['mean'])\n",
    "                \n",
    "                df_prediction_dev = predictionCheck(mean_metric_dev)\n",
    "                print (df_prediction_dev['meanCheckList'].describe()['mean'])\n",
    "                \n",
    "                metric_results.append([df_prediction_train, df_prediction_dev])\n",
    "                \n",
    "        if epoch % 10 == 0: \n",
    "            \n",
    "            #eval_dev = devCheck(dev_encoded_text, dev_decoded_text, True)\n",
    "            \n",
    "            #dev_test_results.append(eval_dev)\n",
    "            \n",
    "            #pickle.dump(dev_test_results, open('d:\\coding\\chkpt\\dev_test_results_epoch_%d.pkl' % epoch, 'wb'))\n",
    "            \n",
    "            saver.save(session, \\\n",
    "'d:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_%d_decode_%d_vocab_%d_embedding_%d_seq_%d_%d_batch_%d_layers_%d_enkeep_%d_dekeep_%d' % \\\n",
    "                (n_cells, n_cells*2, vocab_size, input_embedding_size, length_from, length_to, n_batch_size, num_layers,\n",
    "                int(encoder_output_keep*10), int(decoder_output_keep*10)), \\\n",
    "                       global_step = tf.train.global_step(session, global_step))\n",
    "            \n",
    "        variables_names =[v.name for v in tf.trainable_variables()]\n",
    "        values = session.run(variables_names)\n",
    "        all_weights.append([values[1], values[3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#How are we preprocessing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03561141, -0.08436941,  0.02523125, ..., -0.04474876,\n",
       "         -0.06028526,  0.06598502],\n",
       "        [ 0.0808537 , -0.05313767, -0.0562261 , ..., -0.00807003,\n",
       "         -0.02093897,  0.02892466],\n",
       "        [-0.03273988,  0.06598959, -0.03424493, ...,  0.00351857,\n",
       "          0.01417433,  0.05116267],\n",
       "        ..., \n",
       "        [ 0.02584015, -0.08339297, -0.08304574, ...,  0.01859791,\n",
       "         -0.02313082, -0.01909244],\n",
       "        [-0.03006146, -0.01373254, -0.06796414, ..., -0.00603042,\n",
       "         -0.05191033,  0.03397365],\n",
       "        [ 0.08308677,  0.07712685,  0.05976195, ..., -0.01024244,\n",
       "         -0.05013997,  0.04459937]], dtype=float32),\n",
       " array([[ 0.02026712,  0.06020831,  0.06318098, ..., -0.07355831,\n",
       "          0.02328249, -0.03861096],\n",
       "        [ 0.0051128 , -0.03153554,  0.02082994, ..., -0.04643549,\n",
       "         -0.04393444,  0.02202067],\n",
       "        [-0.04436629,  0.03060955, -0.00758799, ...,  0.06842236,\n",
       "          0.07158019, -0.01773562],\n",
       "        ..., \n",
       "        [-0.03622399,  0.01435806,  0.06125661, ..., -0.06887323,\n",
       "          0.03991424, -0.06336081],\n",
       "        [ 0.01104193, -0.111066  , -0.00346948, ..., -0.02239933,\n",
       "         -0.08561457,  0.06243551],\n",
       "        [ 0.05310721,  0.06092684,  0.06588251, ..., -0.04771718,\n",
       "         -0.10439539,  0.05250312]], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b974e7eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot([i for i in range(len(loss_track))], loss_track)\n",
    "plt.plot([i for i in range(len(dev_loss_track))], dev_loss_track)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7344, 2675, 10099, 3520, 8791, 6626, 3956, 5961, 7647, 6626, 1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_dev.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935388]\n",
      "1 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935366]\n",
      "2 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935366]\n",
      "3 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935396]\n",
      "4 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935366]\n",
      "5 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935366]\n",
      "6 7\n",
      "[[1]]\n",
      "    sample 1:\n",
      "    enc input                > ['get', 'the', 'report', 'finished']\n",
      "    dec train inference      > ['<EOS>']\n",
      "    dec train inference prob > [0.065935366]\n",
      "[<tf.Operation 'encoder_inputs' type=Placeholder>, <tf.Operation 'encoder_inputs_length' type=Placeholder>, <tf.Operation 'decoder_targets' type=Placeholder>, <tf.Operation 'decoder_targets_length' type=Placeholder>]\n"
     ]
    }
   ],
   "source": [
    "#Create inference\n",
    "mean_metric = []\n",
    "chunk_size = 500\n",
    "n_chunks = int(df_all_train.shape[0]/chunk_size)\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, \\\n",
    "'d:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10_test-119')\n",
    "    for chunk in range(n_chunks):\n",
    "        print (chunk, n_chunks)\n",
    "        #fd = make_inference_inputs(\n",
    "        #    [i for i in df_all_train['alpha_Pair_0_encoding'].values[chunk*chunk_size:(chunk+1)*chunk_size]])\n",
    "        fd = make_inference_inputs(\n",
    "            [numericEncode('get the report finished')])\n",
    "\n",
    "        inf_out = session.run(decoder_prediction_inference, fd)\n",
    "        inf_prob_out = session.run(decoder_prediction_prob_inference, fd)\n",
    "\n",
    "        print(inf_out.T)\n",
    "        #print (df_all_train.values[0][1], df_all_train.values[1][1])\n",
    "\n",
    "        for i, (e_in, dt_inf) in enumerate(zip(fd[encoder_inputs].T, inf_out.T)):\n",
    "            #mean_metric.append([df_all_train.values[i][0], df_all_train.values[i][1], dt_inf])\n",
    "            print('    sample {}:'.format(i + 1))\n",
    "            print('    enc input                > {}'.format([inv_map[k] for k in e_in]))\n",
    "            #print('    dec input                > {}'.format([inv_map[k] for k in df_all_train.values[i][1]]))\n",
    "            print('    dec train inference      > {}'.format([inv_map[k] for k in dt_inf]))\n",
    "            print('    dec train inference prob > {}'.format([inf_prob_out[j][i].max() for j in range((len(inf_prob_out)))]))\n",
    "            \n",
    "            if i>0: continue\n",
    "        \n",
    "       # print ('Save Model')\n",
    "       # builder = tf.saved_model.builder.SavedModelBuilder('d:\\coding\\seq2seq\\model')\n",
    "       # builder.add_meta_graph_and_variables(session, ['serve'])\n",
    "\n",
    "        #builder.save()\n",
    "    ops = session.graph.get_operations()\n",
    "\n",
    "    feed_ops = [op for op in ops if op.type=='Placeholder']\n",
    "\n",
    "    print(feed_ops)\n",
    "        #if n_chunks >0: \n",
    "         #   break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No op named attn_add_fun_f32f32f32 in defined operations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a0671061cfd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# We import the meta graph in the current default Graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10_test-119.meta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# We restore the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1575\u001b[0m                                       \u001b[0mclear_devices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m                                       \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m                                       **kwargs)\n\u001b[0m\u001b[0;32m   1578\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHasField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saver_def\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name)\u001b[0m\n\u001b[0;32m    496\u001b[0m     importer.import_graph_def(\n\u001b[0;32m    497\u001b[0m         \u001b[0minput_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimport_scope\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         producer_op_list=producer_op_list)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;31m# Restores all the other collections.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    257\u001b[0m       \u001b[1;31m# Set any default attr values that aren't present.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No op named %s in defined operations.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m       \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mattr_def\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No op named attn_add_fun_f32f32f32 in defined operations."
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    \n",
    "    # We import the meta graph in the current default Graph\n",
    "    saver = tf.train.import_meta_graph('d:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10_test-119.meta')\n",
    "\n",
    "    # We restore the weights\n",
    "    saver.restore(session, 'd:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10_test-119')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric = pd.DataFrame(mean_metric, columns=['input', 'output', 'inference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metric['truth_sent'] = df_metric[1].apply(decodeSent)\n",
    "df_metric['inference_sent'] = df_metric['inference'].apply(decodeSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkListResults = list(map(checkList, df_metric['output'].values, df_metric['inference_sent'].values))\n",
    "\n",
    "df_metric['checkList'] = checkListResults\n",
    "\n",
    "df_metric['meanCheckList'] = df_metric['checkList'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>inference</th>\n",
       "      <th>inference_sent</th>\n",
       "      <th>checkList</th>\n",
       "      <th>meanCheckList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[reporting, agency, and, data, source, informa...</td>\n",
       "      <td>[enron, capital, trade, resources, corp, repor...</td>\n",
       "      <td>[4880, 3447, 3619, 4536, 86, 3748, 3446, 4533,...</td>\n",
       "      <td>[enron, capital, trade, resources, corp, repor...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[we, don, t, hear, from, him, by, noon, i, wou...</td>\n",
       "      <td>[be, cut, off, this, cold, november, any, prob...</td>\n",
       "      <td>[3249, 1422, 6289, 175, 4302, 1461, 1397, 4683...</td>\n",
       "      <td>[be, cut, off, this, cold, november, any, prob...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[month, changes, they, re, very, simple, to, m...</td>\n",
       "      <td>[these, are, done, &lt;EOS&gt;]</td>\n",
       "      <td>[6818, 6826, 1747, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[these, are, done, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;,...</td>\n",
       "      <td>[True, True, True, True]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[subject, re, dinner, on, friday, ?, subject, ...</td>\n",
       "      <td>[subject, re, dinner, on, friday, ?, subject, ...</td>\n",
       "      <td>[2126, 6792, 6346, 1654, 325, 2222, 2126, 6792...</td>\n",
       "      <td>[subject, re, dinner, on, friday, ?, subject, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thanksi, have, no, revisions, enjoy, the, par...</td>\n",
       "      <td>[and, positions, circulate, the, plan, early, ...</td>\n",
       "      <td>[4533, 6637, 2496, 208, 259, 1521, 175, 1306, ...</td>\n",
       "      <td>[and, positions, circulate, the, plan, early, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[attached, dealing, with, a, us, counterparty,...</td>\n",
       "      <td>[anytime, attached, dealing, with, a, us, coun...</td>\n",
       "      <td>[4998, 1970, 5463, 2589, 5934, 5674, 6467, 222...</td>\n",
       "      <td>[anytime, attached, dealing, with, a, us, coun...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[felt, that, out, of, shape, so, what, are, yo...</td>\n",
       "      <td>[is, the, filename, tran, enron, north, americ...</td>\n",
       "      <td>[1384, 208, 1676, 6159, 4880, 3837, 3576, 86, ...</td>\n",
       "      <td>[is, the, filename, tran, enron, north, americ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[my, comments, on, bob, s, memo, thanks, &lt;EOS&gt;]</td>\n",
       "      <td>[office, number, &lt;EOS&gt;]</td>\n",
       "      <td>[2315, 6460, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[office, number, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;...</td>\n",
       "      <td>[True, True, True]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[let, you, know, when, they, settle, it, prebo...</td>\n",
       "      <td>[but, we, should, know, soon, i, ll, e, mail, ...</td>\n",
       "      <td>[595, 4780, 4399, 3832, 3973, 439, 1179, 1450,...</td>\n",
       "      <td>[but, we, should, know, soon, i, ll, e, mail, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[likewise, so, who, is, the, lucky, person, fo...</td>\n",
       "      <td>[think, a, develop, engineer, initialled, for,...</td>\n",
       "      <td>[5675, 5934, 2305, 2431, 3475, 2881, 1799, 152...</td>\n",
       "      <td>[think, a, develop, engineer, initialled, for,...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[has, been, changed, yet, ?, calc, these, deal...</td>\n",
       "      <td>[you, re, right, i, ve, changed, this, deal, i...</td>\n",
       "      <td>[290, 6792, 759, 439, 5632, 3708, 175, 2146, 5...</td>\n",
       "      <td>[you, re, right, i, ve, changed, this, deal, i...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[as, soon, as, you, like, enron, north, americ...</td>\n",
       "      <td>[i, think, it, s, a, nice, idea, say, thanks, ...</td>\n",
       "      <td>[439, 5675, 6806, 2255, 5934, 4185, 1998, 6226...</td>\n",
       "      <td>[i, think, it, s, a, nice, idea, say, thanks, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[here, is, the, swap, confirmations, take, out...</td>\n",
       "      <td>[here, are, the, swap, confirmations, take, ou...</td>\n",
       "      <td>[1821, 6826, 208, 296, 1311, 803, 279, 1, 0, 0...</td>\n",
       "      <td>[here, are, the, swap, confirmations, take, ou...</td>\n",
       "      <td>[True, True, True, True, True, True, True, True]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[anxious, to, sign, please, advise, thanks, en...</td>\n",
       "      <td>[resolved, ?, i, left, a, message, with, tracy...</td>\n",
       "      <td>[2616, 2222, 439, 955, 5934, 1415, 2589, 2076,...</td>\n",
       "      <td>[resolved, ?, i, left, a, message, with, tracy...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[enron, north, america, corp, not, be, in, hou...</td>\n",
       "      <td>[thanks, i, m, looking, at, august, jean, is, ...</td>\n",
       "      <td>[6261, 439, 2006, 4429, 2132, 5595, 3879, 1384...</td>\n",
       "      <td>[thanks, i, m, looking, at, august, jean, is, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[then, is, already, moved, it, just, needs, to...</td>\n",
       "      <td>[is, being, sold, to, icc, on, deal, what, is,...</td>\n",
       "      <td>[1384, 3974, 3799, 818, 5927, 1654, 2146, 2826...</td>\n",
       "      <td>[is, being, sold, to, icc, on, deal, what, is,...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[management, pwr, &lt;EOS&gt;]</td>\n",
       "      <td>[management, gas, management, pwr, &lt;EOS&gt;]</td>\n",
       "      <td>[4593, 3044, 4593, 6525, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[management, gas, management, pwr, &lt;EOS&gt;, &lt;PAD...</td>\n",
       "      <td>[True, True, True, True, True]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[they, did, this, right, with, you, in, the, s...</td>\n",
       "      <td>[enron, north, america, corp, list, will, know...</td>\n",
       "      <td>[4880, 3837, 3576, 86, 4136, 5265, 3832, 3234,...</td>\n",
       "      <td>[enron, north, america, corp, list, will, know...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[hi, sara, hope, you, had, a, good, time, in, ...</td>\n",
       "      <td>[no, thanks, &lt;EOS&gt;]</td>\n",
       "      <td>[5253, 6261, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[no, thanks, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;...</td>\n",
       "      <td>[True, True, True]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[sometime, today, to, talk, further, about, th...</td>\n",
       "      <td>[feel, i, fit, that, profile, and, am, excited...</td>\n",
       "      <td>[3209, 439, 3858, 4786, 3892, 4533, 4649, 2519...</td>\n",
       "      <td>[feel, i, fit, that, profile, and, am, excited...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[i, will, take, a, spot, the, enron, center, g...</td>\n",
       "      <td>[i, would, like, to, move, to, the, new, garag...</td>\n",
       "      <td>[439, 4371, 4505, 818, 1810, 818, 208, 5740, 4...</td>\n",
       "      <td>[i, would, like, to, move, to, the, new, garag...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[i, do, not, appear, to, have, it, &lt;EOS&gt;]</td>\n",
       "      <td>[for, it, &lt;EOS&gt;]</td>\n",
       "      <td>[2881, 6806, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[for, it, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;...</td>\n",
       "      <td>[True, True, True]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[abb, would, not, buy, back, the, unit, except...</td>\n",
       "      <td>[he, s, re, trading, on, the, retainage, let, ...</td>\n",
       "      <td>[1648, 2255, 6792, 658, 1654, 208, 4849, 1141,...</td>\n",
       "      <td>[he, s, re, trading, on, the, retainage, let, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[thanks, man, &lt;EOS&gt;]</td>\n",
       "      <td>[thanks, a, lot, i, appreciate, your, kind, wo...</td>\n",
       "      <td>[6261, 5934, 4171, 439, 4999, 4526, 1980, 5637...</td>\n",
       "      <td>[thanks, a, lot, i, appreciate, your, kind, wo...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[i, will, attend, items, can, be, ordered, tha...</td>\n",
       "      <td>[i, plan, to, attend, items, can, be, ordered,...</td>\n",
       "      <td>[439, 259, 818, 4491, 1846, 2545, 3249, 2217, ...</td>\n",
       "      <td>[i, plan, to, attend, items, can, be, ordered,...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[for, you, too, what, is, new, with, you, ?, &lt;...</td>\n",
       "      <td>[how, about, ali, i, hate, pms, saler, ?, how,...</td>\n",
       "      <td>[4361, 4742, 964, 439, 198, 4892, 5423, 2222, ...</td>\n",
       "      <td>[how, about, ali, i, hate, pms, saler, ?, how,...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[to, danny, mccarty, et, s, enron, get, to, mm...</td>\n",
       "      <td>[getting, emails, to, go, through, to, him, am...</td>\n",
       "      <td>[2418, 1356, 818, 464, 6022, 818, 1344, 4649, ...</td>\n",
       "      <td>[getting, emails, to, go, through, to, him, am...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[big, will, wonders, never, cease, condolences...</td>\n",
       "      <td>[over, guys, flush, out, the, shortcomings, of...</td>\n",
       "      <td>[153, 601, 6020, 279, 208, 943, 5505, 985, 435...</td>\n",
       "      <td>[over, guys, flush, out, the, shortcomings, of...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[are, you, sure, we, have, a, contract, with, ...</td>\n",
       "      <td>[i, am, working, on, getting, the, number, it,...</td>\n",
       "      <td>[439, 4649, 3614, 1654, 2418, 208, 6460, 6806,...</td>\n",
       "      <td>[i, am, working, on, getting, the, number, it,...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[entity, has, had, some, or, all, of, its, ass...</td>\n",
       "      <td>[confirm, to, sandra, please, advise, enron, n...</td>\n",
       "      <td>[4297, 818, 5933, 7196, 3499, 4880, 3837, 3576...</td>\n",
       "      <td>[confirm, to, sandra, please, advise, enron, n...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>[enron, north, america, corp, good, news, comp...</td>\n",
       "      <td>[program, ?, &lt;EOS&gt;]</td>\n",
       "      <td>[4136, 2222, 5984, 836, 5075, 1210, 2255, 4745...</td>\n",
       "      <td>[list, ?, not, sure, if, she, s, still, with, ...</td>\n",
       "      <td>[False, True, False]</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>[issues, with, you, before, we, could, continu...</td>\n",
       "      <td>[call, if, you, wish, to, discuss, this, furth...</td>\n",
       "      <td>[1156, 5934, 4872, 1069, 4533, 3571, 110, 279,...</td>\n",
       "      <td>[have, a, great, time, and, definitely, hang, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>[tetco, wla, tetco, stx, and, tetco, ela, for,...</td>\n",
       "      <td>[could, you, get, me, the, gas, daily, s, for,...</td>\n",
       "      <td>[5427, 6672, 6618, 2881, 6681, 7137, 2826, 290...</td>\n",
       "      <td>[yes, pdt, works, for, me, understand, what, y...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>[i, will, call, you, later, could, you, please...</td>\n",
       "      <td>[the, credit, worksheet, as, some, of, the, nu...</td>\n",
       "      <td>[4880, 3837, 3576, 86, 6816, 1930, 5452, 5689,...</td>\n",
       "      <td>[enron, north, america, corp, grant, did, li, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>[i, have, enclosed, a, draft, of, the, letter,...</td>\n",
       "      <td>[rolling, otherwise, things, will, sit, around...</td>\n",
       "      <td>[5253, 5253, 5457, 439, 5265, 1460, 5793, 818,...</td>\n",
       "      <td>[no, no, updates, i, will, ask, brian, to, res...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>[enron, capital, trade, resources, corp, happy...</td>\n",
       "      <td>[school, and, cant, leave, there, until, see, ...</td>\n",
       "      <td>[3251, 2914, 2222, 2222, 2222, 2642, 4505, 393...</td>\n",
       "      <td>[butt, burn, ?, ?, ?, looks, like, they, will,...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>[opinion, and, or, resolution, that, i, receiv...</td>\n",
       "      <td>[yes, that, would, be, helpful, let, me, know,...</td>\n",
       "      <td>[1357, 4780, 2383, 439, 2732, 5441, 2881, 5934...</td>\n",
       "      <td>[as, we, spoke, i, got, scheduled, for, a, too...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>[during, the, inspection, &lt;EOS&gt;]</td>\n",
       "      <td>[again, during, the, inspection, &lt;EOS&gt;]</td>\n",
       "      <td>[6412, 290, 741, 4742, 6590, 2222, 4996, 4538,...</td>\n",
       "      <td>[do, you, remember, about, exceed, ?, interact...</td>\n",
       "      <td>[False, False, False, False, False]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>[confirm, ?, let, me, know, confirmations, wha...</td>\n",
       "      <td>[deal, great, thanks, confirm, ?, let, me, kno...</td>\n",
       "      <td>[5893, 4149, 307, 208, 1245, 818, 1935, 4780, ...</td>\n",
       "      <td>[all, just, spread, the, word, to, anyone, we,...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>[weekend, time, is, running, out, and, we, nee...</td>\n",
       "      <td>[i, will, pledge, to, him, weekend, time, is, ...</td>\n",
       "      <td>[6466, 2146, 2238, 1753, 279, 2589, 3309, 724,...</td>\n",
       "      <td>[supply, deal, gets, booked, out, with, sale, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>[me, to, bow, and, scrape, the, next, time, yo...</td>\n",
       "      <td>[your, ring, or, something, like, that, from, ...</td>\n",
       "      <td>[1397, 5457, 1654, 4388, 208, 5091, 1988, 4017...</td>\n",
       "      <td>[any, updates, on, adding, the, correct, legal...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>[count, can, youu, please, confirm, this, than...</td>\n",
       "      <td>[count, can, youu, please, confirm, this, than...</td>\n",
       "      <td>[6806, 2255, 1747, 7196, 464, 2385, 4533, 3329...</td>\n",
       "      <td>[it, s, done, please, go, ahead, and, change, ...</td>\n",
       "      <td>[False, False, False, True, False, False, Fals...</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>[thanks, you, re, the, best, &lt;EOS&gt;]</td>\n",
       "      <td>[thanks, see, you, tonite, looking, forward, t...</td>\n",
       "      <td>[4149, 6015, 4705, 5934, 4359, 2146, 279, 5505...</td>\n",
       "      <td>[just, might, get, a, sweet, deal, out, of, it...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>[sorry, that, just, slipped, out, i, ll, have,...</td>\n",
       "      <td>[the, recent, promotion, i, hope, to, meet, ex...</td>\n",
       "      <td>[6261, 2426, 2881, 4526, 1069, 1479, 6294, 229...</td>\n",
       "      <td>[thanks, again, for, your, time, thursday, gov...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>[can, you, please, send, my, itinerary, to, lu...</td>\n",
       "      <td>[eric, sorry, for, the, delay, it, s, a, busy,...</td>\n",
       "      <td>[4533, 4075, 2512, 2132, 6092, 4786, 2255, 436...</td>\n",
       "      <td>[and, accounting, treatment, at, least, that, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>[we, decide, that, is, needed, &lt;EOS&gt;]</td>\n",
       "      <td>[for, vacation, friday, if, this, is, not, fea...</td>\n",
       "      <td>[818, 6005, 4475, 4933, 4639, 6895, 3692, 1, 0...</td>\n",
       "      <td>[to, co, op, city, one, year, term, &lt;EOS&gt;, &lt;PA...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>[demand, to, go, up, were, you, referring, to,...</td>\n",
       "      <td>[absolutely, no, need, to, be, sorry, my, dear...</td>\n",
       "      <td>[6876, 4185, 6758, 1787, 3366, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[ouch, nice, game, stretch, rights, &lt;EOS&gt;, &lt;PA...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>[sounds, familiar, isn, t, that, what, butch, ...</td>\n",
       "      <td>[anything, yet, &lt;EOS&gt;]</td>\n",
       "      <td>[1384, 4635, 6386, 290, 6818, 2637, 6826, 290,...</td>\n",
       "      <td>[is, mark, sending, you, these, or, are, you, ...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>[how, does, that, sound, ?, to, vicki, to, pre...</td>\n",
       "      <td>[i, ll, follow, back, with, them, and, get, ba...</td>\n",
       "      <td>[5327, 5481, 2637, 6595, 2386, 4493, 2255, 967...</td>\n",
       "      <td>[even, desired, or, necessary, jet, ski, s, fl...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>[congratulations, drew, we, look, forward, to,...</td>\n",
       "      <td>[your, family, will, love, living, in, houston...</td>\n",
       "      <td>[6115, 2589, 6310, 4281, 2637, 208, 4861, 1, 0...</td>\n",
       "      <td>[now, with, egm, ena, or, the, cp, &lt;EOS&gt;, &lt;PAD...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>[leboeuf, i, think, there, must, be, some, add...</td>\n",
       "      <td>[contact, him, all, first, to, see, what, we, ...</td>\n",
       "      <td>[626, 818, 4705, 290, 339, 1, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[try, to, get, you, info, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;,...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>[i, do, not, find, any, existing, agreements, ...</td>\n",
       "      <td>[are, you, sure, we, have, a, contract, with, ...</td>\n",
       "      <td>[175, 4621, 2388, 2613, 393, 1083, 2388, 4953,...</td>\n",
       "      <td>[this, doesn, t, mean, they, haven, t, tried, ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>[make, sense, to, you, ?, discounted, rate, pl...</td>\n",
       "      <td>[discounted, rate, please, contact, me, at, x,...</td>\n",
       "      <td>[5505, 4191, 1988, 1147, 5577, 5384, 2861, 488...</td>\n",
       "      <td>[of, outside, legal, costs, by, business, unit...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>[when, will, he, be, calling, in, ?, at, pm, c...</td>\n",
       "      <td>[that, will, help, we, ve, deferred, him, to, ...</td>\n",
       "      <td>[6826, 290, 2867, 208, 2057, 2881, 5674, 2222,...</td>\n",
       "      <td>[are, you, preparing, the, information, for, u...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>[we, ll, get, this, deal, out, of, the, new, c...</td>\n",
       "      <td>[we, have, a, match, up, and, it, s, powerex, ...</td>\n",
       "      <td>[3075, 7196, 2720, 208, 1970, 6261, 2881, 4526...</td>\n",
       "      <td>[kay, please, review, the, attached, thanks, f...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>[attached, is, the, weekly, status, report, re...</td>\n",
       "      <td>[attached, is, the, weekly, ena, litigation, s...</td>\n",
       "      <td>[2589, 4786, 4639, 4149, 2985, 6681, 5934, 63,...</td>\n",
       "      <td>[with, that, one, just, give, me, a, call, &lt;EO...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>[term, sheet, for, huber, deal, agreements, le...</td>\n",
       "      <td>[here, s, one, carol, did, &lt;EOS&gt;]</td>\n",
       "      <td>[439, 1179, 6548, 660, 2179, 1821, 5505, 1397,...</td>\n",
       "      <td>[i, ll, come, find, u, here, of, any, body, go...</td>\n",
       "      <td>[False, False, False, False, False, False]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>[per, your, request, detail, then, &lt;EOS&gt;]</td>\n",
       "      <td>[is, there, something, i, can, help, you, with...</td>\n",
       "      <td>[724, 439, 2006, 615, 4533, 759, 6115, 4533, 1...</td>\n",
       "      <td>[deals, i, m, killing, and, right, now, and, p...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>[you, know, any, minute, the, new, counterpart...</td>\n",
       "      <td>[california, energy, resource, schedulers, cer...</td>\n",
       "      <td>[4880, 3447, 3619, 4536, 86, 2126, 5792, 1, 0,...</td>\n",
       "      <td>[enron, capital, trade, resources, corp, subje...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>[an, email, problem, ?, &lt;EOS&gt;]</td>\n",
       "      <td>[least, that, s, the, poop, that, i, ve, recei...</td>\n",
       "      <td>[1368, 6799, 818, 5036, 279, 5934, 3172, 2883,...</td>\n",
       "      <td>[letter, going, to, send, out, a, complete, se...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     [reporting, agency, and, data, source, informa...   \n",
       "1     [we, don, t, hear, from, him, by, noon, i, wou...   \n",
       "2     [month, changes, they, re, very, simple, to, m...   \n",
       "3     [subject, re, dinner, on, friday, ?, subject, ...   \n",
       "4     [thanksi, have, no, revisions, enjoy, the, par...   \n",
       "5     [attached, dealing, with, a, us, counterparty,...   \n",
       "6     [felt, that, out, of, shape, so, what, are, yo...   \n",
       "7       [my, comments, on, bob, s, memo, thanks, <EOS>]   \n",
       "8     [let, you, know, when, they, settle, it, prebo...   \n",
       "9     [likewise, so, who, is, the, lucky, person, fo...   \n",
       "10    [has, been, changed, yet, ?, calc, these, deal...   \n",
       "11    [as, soon, as, you, like, enron, north, americ...   \n",
       "12    [here, is, the, swap, confirmations, take, out...   \n",
       "13    [anxious, to, sign, please, advise, thanks, en...   \n",
       "14    [enron, north, america, corp, not, be, in, hou...   \n",
       "15    [then, is, already, moved, it, just, needs, to...   \n",
       "16                             [management, pwr, <EOS>]   \n",
       "17    [they, did, this, right, with, you, in, the, s...   \n",
       "18    [hi, sara, hope, you, had, a, good, time, in, ...   \n",
       "19    [sometime, today, to, talk, further, about, th...   \n",
       "20    [i, will, take, a, spot, the, enron, center, g...   \n",
       "21            [i, do, not, appear, to, have, it, <EOS>]   \n",
       "22    [abb, would, not, buy, back, the, unit, except...   \n",
       "23                                 [thanks, man, <EOS>]   \n",
       "24    [i, will, attend, items, can, be, ordered, tha...   \n",
       "25    [for, you, too, what, is, new, with, you, ?, <...   \n",
       "26    [to, danny, mccarty, et, s, enron, get, to, mm...   \n",
       "27    [big, will, wonders, never, cease, condolences...   \n",
       "28    [are, you, sure, we, have, a, contract, with, ...   \n",
       "29    [entity, has, had, some, or, all, of, its, ass...   \n",
       "...                                                 ...   \n",
       "3470  [enron, north, america, corp, good, news, comp...   \n",
       "3471  [issues, with, you, before, we, could, continu...   \n",
       "3472  [tetco, wla, tetco, stx, and, tetco, ela, for,...   \n",
       "3473  [i, will, call, you, later, could, you, please...   \n",
       "3474  [i, have, enclosed, a, draft, of, the, letter,...   \n",
       "3475  [enron, capital, trade, resources, corp, happy...   \n",
       "3476  [opinion, and, or, resolution, that, i, receiv...   \n",
       "3477                   [during, the, inspection, <EOS>]   \n",
       "3478  [confirm, ?, let, me, know, confirmations, wha...   \n",
       "3479  [weekend, time, is, running, out, and, we, nee...   \n",
       "3480  [me, to, bow, and, scrape, the, next, time, yo...   \n",
       "3481  [count, can, youu, please, confirm, this, than...   \n",
       "3482                [thanks, you, re, the, best, <EOS>]   \n",
       "3483  [sorry, that, just, slipped, out, i, ll, have,...   \n",
       "3484  [can, you, please, send, my, itinerary, to, lu...   \n",
       "3485              [we, decide, that, is, needed, <EOS>]   \n",
       "3486  [demand, to, go, up, were, you, referring, to,...   \n",
       "3487  [sounds, familiar, isn, t, that, what, butch, ...   \n",
       "3488  [how, does, that, sound, ?, to, vicki, to, pre...   \n",
       "3489  [congratulations, drew, we, look, forward, to,...   \n",
       "3490  [leboeuf, i, think, there, must, be, some, add...   \n",
       "3491  [i, do, not, find, any, existing, agreements, ...   \n",
       "3492  [make, sense, to, you, ?, discounted, rate, pl...   \n",
       "3493  [when, will, he, be, calling, in, ?, at, pm, c...   \n",
       "3494  [we, ll, get, this, deal, out, of, the, new, c...   \n",
       "3495  [attached, is, the, weekly, status, report, re...   \n",
       "3496  [term, sheet, for, huber, deal, agreements, le...   \n",
       "3497          [per, your, request, detail, then, <EOS>]   \n",
       "3498  [you, know, any, minute, the, new, counterpart...   \n",
       "3499                     [an, email, problem, ?, <EOS>]   \n",
       "\n",
       "                                                 output  \\\n",
       "0     [enron, capital, trade, resources, corp, repor...   \n",
       "1     [be, cut, off, this, cold, november, any, prob...   \n",
       "2                             [these, are, done, <EOS>]   \n",
       "3     [subject, re, dinner, on, friday, ?, subject, ...   \n",
       "4     [and, positions, circulate, the, plan, early, ...   \n",
       "5     [anytime, attached, dealing, with, a, us, coun...   \n",
       "6     [is, the, filename, tran, enron, north, americ...   \n",
       "7                               [office, number, <EOS>]   \n",
       "8     [but, we, should, know, soon, i, ll, e, mail, ...   \n",
       "9     [think, a, develop, engineer, initialled, for,...   \n",
       "10    [you, re, right, i, ve, changed, this, deal, i...   \n",
       "11    [i, think, it, s, a, nice, idea, say, thanks, ...   \n",
       "12    [here, are, the, swap, confirmations, take, ou...   \n",
       "13    [resolved, ?, i, left, a, message, with, tracy...   \n",
       "14    [thanks, i, m, looking, at, august, jean, is, ...   \n",
       "15    [is, being, sold, to, icc, on, deal, what, is,...   \n",
       "16            [management, gas, management, pwr, <EOS>]   \n",
       "17    [enron, north, america, corp, list, will, know...   \n",
       "18                                  [no, thanks, <EOS>]   \n",
       "19    [feel, i, fit, that, profile, and, am, excited...   \n",
       "20    [i, would, like, to, move, to, the, new, garag...   \n",
       "21                                     [for, it, <EOS>]   \n",
       "22    [he, s, re, trading, on, the, retainage, let, ...   \n",
       "23    [thanks, a, lot, i, appreciate, your, kind, wo...   \n",
       "24    [i, plan, to, attend, items, can, be, ordered,...   \n",
       "25    [how, about, ali, i, hate, pms, saler, ?, how,...   \n",
       "26    [getting, emails, to, go, through, to, him, am...   \n",
       "27    [over, guys, flush, out, the, shortcomings, of...   \n",
       "28    [i, am, working, on, getting, the, number, it,...   \n",
       "29    [confirm, to, sandra, please, advise, enron, n...   \n",
       "...                                                 ...   \n",
       "3470                                [program, ?, <EOS>]   \n",
       "3471  [call, if, you, wish, to, discuss, this, furth...   \n",
       "3472  [could, you, get, me, the, gas, daily, s, for,...   \n",
       "3473  [the, credit, worksheet, as, some, of, the, nu...   \n",
       "3474  [rolling, otherwise, things, will, sit, around...   \n",
       "3475  [school, and, cant, leave, there, until, see, ...   \n",
       "3476  [yes, that, would, be, helpful, let, me, know,...   \n",
       "3477            [again, during, the, inspection, <EOS>]   \n",
       "3478  [deal, great, thanks, confirm, ?, let, me, kno...   \n",
       "3479  [i, will, pledge, to, him, weekend, time, is, ...   \n",
       "3480  [your, ring, or, something, like, that, from, ...   \n",
       "3481  [count, can, youu, please, confirm, this, than...   \n",
       "3482  [thanks, see, you, tonite, looking, forward, t...   \n",
       "3483  [the, recent, promotion, i, hope, to, meet, ex...   \n",
       "3484  [eric, sorry, for, the, delay, it, s, a, busy,...   \n",
       "3485  [for, vacation, friday, if, this, is, not, fea...   \n",
       "3486  [absolutely, no, need, to, be, sorry, my, dear...   \n",
       "3487                             [anything, yet, <EOS>]   \n",
       "3488  [i, ll, follow, back, with, them, and, get, ba...   \n",
       "3489  [your, family, will, love, living, in, houston...   \n",
       "3490  [contact, him, all, first, to, see, what, we, ...   \n",
       "3491  [are, you, sure, we, have, a, contract, with, ...   \n",
       "3492  [discounted, rate, please, contact, me, at, x,...   \n",
       "3493  [that, will, help, we, ve, deferred, him, to, ...   \n",
       "3494  [we, have, a, match, up, and, it, s, powerex, ...   \n",
       "3495  [attached, is, the, weekly, ena, litigation, s...   \n",
       "3496                  [here, s, one, carol, did, <EOS>]   \n",
       "3497  [is, there, something, i, can, help, you, with...   \n",
       "3498  [california, energy, resource, schedulers, cer...   \n",
       "3499  [least, that, s, the, poop, that, i, ve, recei...   \n",
       "\n",
       "                                              inference  \\\n",
       "0     [4880, 3447, 3619, 4536, 86, 3748, 3446, 4533,...   \n",
       "1     [3249, 1422, 6289, 175, 4302, 1461, 1397, 4683...   \n",
       "2     [6818, 6826, 1747, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [2126, 6792, 6346, 1654, 325, 2222, 2126, 6792...   \n",
       "4     [4533, 6637, 2496, 208, 259, 1521, 175, 1306, ...   \n",
       "5     [4998, 1970, 5463, 2589, 5934, 5674, 6467, 222...   \n",
       "6     [1384, 208, 1676, 6159, 4880, 3837, 3576, 86, ...   \n",
       "7     [2315, 6460, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8     [595, 4780, 4399, 3832, 3973, 439, 1179, 1450,...   \n",
       "9     [5675, 5934, 2305, 2431, 3475, 2881, 1799, 152...   \n",
       "10    [290, 6792, 759, 439, 5632, 3708, 175, 2146, 5...   \n",
       "11    [439, 5675, 6806, 2255, 5934, 4185, 1998, 6226...   \n",
       "12    [1821, 6826, 208, 296, 1311, 803, 279, 1, 0, 0...   \n",
       "13    [2616, 2222, 439, 955, 5934, 1415, 2589, 2076,...   \n",
       "14    [6261, 439, 2006, 4429, 2132, 5595, 3879, 1384...   \n",
       "15    [1384, 3974, 3799, 818, 5927, 1654, 2146, 2826...   \n",
       "16    [4593, 3044, 4593, 6525, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "17    [4880, 3837, 3576, 86, 4136, 5265, 3832, 3234,...   \n",
       "18    [5253, 6261, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "19    [3209, 439, 3858, 4786, 3892, 4533, 4649, 2519...   \n",
       "20    [439, 4371, 4505, 818, 1810, 818, 208, 5740, 4...   \n",
       "21    [2881, 6806, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "22    [1648, 2255, 6792, 658, 1654, 208, 4849, 1141,...   \n",
       "23    [6261, 5934, 4171, 439, 4999, 4526, 1980, 5637...   \n",
       "24    [439, 259, 818, 4491, 1846, 2545, 3249, 2217, ...   \n",
       "25    [4361, 4742, 964, 439, 198, 4892, 5423, 2222, ...   \n",
       "26    [2418, 1356, 818, 464, 6022, 818, 1344, 4649, ...   \n",
       "27    [153, 601, 6020, 279, 208, 943, 5505, 985, 435...   \n",
       "28    [439, 4649, 3614, 1654, 2418, 208, 6460, 6806,...   \n",
       "29    [4297, 818, 5933, 7196, 3499, 4880, 3837, 3576...   \n",
       "...                                                 ...   \n",
       "3470  [4136, 2222, 5984, 836, 5075, 1210, 2255, 4745...   \n",
       "3471  [1156, 5934, 4872, 1069, 4533, 3571, 110, 279,...   \n",
       "3472  [5427, 6672, 6618, 2881, 6681, 7137, 2826, 290...   \n",
       "3473  [4880, 3837, 3576, 86, 6816, 1930, 5452, 5689,...   \n",
       "3474  [5253, 5253, 5457, 439, 5265, 1460, 5793, 818,...   \n",
       "3475  [3251, 2914, 2222, 2222, 2222, 2642, 4505, 393...   \n",
       "3476  [1357, 4780, 2383, 439, 2732, 5441, 2881, 5934...   \n",
       "3477  [6412, 290, 741, 4742, 6590, 2222, 4996, 4538,...   \n",
       "3478  [5893, 4149, 307, 208, 1245, 818, 1935, 4780, ...   \n",
       "3479  [6466, 2146, 2238, 1753, 279, 2589, 3309, 724,...   \n",
       "3480  [1397, 5457, 1654, 4388, 208, 5091, 1988, 4017...   \n",
       "3481  [6806, 2255, 1747, 7196, 464, 2385, 4533, 3329...   \n",
       "3482  [4149, 6015, 4705, 5934, 4359, 2146, 279, 5505...   \n",
       "3483  [6261, 2426, 2881, 4526, 1069, 1479, 6294, 229...   \n",
       "3484  [4533, 4075, 2512, 2132, 6092, 4786, 2255, 436...   \n",
       "3485  [818, 6005, 4475, 4933, 4639, 6895, 3692, 1, 0...   \n",
       "3486  [6876, 4185, 6758, 1787, 3366, 1, 0, 0, 0, 0, ...   \n",
       "3487  [1384, 4635, 6386, 290, 6818, 2637, 6826, 290,...   \n",
       "3488  [5327, 5481, 2637, 6595, 2386, 4493, 2255, 967...   \n",
       "3489  [6115, 2589, 6310, 4281, 2637, 208, 4861, 1, 0...   \n",
       "3490  [626, 818, 4705, 290, 339, 1, 0, 0, 0, 0, 0, 0...   \n",
       "3491  [175, 4621, 2388, 2613, 393, 1083, 2388, 4953,...   \n",
       "3492  [5505, 4191, 1988, 1147, 5577, 5384, 2861, 488...   \n",
       "3493  [6826, 290, 2867, 208, 2057, 2881, 5674, 2222,...   \n",
       "3494  [3075, 7196, 2720, 208, 1970, 6261, 2881, 4526...   \n",
       "3495  [2589, 4786, 4639, 4149, 2985, 6681, 5934, 63,...   \n",
       "3496  [439, 1179, 6548, 660, 2179, 1821, 5505, 1397,...   \n",
       "3497  [724, 439, 2006, 615, 4533, 759, 6115, 4533, 1...   \n",
       "3498  [4880, 3447, 3619, 4536, 86, 2126, 5792, 1, 0,...   \n",
       "3499  [1368, 6799, 818, 5036, 279, 5934, 3172, 2883,...   \n",
       "\n",
       "                                         inference_sent  \\\n",
       "0     [enron, capital, trade, resources, corp, repor...   \n",
       "1     [be, cut, off, this, cold, november, any, prob...   \n",
       "2     [these, are, done, <EOS>, <PAD>, <PAD>, <PAD>,...   \n",
       "3     [subject, re, dinner, on, friday, ?, subject, ...   \n",
       "4     [and, positions, circulate, the, plan, early, ...   \n",
       "5     [anytime, attached, dealing, with, a, us, coun...   \n",
       "6     [is, the, filename, tran, enron, north, americ...   \n",
       "7     [office, number, <EOS>, <PAD>, <PAD>, <PAD>, <...   \n",
       "8     [but, we, should, know, soon, i, ll, e, mail, ...   \n",
       "9     [think, a, develop, engineer, initialled, for,...   \n",
       "10    [you, re, right, i, ve, changed, this, deal, i...   \n",
       "11    [i, think, it, s, a, nice, idea, say, thanks, ...   \n",
       "12    [here, are, the, swap, confirmations, take, ou...   \n",
       "13    [resolved, ?, i, left, a, message, with, tracy...   \n",
       "14    [thanks, i, m, looking, at, august, jean, is, ...   \n",
       "15    [is, being, sold, to, icc, on, deal, what, is,...   \n",
       "16    [management, gas, management, pwr, <EOS>, <PAD...   \n",
       "17    [enron, north, america, corp, list, will, know...   \n",
       "18    [no, thanks, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>...   \n",
       "19    [feel, i, fit, that, profile, and, am, excited...   \n",
       "20    [i, would, like, to, move, to, the, new, garag...   \n",
       "21    [for, it, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <...   \n",
       "22    [he, s, re, trading, on, the, retainage, let, ...   \n",
       "23    [thanks, a, lot, i, appreciate, your, kind, wo...   \n",
       "24    [i, plan, to, attend, items, can, be, ordered,...   \n",
       "25    [how, about, ali, i, hate, pms, saler, ?, how,...   \n",
       "26    [getting, emails, to, go, through, to, him, am...   \n",
       "27    [over, guys, flush, out, the, shortcomings, of...   \n",
       "28    [i, am, working, on, getting, the, number, it,...   \n",
       "29    [confirm, to, sandra, please, advise, enron, n...   \n",
       "...                                                 ...   \n",
       "3470  [list, ?, not, sure, if, she, s, still, with, ...   \n",
       "3471  [have, a, great, time, and, definitely, hang, ...   \n",
       "3472  [yes, pdt, works, for, me, understand, what, y...   \n",
       "3473  [enron, north, america, corp, grant, did, li, ...   \n",
       "3474  [no, no, updates, i, will, ask, brian, to, res...   \n",
       "3475  [butt, burn, ?, ?, ?, looks, like, they, will,...   \n",
       "3476  [as, we, spoke, i, got, scheduled, for, a, too...   \n",
       "3477  [do, you, remember, about, exceed, ?, interact...   \n",
       "3478  [all, just, spread, the, word, to, anyone, we,...   \n",
       "3479  [supply, deal, gets, booked, out, with, sale, ...   \n",
       "3480  [any, updates, on, adding, the, correct, legal...   \n",
       "3481  [it, s, done, please, go, ahead, and, change, ...   \n",
       "3482  [just, might, get, a, sweet, deal, out, of, it...   \n",
       "3483  [thanks, again, for, your, time, thursday, gov...   \n",
       "3484  [and, accounting, treatment, at, least, that, ...   \n",
       "3485  [to, co, op, city, one, year, term, <EOS>, <PA...   \n",
       "3486  [ouch, nice, game, stretch, rights, <EOS>, <PA...   \n",
       "3487  [is, mark, sending, you, these, or, are, you, ...   \n",
       "3488  [even, desired, or, necessary, jet, ski, s, fl...   \n",
       "3489  [now, with, egm, ena, or, the, cp, <EOS>, <PAD...   \n",
       "3490  [try, to, get, you, info, <EOS>, <PAD>, <PAD>,...   \n",
       "3491  [this, doesn, t, mean, they, haven, t, tried, ...   \n",
       "3492  [of, outside, legal, costs, by, business, unit...   \n",
       "3493  [are, you, preparing, the, information, for, u...   \n",
       "3494  [kay, please, review, the, attached, thanks, f...   \n",
       "3495  [with, that, one, just, give, me, a, call, <EO...   \n",
       "3496  [i, ll, come, find, u, here, of, any, body, go...   \n",
       "3497  [deals, i, m, killing, and, right, now, and, p...   \n",
       "3498  [enron, capital, trade, resources, corp, subje...   \n",
       "3499  [letter, going, to, send, out, a, complete, se...   \n",
       "\n",
       "                                              checkList  meanCheckList  \n",
       "0     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "1     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "2                              [True, True, True, True]       1.000000  \n",
       "3     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "4     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "5     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "6     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "7                                    [True, True, True]       1.000000  \n",
       "8     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "9     [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "10    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "11    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "12     [True, True, True, True, True, True, True, True]       1.000000  \n",
       "13    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "14    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "15    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "16                       [True, True, True, True, True]       1.000000  \n",
       "17    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "18                                   [True, True, True]       1.000000  \n",
       "19    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "20    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "21                                   [True, True, True]       1.000000  \n",
       "22    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "23    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "24    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "25    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "26    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "27    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "28    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "29    [True, True, True, True, True, True, True, Tru...       1.000000  \n",
       "...                                                 ...            ...  \n",
       "3470                               [False, True, False]       0.333333  \n",
       "3471  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3472  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3473  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3474  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3475  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3476  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3477                [False, False, False, False, False]       0.000000  \n",
       "3478  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3479  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3480  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3481  [False, False, False, True, False, False, Fals...       0.083333  \n",
       "3482  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3483  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3484  [False, False, False, False, False, False, Tru...       0.090909  \n",
       "3485  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3486  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3487                              [False, False, False]       0.000000  \n",
       "3488  [False, False, False, False, False, False, Fal...       0.071429  \n",
       "3489  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3490  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3491  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3492  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3493  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3494  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3495  [False, False, False, False, False, False, Fal...       0.111111  \n",
       "3496         [False, False, False, False, False, False]       0.000000  \n",
       "3497  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3498  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "3499  [False, False, False, False, False, False, Fal...       0.000000  \n",
       "\n",
       "[3500 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list(['how', 'about', '?', '<EOS>']),\n",
       "        list(['yea', 'how', 'about', '?', '<EOS>']),\n",
       "        list(['has', 'the', 'counterparty', 'ever', 'signed', 'confirms', '?', 'would', 'you', 'be', 'interested', 'in', 'meeting', 'today', 'at', '?', 'i', 'll', 'keep', 'you', 'updated', 'any', 'luck', 'with', 'morgan', 'williams', 'or', 'any', 'other', 'updates', '?', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])],\n",
       "       [list(['thanks', 'you', 're', 'the', 'best', '<EOS>']),\n",
       "        list(['thanks', 'see', 'you', 'tonite', 'looking', 'forward', 'to', 'it', '<EOS>']),\n",
       "        list(['dan', 'it', 'will', 'have', 'to', 'wait', 'i', 'will', 'be', 'back', 'in', 'early', 'january', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])],\n",
       "       [ list(['we', 'don', 't', 'hear', 'from', 'him', 'by', 'noon', 'i', 'would', 'go', 'with', 'it', 'approvals', 'with', 'global', 'finance', 'credit', 'and', 'rac', 'thanks', 'again', 'for', 'your', 'help', 'on', 'your', 'vacation', 'day', '<EOS>']),\n",
       "        list(['be', 'cut', 'off', 'this', 'cold', 'november', 'any', 'problem', 'with', 'this', '?', 'kay', 'here', 'is', 'my', 'attempt', 'to', 'turn', 'the', 'term', 'sheet', 'into', 'something', 'executable', 'rac', 'thanks', 'again', 'for', 'your', 'help', 'on', 'your', 'vacation', 'day', 'recipients', 'is', 'not', 'authorized', 'and', 'may', 'be', 'unlawful', '<EOS>']),\n",
       "        list(['of', 'what', 'happened', '?', 'just', 'let', 'me', 'know', 'and', 'we', 'll', 'do', 'what', 'we', 'can', 'to', 'help', 'please', 'let', 'me', 'know', 'the', 'details', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])],\n",
       "       ..., \n",
       "       [list(['per', 'your', 'request', 'detail', 'then', '<EOS>']),\n",
       "        list(['is', 'there', 'something', 'i', 'can', 'help', 'you', 'with', '?', 'per', 'your', 'request', 'detail', 'then', '<EOS>']),\n",
       "        list(['deals', 'i', 'm', 'killing', 'and', 'right', 'now', 'and', 'pls', 'verify', 'that', 'sean', 'or', 'diana', 'did', 'both', 'of', 'these', 'deals', 'twice', 'verified', 'with', 'diana', 'and', 'sean', 'these', 'should', 'be', 'apb', 'why', 'i', 'was', 'trying', 'to', 'get', 'these', 'deals', 'resolved', 'system', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])],\n",
       "       [ list(['you', 'know', 'any', 'minute', 'the', 'new', 'counterparty', 'status', 'thanks', 'enron', 'north', 'america', 'corp', 'know', '?', 'thanks', '<EOS>']),\n",
       "        list(['california', 'energy', 'resource', 'schedulers', 'cers', 'it', 's', 'been', 'changed', 'the', 'new', 'counterparty', 'status', 'thanks', 'enron', 'north', 'america', 'corp', 'know', '?', 'thanks', '<EOS>']),\n",
       "        list(['enron', 'capital', 'trade', 'resources', 'corp', 'subject', 'priceless', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])],\n",
       "       [list(['an', 'email', 'problem', '?', '<EOS>']),\n",
       "        list(['least', 'that', 's', 'the', 'poop', 'that', 'i', 've', 'received', 'thus', 'far', '<EOS>']),\n",
       "        list(['letter', 'going', 'to', 'send', 'out', 'a', 'complete', 'set', 'of', 'the', 'final', 'documents', '?', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])]], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric[df_metric['meanCheckList']==0][['input', 'output', 'inference_sent']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[reporting, agency, and, data, source, informa...</td>\n",
       "      <td>[enron, capital, trade, resources, corp, repor...</td>\n",
       "      <td>[4880, 3447, 3619, 4536, 86, 3748, 3446, 4533,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[we, don, t, hear, from, him, by, noon, i, wou...</td>\n",
       "      <td>[be, cut, off, this, cold, november, any, prob...</td>\n",
       "      <td>[3249, 1422, 6289, 175, 4302, 1461, 1397, 4683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[month, changes, they, re, very, simple, to, m...</td>\n",
       "      <td>[these, are, done, &lt;EOS&gt;]</td>\n",
       "      <td>[6818, 6826, 1747, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[subject, re, dinner, on, friday, ?, subject, ...</td>\n",
       "      <td>[subject, re, dinner, on, friday, ?, subject, ...</td>\n",
       "      <td>[2126, 6792, 6346, 1654, 325, 2222, 2126, 6792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thanksi, have, no, revisions, enjoy, the, par...</td>\n",
       "      <td>[and, positions, circulate, the, plan, early, ...</td>\n",
       "      <td>[4533, 6637, 2496, 208, 259, 1521, 175, 1306, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[attached, dealing, with, a, us, counterparty,...</td>\n",
       "      <td>[anytime, attached, dealing, with, a, us, coun...</td>\n",
       "      <td>[4998, 1970, 5463, 2589, 5934, 5674, 6467, 222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[felt, that, out, of, shape, so, what, are, yo...</td>\n",
       "      <td>[is, the, filename, tran, enron, north, americ...</td>\n",
       "      <td>[1384, 208, 1676, 6159, 4880, 3837, 3576, 86, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[my, comments, on, bob, s, memo, thanks, &lt;EOS&gt;]</td>\n",
       "      <td>[office, number, &lt;EOS&gt;]</td>\n",
       "      <td>[2315, 6460, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[let, you, know, when, they, settle, it, prebo...</td>\n",
       "      <td>[but, we, should, know, soon, i, ll, e, mail, ...</td>\n",
       "      <td>[595, 4780, 4399, 3832, 3973, 439, 1179, 1450,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[likewise, so, who, is, the, lucky, person, fo...</td>\n",
       "      <td>[think, a, develop, engineer, initialled, for,...</td>\n",
       "      <td>[5675, 5934, 2305, 2431, 3475, 2881, 1799, 152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[has, been, changed, yet, ?, calc, these, deal...</td>\n",
       "      <td>[you, re, right, i, ve, changed, this, deal, i...</td>\n",
       "      <td>[290, 6792, 759, 439, 5632, 3708, 175, 2146, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[as, soon, as, you, like, enron, north, americ...</td>\n",
       "      <td>[i, think, it, s, a, nice, idea, say, thanks, ...</td>\n",
       "      <td>[439, 5675, 6806, 2255, 5934, 4185, 1998, 6226...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[here, is, the, swap, confirmations, take, out...</td>\n",
       "      <td>[here, are, the, swap, confirmations, take, ou...</td>\n",
       "      <td>[1821, 6826, 208, 296, 1311, 803, 279, 1, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[anxious, to, sign, please, advise, thanks, en...</td>\n",
       "      <td>[resolved, ?, i, left, a, message, with, tracy...</td>\n",
       "      <td>[2616, 2222, 439, 955, 5934, 1415, 2589, 2076,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[enron, north, america, corp, not, be, in, hou...</td>\n",
       "      <td>[thanks, i, m, looking, at, august, jean, is, ...</td>\n",
       "      <td>[6261, 439, 2006, 4429, 2132, 5595, 3879, 1384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[then, is, already, moved, it, just, needs, to...</td>\n",
       "      <td>[is, being, sold, to, icc, on, deal, what, is,...</td>\n",
       "      <td>[1384, 3974, 3799, 818, 5927, 1654, 2146, 2826...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[management, pwr, &lt;EOS&gt;]</td>\n",
       "      <td>[management, gas, management, pwr, &lt;EOS&gt;]</td>\n",
       "      <td>[4593, 3044, 4593, 6525, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[they, did, this, right, with, you, in, the, s...</td>\n",
       "      <td>[enron, north, america, corp, list, will, know...</td>\n",
       "      <td>[4880, 3837, 3576, 86, 4136, 5265, 3832, 3234,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[hi, sara, hope, you, had, a, good, time, in, ...</td>\n",
       "      <td>[no, thanks, &lt;EOS&gt;]</td>\n",
       "      <td>[5253, 6261, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[sometime, today, to, talk, further, about, th...</td>\n",
       "      <td>[feel, i, fit, that, profile, and, am, excited...</td>\n",
       "      <td>[3209, 439, 3858, 4786, 3892, 4533, 4649, 2519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[i, will, take, a, spot, the, enron, center, g...</td>\n",
       "      <td>[i, would, like, to, move, to, the, new, garag...</td>\n",
       "      <td>[439, 4371, 4505, 818, 1810, 818, 208, 5740, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[i, do, not, appear, to, have, it, &lt;EOS&gt;]</td>\n",
       "      <td>[for, it, &lt;EOS&gt;]</td>\n",
       "      <td>[2881, 6806, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[abb, would, not, buy, back, the, unit, except...</td>\n",
       "      <td>[he, s, re, trading, on, the, retainage, let, ...</td>\n",
       "      <td>[1648, 2255, 6792, 658, 1654, 208, 4849, 1141,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[thanks, man, &lt;EOS&gt;]</td>\n",
       "      <td>[thanks, a, lot, i, appreciate, your, kind, wo...</td>\n",
       "      <td>[6261, 5934, 4171, 439, 4999, 4526, 1980, 5637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[i, will, attend, items, can, be, ordered, tha...</td>\n",
       "      <td>[i, plan, to, attend, items, can, be, ordered,...</td>\n",
       "      <td>[439, 259, 818, 4491, 1846, 2545, 3249, 2217, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[for, you, too, what, is, new, with, you, ?, &lt;...</td>\n",
       "      <td>[how, about, ali, i, hate, pms, saler, ?, how,...</td>\n",
       "      <td>[4361, 4742, 964, 439, 198, 4892, 5423, 2222, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[to, danny, mccarty, et, s, enron, get, to, mm...</td>\n",
       "      <td>[getting, emails, to, go, through, to, him, am...</td>\n",
       "      <td>[2418, 1356, 818, 464, 6022, 818, 1344, 4649, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[big, will, wonders, never, cease, condolences...</td>\n",
       "      <td>[over, guys, flush, out, the, shortcomings, of...</td>\n",
       "      <td>[153, 601, 6020, 279, 208, 943, 5505, 985, 435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[are, you, sure, we, have, a, contract, with, ...</td>\n",
       "      <td>[i, am, working, on, getting, the, number, it,...</td>\n",
       "      <td>[439, 4649, 3614, 1654, 2418, 208, 6460, 6806,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[entity, has, had, some, or, all, of, its, ass...</td>\n",
       "      <td>[confirm, to, sandra, please, advise, enron, n...</td>\n",
       "      <td>[4297, 818, 5933, 7196, 3499, 4880, 3837, 3576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>[enron, north, america, corp, good, news, comp...</td>\n",
       "      <td>[program, ?, &lt;EOS&gt;]</td>\n",
       "      <td>[4136, 2222, 5984, 836, 5075, 1210, 2255, 4745...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>[issues, with, you, before, we, could, continu...</td>\n",
       "      <td>[call, if, you, wish, to, discuss, this, furth...</td>\n",
       "      <td>[1156, 5934, 4872, 1069, 4533, 3571, 110, 279,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>[tetco, wla, tetco, stx, and, tetco, ela, for,...</td>\n",
       "      <td>[could, you, get, me, the, gas, daily, s, for,...</td>\n",
       "      <td>[5427, 6672, 6618, 2881, 6681, 7137, 2826, 290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>[i, will, call, you, later, could, you, please...</td>\n",
       "      <td>[the, credit, worksheet, as, some, of, the, nu...</td>\n",
       "      <td>[4880, 3837, 3576, 86, 6816, 1930, 5452, 5689,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>[i, have, enclosed, a, draft, of, the, letter,...</td>\n",
       "      <td>[rolling, otherwise, things, will, sit, around...</td>\n",
       "      <td>[5253, 5253, 5457, 439, 5265, 1460, 5793, 818,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>[enron, capital, trade, resources, corp, happy...</td>\n",
       "      <td>[school, and, cant, leave, there, until, see, ...</td>\n",
       "      <td>[3251, 2914, 2222, 2222, 2222, 2642, 4505, 393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>[opinion, and, or, resolution, that, i, receiv...</td>\n",
       "      <td>[yes, that, would, be, helpful, let, me, know,...</td>\n",
       "      <td>[1357, 4780, 2383, 439, 2732, 5441, 2881, 5934...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>[during, the, inspection, &lt;EOS&gt;]</td>\n",
       "      <td>[again, during, the, inspection, &lt;EOS&gt;]</td>\n",
       "      <td>[6412, 290, 741, 4742, 6590, 2222, 4996, 4538,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>[confirm, ?, let, me, know, confirmations, wha...</td>\n",
       "      <td>[deal, great, thanks, confirm, ?, let, me, kno...</td>\n",
       "      <td>[5893, 4149, 307, 208, 1245, 818, 1935, 4780, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>[weekend, time, is, running, out, and, we, nee...</td>\n",
       "      <td>[i, will, pledge, to, him, weekend, time, is, ...</td>\n",
       "      <td>[6466, 2146, 2238, 1753, 279, 2589, 3309, 724,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>[me, to, bow, and, scrape, the, next, time, yo...</td>\n",
       "      <td>[your, ring, or, something, like, that, from, ...</td>\n",
       "      <td>[1397, 5457, 1654, 4388, 208, 5091, 1988, 4017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>[count, can, youu, please, confirm, this, than...</td>\n",
       "      <td>[count, can, youu, please, confirm, this, than...</td>\n",
       "      <td>[6806, 2255, 1747, 7196, 464, 2385, 4533, 3329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>[thanks, you, re, the, best, &lt;EOS&gt;]</td>\n",
       "      <td>[thanks, see, you, tonite, looking, forward, t...</td>\n",
       "      <td>[4149, 6015, 4705, 5934, 4359, 2146, 279, 5505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>[sorry, that, just, slipped, out, i, ll, have,...</td>\n",
       "      <td>[the, recent, promotion, i, hope, to, meet, ex...</td>\n",
       "      <td>[6261, 2426, 2881, 4526, 1069, 1479, 6294, 229...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>[can, you, please, send, my, itinerary, to, lu...</td>\n",
       "      <td>[eric, sorry, for, the, delay, it, s, a, busy,...</td>\n",
       "      <td>[4533, 4075, 2512, 2132, 6092, 4786, 2255, 436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>[we, decide, that, is, needed, &lt;EOS&gt;]</td>\n",
       "      <td>[for, vacation, friday, if, this, is, not, fea...</td>\n",
       "      <td>[818, 6005, 4475, 4933, 4639, 6895, 3692, 1, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>[demand, to, go, up, were, you, referring, to,...</td>\n",
       "      <td>[absolutely, no, need, to, be, sorry, my, dear...</td>\n",
       "      <td>[6876, 4185, 6758, 1787, 3366, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>[sounds, familiar, isn, t, that, what, butch, ...</td>\n",
       "      <td>[anything, yet, &lt;EOS&gt;]</td>\n",
       "      <td>[1384, 4635, 6386, 290, 6818, 2637, 6826, 290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>[how, does, that, sound, ?, to, vicki, to, pre...</td>\n",
       "      <td>[i, ll, follow, back, with, them, and, get, ba...</td>\n",
       "      <td>[5327, 5481, 2637, 6595, 2386, 4493, 2255, 967...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>[congratulations, drew, we, look, forward, to,...</td>\n",
       "      <td>[your, family, will, love, living, in, houston...</td>\n",
       "      <td>[6115, 2589, 6310, 4281, 2637, 208, 4861, 1, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>[leboeuf, i, think, there, must, be, some, add...</td>\n",
       "      <td>[contact, him, all, first, to, see, what, we, ...</td>\n",
       "      <td>[626, 818, 4705, 290, 339, 1, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>[i, do, not, find, any, existing, agreements, ...</td>\n",
       "      <td>[are, you, sure, we, have, a, contract, with, ...</td>\n",
       "      <td>[175, 4621, 2388, 2613, 393, 1083, 2388, 4953,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>[make, sense, to, you, ?, discounted, rate, pl...</td>\n",
       "      <td>[discounted, rate, please, contact, me, at, x,...</td>\n",
       "      <td>[5505, 4191, 1988, 1147, 5577, 5384, 2861, 488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>[when, will, he, be, calling, in, ?, at, pm, c...</td>\n",
       "      <td>[that, will, help, we, ve, deferred, him, to, ...</td>\n",
       "      <td>[6826, 290, 2867, 208, 2057, 2881, 5674, 2222,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>[we, ll, get, this, deal, out, of, the, new, c...</td>\n",
       "      <td>[we, have, a, match, up, and, it, s, powerex, ...</td>\n",
       "      <td>[3075, 7196, 2720, 208, 1970, 6261, 2881, 4526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>[attached, is, the, weekly, status, report, re...</td>\n",
       "      <td>[attached, is, the, weekly, ena, litigation, s...</td>\n",
       "      <td>[2589, 4786, 4639, 4149, 2985, 6681, 5934, 63,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>[term, sheet, for, huber, deal, agreements, le...</td>\n",
       "      <td>[here, s, one, carol, did, &lt;EOS&gt;]</td>\n",
       "      <td>[439, 1179, 6548, 660, 2179, 1821, 5505, 1397,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>[per, your, request, detail, then, &lt;EOS&gt;]</td>\n",
       "      <td>[is, there, something, i, can, help, you, with...</td>\n",
       "      <td>[724, 439, 2006, 615, 4533, 759, 6115, 4533, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>[you, know, any, minute, the, new, counterpart...</td>\n",
       "      <td>[california, energy, resource, schedulers, cer...</td>\n",
       "      <td>[4880, 3447, 3619, 4536, 86, 2126, 5792, 1, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>[an, email, problem, ?, &lt;EOS&gt;]</td>\n",
       "      <td>[least, that, s, the, poop, that, i, ve, recei...</td>\n",
       "      <td>[1368, 6799, 818, 5036, 279, 5934, 3172, 2883,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input  \\\n",
       "0     [reporting, agency, and, data, source, informa...   \n",
       "1     [we, don, t, hear, from, him, by, noon, i, wou...   \n",
       "2     [month, changes, they, re, very, simple, to, m...   \n",
       "3     [subject, re, dinner, on, friday, ?, subject, ...   \n",
       "4     [thanksi, have, no, revisions, enjoy, the, par...   \n",
       "5     [attached, dealing, with, a, us, counterparty,...   \n",
       "6     [felt, that, out, of, shape, so, what, are, yo...   \n",
       "7       [my, comments, on, bob, s, memo, thanks, <EOS>]   \n",
       "8     [let, you, know, when, they, settle, it, prebo...   \n",
       "9     [likewise, so, who, is, the, lucky, person, fo...   \n",
       "10    [has, been, changed, yet, ?, calc, these, deal...   \n",
       "11    [as, soon, as, you, like, enron, north, americ...   \n",
       "12    [here, is, the, swap, confirmations, take, out...   \n",
       "13    [anxious, to, sign, please, advise, thanks, en...   \n",
       "14    [enron, north, america, corp, not, be, in, hou...   \n",
       "15    [then, is, already, moved, it, just, needs, to...   \n",
       "16                             [management, pwr, <EOS>]   \n",
       "17    [they, did, this, right, with, you, in, the, s...   \n",
       "18    [hi, sara, hope, you, had, a, good, time, in, ...   \n",
       "19    [sometime, today, to, talk, further, about, th...   \n",
       "20    [i, will, take, a, spot, the, enron, center, g...   \n",
       "21            [i, do, not, appear, to, have, it, <EOS>]   \n",
       "22    [abb, would, not, buy, back, the, unit, except...   \n",
       "23                                 [thanks, man, <EOS>]   \n",
       "24    [i, will, attend, items, can, be, ordered, tha...   \n",
       "25    [for, you, too, what, is, new, with, you, ?, <...   \n",
       "26    [to, danny, mccarty, et, s, enron, get, to, mm...   \n",
       "27    [big, will, wonders, never, cease, condolences...   \n",
       "28    [are, you, sure, we, have, a, contract, with, ...   \n",
       "29    [entity, has, had, some, or, all, of, its, ass...   \n",
       "...                                                 ...   \n",
       "3470  [enron, north, america, corp, good, news, comp...   \n",
       "3471  [issues, with, you, before, we, could, continu...   \n",
       "3472  [tetco, wla, tetco, stx, and, tetco, ela, for,...   \n",
       "3473  [i, will, call, you, later, could, you, please...   \n",
       "3474  [i, have, enclosed, a, draft, of, the, letter,...   \n",
       "3475  [enron, capital, trade, resources, corp, happy...   \n",
       "3476  [opinion, and, or, resolution, that, i, receiv...   \n",
       "3477                   [during, the, inspection, <EOS>]   \n",
       "3478  [confirm, ?, let, me, know, confirmations, wha...   \n",
       "3479  [weekend, time, is, running, out, and, we, nee...   \n",
       "3480  [me, to, bow, and, scrape, the, next, time, yo...   \n",
       "3481  [count, can, youu, please, confirm, this, than...   \n",
       "3482                [thanks, you, re, the, best, <EOS>]   \n",
       "3483  [sorry, that, just, slipped, out, i, ll, have,...   \n",
       "3484  [can, you, please, send, my, itinerary, to, lu...   \n",
       "3485              [we, decide, that, is, needed, <EOS>]   \n",
       "3486  [demand, to, go, up, were, you, referring, to,...   \n",
       "3487  [sounds, familiar, isn, t, that, what, butch, ...   \n",
       "3488  [how, does, that, sound, ?, to, vicki, to, pre...   \n",
       "3489  [congratulations, drew, we, look, forward, to,...   \n",
       "3490  [leboeuf, i, think, there, must, be, some, add...   \n",
       "3491  [i, do, not, find, any, existing, agreements, ...   \n",
       "3492  [make, sense, to, you, ?, discounted, rate, pl...   \n",
       "3493  [when, will, he, be, calling, in, ?, at, pm, c...   \n",
       "3494  [we, ll, get, this, deal, out, of, the, new, c...   \n",
       "3495  [attached, is, the, weekly, status, report, re...   \n",
       "3496  [term, sheet, for, huber, deal, agreements, le...   \n",
       "3497          [per, your, request, detail, then, <EOS>]   \n",
       "3498  [you, know, any, minute, the, new, counterpart...   \n",
       "3499                     [an, email, problem, ?, <EOS>]   \n",
       "\n",
       "                                                 output  \\\n",
       "0     [enron, capital, trade, resources, corp, repor...   \n",
       "1     [be, cut, off, this, cold, november, any, prob...   \n",
       "2                             [these, are, done, <EOS>]   \n",
       "3     [subject, re, dinner, on, friday, ?, subject, ...   \n",
       "4     [and, positions, circulate, the, plan, early, ...   \n",
       "5     [anytime, attached, dealing, with, a, us, coun...   \n",
       "6     [is, the, filename, tran, enron, north, americ...   \n",
       "7                               [office, number, <EOS>]   \n",
       "8     [but, we, should, know, soon, i, ll, e, mail, ...   \n",
       "9     [think, a, develop, engineer, initialled, for,...   \n",
       "10    [you, re, right, i, ve, changed, this, deal, i...   \n",
       "11    [i, think, it, s, a, nice, idea, say, thanks, ...   \n",
       "12    [here, are, the, swap, confirmations, take, ou...   \n",
       "13    [resolved, ?, i, left, a, message, with, tracy...   \n",
       "14    [thanks, i, m, looking, at, august, jean, is, ...   \n",
       "15    [is, being, sold, to, icc, on, deal, what, is,...   \n",
       "16            [management, gas, management, pwr, <EOS>]   \n",
       "17    [enron, north, america, corp, list, will, know...   \n",
       "18                                  [no, thanks, <EOS>]   \n",
       "19    [feel, i, fit, that, profile, and, am, excited...   \n",
       "20    [i, would, like, to, move, to, the, new, garag...   \n",
       "21                                     [for, it, <EOS>]   \n",
       "22    [he, s, re, trading, on, the, retainage, let, ...   \n",
       "23    [thanks, a, lot, i, appreciate, your, kind, wo...   \n",
       "24    [i, plan, to, attend, items, can, be, ordered,...   \n",
       "25    [how, about, ali, i, hate, pms, saler, ?, how,...   \n",
       "26    [getting, emails, to, go, through, to, him, am...   \n",
       "27    [over, guys, flush, out, the, shortcomings, of...   \n",
       "28    [i, am, working, on, getting, the, number, it,...   \n",
       "29    [confirm, to, sandra, please, advise, enron, n...   \n",
       "...                                                 ...   \n",
       "3470                                [program, ?, <EOS>]   \n",
       "3471  [call, if, you, wish, to, discuss, this, furth...   \n",
       "3472  [could, you, get, me, the, gas, daily, s, for,...   \n",
       "3473  [the, credit, worksheet, as, some, of, the, nu...   \n",
       "3474  [rolling, otherwise, things, will, sit, around...   \n",
       "3475  [school, and, cant, leave, there, until, see, ...   \n",
       "3476  [yes, that, would, be, helpful, let, me, know,...   \n",
       "3477            [again, during, the, inspection, <EOS>]   \n",
       "3478  [deal, great, thanks, confirm, ?, let, me, kno...   \n",
       "3479  [i, will, pledge, to, him, weekend, time, is, ...   \n",
       "3480  [your, ring, or, something, like, that, from, ...   \n",
       "3481  [count, can, youu, please, confirm, this, than...   \n",
       "3482  [thanks, see, you, tonite, looking, forward, t...   \n",
       "3483  [the, recent, promotion, i, hope, to, meet, ex...   \n",
       "3484  [eric, sorry, for, the, delay, it, s, a, busy,...   \n",
       "3485  [for, vacation, friday, if, this, is, not, fea...   \n",
       "3486  [absolutely, no, need, to, be, sorry, my, dear...   \n",
       "3487                             [anything, yet, <EOS>]   \n",
       "3488  [i, ll, follow, back, with, them, and, get, ba...   \n",
       "3489  [your, family, will, love, living, in, houston...   \n",
       "3490  [contact, him, all, first, to, see, what, we, ...   \n",
       "3491  [are, you, sure, we, have, a, contract, with, ...   \n",
       "3492  [discounted, rate, please, contact, me, at, x,...   \n",
       "3493  [that, will, help, we, ve, deferred, him, to, ...   \n",
       "3494  [we, have, a, match, up, and, it, s, powerex, ...   \n",
       "3495  [attached, is, the, weekly, ena, litigation, s...   \n",
       "3496                  [here, s, one, carol, did, <EOS>]   \n",
       "3497  [is, there, something, i, can, help, you, with...   \n",
       "3498  [california, energy, resource, schedulers, cer...   \n",
       "3499  [least, that, s, the, poop, that, i, ve, recei...   \n",
       "\n",
       "                                           input_onehot  \n",
       "0     [4880, 3447, 3619, 4536, 86, 3748, 3446, 4533,...  \n",
       "1     [3249, 1422, 6289, 175, 4302, 1461, 1397, 4683...  \n",
       "2     [6818, 6826, 1747, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [2126, 6792, 6346, 1654, 325, 2222, 2126, 6792...  \n",
       "4     [4533, 6637, 2496, 208, 259, 1521, 175, 1306, ...  \n",
       "5     [4998, 1970, 5463, 2589, 5934, 5674, 6467, 222...  \n",
       "6     [1384, 208, 1676, 6159, 4880, 3837, 3576, 86, ...  \n",
       "7     [2315, 6460, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "8     [595, 4780, 4399, 3832, 3973, 439, 1179, 1450,...  \n",
       "9     [5675, 5934, 2305, 2431, 3475, 2881, 1799, 152...  \n",
       "10    [290, 6792, 759, 439, 5632, 3708, 175, 2146, 5...  \n",
       "11    [439, 5675, 6806, 2255, 5934, 4185, 1998, 6226...  \n",
       "12    [1821, 6826, 208, 296, 1311, 803, 279, 1, 0, 0...  \n",
       "13    [2616, 2222, 439, 955, 5934, 1415, 2589, 2076,...  \n",
       "14    [6261, 439, 2006, 4429, 2132, 5595, 3879, 1384...  \n",
       "15    [1384, 3974, 3799, 818, 5927, 1654, 2146, 2826...  \n",
       "16    [4593, 3044, 4593, 6525, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "17    [4880, 3837, 3576, 86, 4136, 5265, 3832, 3234,...  \n",
       "18    [5253, 6261, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "19    [3209, 439, 3858, 4786, 3892, 4533, 4649, 2519...  \n",
       "20    [439, 4371, 4505, 818, 1810, 818, 208, 5740, 4...  \n",
       "21    [2881, 6806, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "22    [1648, 2255, 6792, 658, 1654, 208, 4849, 1141,...  \n",
       "23    [6261, 5934, 4171, 439, 4999, 4526, 1980, 5637...  \n",
       "24    [439, 259, 818, 4491, 1846, 2545, 3249, 2217, ...  \n",
       "25    [4361, 4742, 964, 439, 198, 4892, 5423, 2222, ...  \n",
       "26    [2418, 1356, 818, 464, 6022, 818, 1344, 4649, ...  \n",
       "27    [153, 601, 6020, 279, 208, 943, 5505, 985, 435...  \n",
       "28    [439, 4649, 3614, 1654, 2418, 208, 6460, 6806,...  \n",
       "29    [4297, 818, 5933, 7196, 3499, 4880, 3837, 3576...  \n",
       "...                                                 ...  \n",
       "3470  [4136, 2222, 5984, 836, 5075, 1210, 2255, 4745...  \n",
       "3471  [1156, 5934, 4872, 1069, 4533, 3571, 110, 279,...  \n",
       "3472  [5427, 6672, 6618, 2881, 6681, 7137, 2826, 290...  \n",
       "3473  [4880, 3837, 3576, 86, 6816, 1930, 5452, 5689,...  \n",
       "3474  [5253, 5253, 5457, 439, 5265, 1460, 5793, 818,...  \n",
       "3475  [3251, 2914, 2222, 2222, 2222, 2642, 4505, 393...  \n",
       "3476  [1357, 4780, 2383, 439, 2732, 5441, 2881, 5934...  \n",
       "3477  [6412, 290, 741, 4742, 6590, 2222, 4996, 4538,...  \n",
       "3478  [5893, 4149, 307, 208, 1245, 818, 1935, 4780, ...  \n",
       "3479  [6466, 2146, 2238, 1753, 279, 2589, 3309, 724,...  \n",
       "3480  [1397, 5457, 1654, 4388, 208, 5091, 1988, 4017...  \n",
       "3481  [6806, 2255, 1747, 7196, 464, 2385, 4533, 3329...  \n",
       "3482  [4149, 6015, 4705, 5934, 4359, 2146, 279, 5505...  \n",
       "3483  [6261, 2426, 2881, 4526, 1069, 1479, 6294, 229...  \n",
       "3484  [4533, 4075, 2512, 2132, 6092, 4786, 2255, 436...  \n",
       "3485  [818, 6005, 4475, 4933, 4639, 6895, 3692, 1, 0...  \n",
       "3486  [6876, 4185, 6758, 1787, 3366, 1, 0, 0, 0, 0, ...  \n",
       "3487  [1384, 4635, 6386, 290, 6818, 2637, 6826, 290,...  \n",
       "3488  [5327, 5481, 2637, 6595, 2386, 4493, 2255, 967...  \n",
       "3489  [6115, 2589, 6310, 4281, 2637, 208, 4861, 1, 0...  \n",
       "3490  [626, 818, 4705, 290, 339, 1, 0, 0, 0, 0, 0, 0...  \n",
       "3491  [175, 4621, 2388, 2613, 393, 1083, 2388, 4953,...  \n",
       "3492  [5505, 4191, 1988, 1147, 5577, 5384, 2861, 488...  \n",
       "3493  [6826, 290, 2867, 208, 2057, 2881, 5674, 2222,...  \n",
       "3494  [3075, 7196, 2720, 208, 1970, 6261, 2881, 4526...  \n",
       "3495  [2589, 4786, 4639, 4149, 2985, 6681, 5934, 63,...  \n",
       "3496  [439, 1179, 6548, 660, 2179, 1821, 5505, 1397,...  \n",
       "3497  [724, 439, 2006, 615, 4533, 759, 6115, 4533, 1...  \n",
       "3498  [4880, 3447, 3619, 4536, 86, 2126, 5792, 1, 0,...  \n",
       "3499  [1368, 6799, 818, 5036, 279, 5934, 3172, 2883,...  \n",
       "\n",
       "[3500 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([list([8656, 5, 531, 4913, 4591, 2407, 4031, 8934, 2881, 6626, 1]),\n",
       "        list([3956, 280, 7068, 1599, 7647, 12339, 13500, 3956, 12460, 1]),\n",
       "        list([11050, 10624, 4031, 3309, 10007, 2289, 10364, 399, 11178, 1]),\n",
       "        ..., list([3635, 12049, 12460, 3894, 1267, 1696, 3849, 6626, 1]),\n",
       "        list([12339, 9585, 2376, 679, 80, 12339, 5567, 4911, 856, 3956, 1]),\n",
       "        list([12339, 7167, 4911, 169, 1696, 4150, 8076, 6796, 2450, 12339, 5708, 3956, 1])], dtype=object),\n",
       " array([ array([8656,    5,  531, 4913, 4591, 2407, 4031, 8934, 2881, 6626,    1,\n",
       "           0,    0,    0,    0,    0,    0], dtype=int64),\n",
       "        array([ 3956, 12460,  7068,  1599,  7647, 12339, 13500,  3956,  3849,\n",
       "            1,     0,     0,     0,     0,     0,     0,     0], dtype=int64),\n",
       "        array([11050, 10364,  3309,  4157,  2615,     1,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0], dtype=int64),\n",
       "        ...,\n",
       "        array([ 3651,   280, 12709,  8728,     1,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0], dtype=int64),\n",
       "        array([ 2615,  3065, 12339,  3140, 10519,  3956,  4667,     1,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0], dtype=int64),\n",
       "        array([ 9746,  3956,  6835, 12550,   958,  6626,     1,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0], dtype=int64)], dtype=object))"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_metric['truth'].values, df_metric['inference'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSc0Z9JLUnEEvSc0Z9JLU3P8D9zqEqqiDQNoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b984bd97b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_metric['meanCheckList'].values, bins=[i/50 for i in range(60)], log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padList(x, y):\n",
    "    \n",
    "    pad_length = max(len(x), len(y))\n",
    "    \n",
    "    print (pad_length)\n",
    "    \n",
    "    if len(x)> len(y): \n",
    "        print ('a')\n",
    "        y = y + [0]\n",
    "    elif len(x) < len(y): \n",
    "        print ('b')\n",
    "        x = x + [0]\n",
    "    \n",
    "    \n",
    "    print (x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_Pair_0_encoding</th>\n",
       "      <th>alpha_Pair_1_encoding</th>\n",
       "      <th>alpha_Pair_1_encoding_reverse_order</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11022</th>\n",
       "      <td>[280, 6242, 4031, 11099, 6626, 1]</td>\n",
       "      <td>[8656, 5, 531, 4913, 4591, 2407, 4031, 8934, 2...</td>\n",
       "      <td>[1, 6626, 2881, 8934, 4031, 2407, 4591, 4913, ...</td>\n",
       "      <td>11022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84499</th>\n",
       "      <td>[3651, 280, 10537, 7470, 8084, 11845, 4057, 1]</td>\n",
       "      <td>[3956, 280, 7068, 1599, 7647, 12339, 13500, 39...</td>\n",
       "      <td>[1, 12460, 3956, 13500, 12339, 7647, 1599, 706...</td>\n",
       "      <td>84499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27462</th>\n",
       "      <td>[13272, 13044, 1195, 3849, 3956, 273, 12437, 6...</td>\n",
       "      <td>[11050, 10624, 4031, 3309, 10007, 2289, 10364,...</td>\n",
       "      <td>[1, 11178, 399, 10364, 2289, 10007, 3309, 4031...</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25199</th>\n",
       "      <td>[531, 181, 8206, 6336, 3849, 3956, 9746, 6626, 1]</td>\n",
       "      <td>[12339, 3140, 10500, 6744, 1]</td>\n",
       "      <td>[1, 6744, 10500, 3140, 12339]</td>\n",
       "      <td>25199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102362</th>\n",
       "      <td>[12049, 6626, 12049, 7344, 7346, 6626, 1]</td>\n",
       "      <td>[7346, 1347, 5092, 8765, 695, 7647, 1696, 1161...</td>\n",
       "      <td>[1, 2675, 3956, 6890, 531, 11610, 1696, 7647, ...</td>\n",
       "      <td>102362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90493</th>\n",
       "      <td>[9746, 3956, 7140, 1856, 6626, 1]</td>\n",
       "      <td>[11050, 11487, 8766, 13217, 8018, 13272, 1347,...</td>\n",
       "      <td>[1, 6626, 11845, 1347, 13272, 8018, 13217, 876...</td>\n",
       "      <td>90493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55216</th>\n",
       "      <td>[6796, 8286, 6381, 10805, 2446, 4116, 1347, 12...</td>\n",
       "      <td>[11968, 6381, 325, 695, 4613, 4157, 4031, 1034...</td>\n",
       "      <td>[1, 13489, 10341, 4031, 4157, 4613, 695, 325, ...</td>\n",
       "      <td>55216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73043</th>\n",
       "      <td>[12339, 5411, 3956, 1637, 4031, 897, 6612, 495...</td>\n",
       "      <td>[3956, 6600, 4911, 11398, 552, 10274, 12049, 5...</td>\n",
       "      <td>[1, 10394, 5240, 12049, 10274, 552, 11398, 491...</td>\n",
       "      <td>73043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21499</th>\n",
       "      <td>[531, 3956, 13500, 2675, 695, 5240, 2985, 6626...</td>\n",
       "      <td>[11355, 3956, 2143, 4031, 10516, 8078, 11625, ...</td>\n",
       "      <td>[1, 6626, 10060, 1577, 11852, 11625, 8078, 105...</td>\n",
       "      <td>21499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96307</th>\n",
       "      <td>[3956, 169, 1696, 10394, 1599, 11489, 6626, 1]</td>\n",
       "      <td>[12887, 4911, 7714, 8240, 12887, 4911, 7714, 1]</td>\n",
       "      <td>[1, 7714, 4911, 12887, 8240, 7714, 4911, 12887]</td>\n",
       "      <td>96307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60996</th>\n",
       "      <td>[7346, 1347, 4501, 13166, 10747, 1]</td>\n",
       "      <td>[11050, 7346, 1347, 4965, 10747, 1]</td>\n",
       "      <td>[1, 10747, 4965, 1347, 7346, 11050]</td>\n",
       "      <td>60996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102127</th>\n",
       "      <td>[2907, 4911, 4031, 1028, 10776, 8728, 1696, 82...</td>\n",
       "      <td>[7346, 1767, 4911, 10776, 4031, 1028, 7346, 13...</td>\n",
       "      <td>[1, 560, 1577, 3561, 13019, 4031, 10776, 1347,...</td>\n",
       "      <td>102127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>[11050, 11355, 3956, 9227, 5240, 2103, 6626, 1]</td>\n",
       "      <td>[4698, 7441, 9227, 4331, 7834, 1]</td>\n",
       "      <td>[1, 7834, 4331, 9227, 7441, 4698]</td>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55442</th>\n",
       "      <td>[3849, 3956, 10045, 6086, 3169, 6626, 1]</td>\n",
       "      <td>[12887, 4911, 7329, 9533, 1]</td>\n",
       "      <td>[1, 9533, 7329, 4911, 12887]</td>\n",
       "      <td>55442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>[12339, 7167, 4911, 9058, 12049, 3265, 13272, ...</td>\n",
       "      <td>[13272, 1378, 1696, 11757, 3956, 531, 7647, 53...</td>\n",
       "      <td>[1, 2780, 2675, 11845, 8759, 531, 7647, 531, 3...</td>\n",
       "      <td>19964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104353</th>\n",
       "      <td>[12339, 3018, 6288, 10562, 7698, 12340, 12887,...</td>\n",
       "      <td>[5240, 140, 11852, 11178, 8172, 2376, 12789, 1]</td>\n",
       "      <td>[1, 12789, 2376, 8172, 11178, 11852, 140, 5240]</td>\n",
       "      <td>104353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24363</th>\n",
       "      <td>[12975, 10512, 5499, 7346, 1347, 10099, 11968,...</td>\n",
       "      <td>[1305, 3956, 9230, 1599, 4613, 7783, 4154, 118...</td>\n",
       "      <td>[1, 6626, 9066, 11852, 4154, 7783, 4613, 1599,...</td>\n",
       "      <td>24363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39474</th>\n",
       "      <td>[8229, 12339, 7173, 4501, 13599, 12339, 1959, ...</td>\n",
       "      <td>[5708, 12298, 11852, 13105, 820, 1]</td>\n",
       "      <td>[1, 820, 13105, 11852, 12298, 5708]</td>\n",
       "      <td>39474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56183</th>\n",
       "      <td>[12339, 7946, 8081, 8457, 12460, 4031, 8898, 6...</td>\n",
       "      <td>[3894, 3008, 2376, 7742, 1378, 12049, 3894, 97...</td>\n",
       "      <td>[1, 9746, 3894, 12049, 1378, 7742, 2376, 3008,...</td>\n",
       "      <td>56183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73258</th>\n",
       "      <td>[3651, 280, 8684, 1599, 2446, 6626, 1]</td>\n",
       "      <td>[3894, 2060, 10273, 531, 7143, 11968, 4031, 82...</td>\n",
       "      <td>[1, 602, 11852, 2895, 5240, 8929, 3651, 820, 4...</td>\n",
       "      <td>73258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76285</th>\n",
       "      <td>[3651, 10800, 4911, 6916, 5240, 5615, 1]</td>\n",
       "      <td>[12339, 4409, 13272, 4157, 4031, 489, 1]</td>\n",
       "      <td>[1, 489, 4031, 4157, 13272, 4409, 12339]</td>\n",
       "      <td>76285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107654</th>\n",
       "      <td>[6288, 3849, 12339, 6288, 3849, 3956, 1]</td>\n",
       "      <td>[7758, 4613, 4157, 5240, 7954, 820, 2491, 1233...</td>\n",
       "      <td>[1, 5508, 7409, 1347, 4613, 4613, 1558, 12339,...</td>\n",
       "      <td>107654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72142</th>\n",
       "      <td>[12049, 4031, 5266, 12460, 3956, 92, 2809, 751...</td>\n",
       "      <td>[12049, 3849, 3956, 7946, 3894, 280, 2809, 959...</td>\n",
       "      <td>[1, 6626, 9595, 2809, 280, 3894, 7946, 3956, 3...</td>\n",
       "      <td>72142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39581</th>\n",
       "      <td>[12049, 1347, 2445, 7170, 6626, 1]</td>\n",
       "      <td>[7884, 3956, 6796, 8228, 5754, 181, 11355, 395...</td>\n",
       "      <td>[1, 6626, 10060, 4965, 1599, 12981, 3849, 3956...</td>\n",
       "      <td>39581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79480</th>\n",
       "      <td>[11882, 6381, 7344, 12339, 10500, 951, 1]</td>\n",
       "      <td>[3894, 280, 7519, 1696, 7338, 10157, 8353, 1]</td>\n",
       "      <td>[1, 8353, 10157, 7338, 1696, 7519, 280, 3894]</td>\n",
       "      <td>79480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74011</th>\n",
       "      <td>[2675, 7344, 181, 3956, 7366, 1128, 6626, 1]</td>\n",
       "      <td>[2675, 7344, 181, 3956, 2060, 3065, 1]</td>\n",
       "      <td>[1, 3065, 2060, 3956, 181, 7344, 2675]</td>\n",
       "      <td>74011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>[181, 8206, 13019, 6626, 1]</td>\n",
       "      <td>[12339, 4571, 4911, 6890, 1]</td>\n",
       "      <td>[1, 6890, 4911, 4571, 12339]</td>\n",
       "      <td>5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45315</th>\n",
       "      <td>[12339, 8485, 10225, 8485, 3956, 1]</td>\n",
       "      <td>[6541, 12339, 2001, 4613, 2289, 2446, 6820, 1]</td>\n",
       "      <td>[1, 6820, 2446, 2289, 4613, 2001, 12339, 6541]</td>\n",
       "      <td>45315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22751</th>\n",
       "      <td>[12049, 4084, 7344, 4613, 6626, 1]</td>\n",
       "      <td>[4031, 4084, 6989, 3956, 346, 2445, 3561, 4031...</td>\n",
       "      <td>[1, 9973, 4031, 3561, 2445, 346, 3956, 6989, 4...</td>\n",
       "      <td>22751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49007</th>\n",
       "      <td>[12339, 10500, 1704, 13500, 4031, 2802, 8006, 1]</td>\n",
       "      <td>[4031, 2802, 7344, 695, 4324, 9912, 7716, 1]</td>\n",
       "      <td>[1, 7716, 9912, 4324, 695, 7344, 2802, 4031]</td>\n",
       "      <td>49007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105336</th>\n",
       "      <td>[12049, 12339, 3849, 10244, 9610, 10140, 12339...</td>\n",
       "      <td>[3956, 280, 757, 4971, 4911, 3956, 1]</td>\n",
       "      <td>[1, 3956, 4911, 4971, 757, 280, 3956]</td>\n",
       "      <td>105336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[2489, 12339, 6278, 1696, 7850, 1696, 3956, 12...</td>\n",
       "      <td>[12339, 1959, 7167, 4911, 7946, 12339, 6278, 1...</td>\n",
       "      <td>[1, 4503, 679, 3956, 9230, 8679, 10829, 11487,...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93724</th>\n",
       "      <td>[13272, 12887, 4911, 5741, 1]</td>\n",
       "      <td>[11050, 13272, 12887, 4911, 1]</td>\n",
       "      <td>[1, 4911, 12887, 13272, 11050]</td>\n",
       "      <td>93724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39796</th>\n",
       "      <td>[11178, 6916, 8136, 695, 13106, 80, 12339, 234...</td>\n",
       "      <td>[8084, 4031, 452, 8656, 3180, 8759, 11852, 480...</td>\n",
       "      <td>[1, 4558, 4805, 11852, 8759, 3180, 8656, 452, ...</td>\n",
       "      <td>39796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56201</th>\n",
       "      <td>[4965, 11958, 9533, 6626, 3961, 6381, 1622, 38...</td>\n",
       "      <td>[11050, 6381, 1347, 7470, 1]</td>\n",
       "      <td>[1, 7470, 1347, 6381, 11050]</td>\n",
       "      <td>56201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26348</th>\n",
       "      <td>[11050, 10995, 6626, 3008, 12339, 6626, 1]</td>\n",
       "      <td>[8094, 4529, 3956, 3477, 7647, 7346, 4157, 403...</td>\n",
       "      <td>[1, 643, 6835, 3956, 820, 489, 4031, 4157, 734...</td>\n",
       "      <td>26348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10269</th>\n",
       "      <td>[531, 3956, 12887, 4698, 6890, 7346, 1347, 403...</td>\n",
       "      <td>[5591, 12049, 7344, 4613, 6626, 1]</td>\n",
       "      <td>[1, 6626, 4613, 7344, 12049, 5591]</td>\n",
       "      <td>10269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107247</th>\n",
       "      <td>[6381, 7329, 1305, 13272, 7344, 6626, 1]</td>\n",
       "      <td>[12339, 7167, 4911, 7946, 6381, 12113, 1]</td>\n",
       "      <td>[1, 12113, 6381, 7946, 4911, 7167, 12339]</td>\n",
       "      <td>107247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106962</th>\n",
       "      <td>[12887, 3956, 8451, 7647, 3561, 80, 6626, 1]</td>\n",
       "      <td>[11500, 3894, 9746, 11050, 8766, 12049, 1347, ...</td>\n",
       "      <td>[1, 11845, 1267, 1347, 12049, 8766, 11050, 974...</td>\n",
       "      <td>106962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68904</th>\n",
       "      <td>[4613, 1347, 4501, 4166, 1]</td>\n",
       "      <td>[3635, 10995, 3849, 3956, 169, 1696, 856, 6626...</td>\n",
       "      <td>[1, 6626, 856, 1696, 169, 3956, 3849, 10995, 3...</td>\n",
       "      <td>68904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45857</th>\n",
       "      <td>[5240, 10704, 11852, 13019, 11852, 4158, 9533,...</td>\n",
       "      <td>[11852, 1030, 6768, 1634, 7370, 2282, 1]</td>\n",
       "      <td>[1, 2282, 7370, 1634, 6768, 1030, 11852]</td>\n",
       "      <td>45857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70676</th>\n",
       "      <td>[2161, 13272, 1347, 4698, 4913, 1028, 680, 1]</td>\n",
       "      <td>[13272, 9585, 6840, 3602, 7346, 1815, 1]</td>\n",
       "      <td>[1, 1815, 7346, 3602, 6840, 9585, 13272]</td>\n",
       "      <td>70676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16863</th>\n",
       "      <td>[12339, 7173, 6784, 8987, 7167, 4911, 2376, 17...</td>\n",
       "      <td>[1770, 6626, 12339, 7173, 12339, 7173, 4442, 1]</td>\n",
       "      <td>[1, 4442, 7173, 12339, 7173, 12339, 6626, 1770]</td>\n",
       "      <td>16863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42787</th>\n",
       "      <td>[12339, 9585, 9746, 5240, 9212, 2388, 2651, 19...</td>\n",
       "      <td>[7346, 1347, 1622, 11845, 7954, 8412, 3956, 28...</td>\n",
       "      <td>[1, 13106, 280, 3956, 8412, 7954, 11845, 1622,...</td>\n",
       "      <td>42787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83562</th>\n",
       "      <td>[12339, 7173, 1267, 9195, 768, 1]</td>\n",
       "      <td>[12339, 9585, 5920, 1599, 3956, 1]</td>\n",
       "      <td>[1, 3956, 1599, 5920, 9585, 12339]</td>\n",
       "      <td>83562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17319</th>\n",
       "      <td>[1599, 4965, 8946, 7698, 6963, 12339, 2343, 10...</td>\n",
       "      <td>[12339, 643, 5240, 358, 3956, 8172, 1]</td>\n",
       "      <td>[1, 8172, 3956, 358, 5240, 643, 12339]</td>\n",
       "      <td>17319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90787</th>\n",
       "      <td>[1305, 12460, 3956, 1267, 6626, 1]</td>\n",
       "      <td>[8987, 3894, 9585, 9746, 1696, 7850, 9446, 1]</td>\n",
       "      <td>[1, 9446, 7850, 1696, 9746, 9585, 3894, 8987]</td>\n",
       "      <td>90787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102020</th>\n",
       "      <td>[3956, 9746, 6220, 1146, 852, 1696, 1604, 2445...</td>\n",
       "      <td>[8494, 7346, 11050, 4154, 12339, 10500, 80, 79...</td>\n",
       "      <td>[1, 7948, 80, 10500, 12339, 4154, 11050, 7346,...</td>\n",
       "      <td>102020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64435</th>\n",
       "      <td>[10995, 8172, 3956, 8084, 2689, 7360, 12339, 5...</td>\n",
       "      <td>[2179, 5920, 11852, 7647, 856, 7647, 905, 1]</td>\n",
       "      <td>[1, 905, 7647, 856, 7647, 11852, 5920, 2179]</td>\n",
       "      <td>64435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23295</th>\n",
       "      <td>[9556, 4031, 3442, 9230, 4031, 12928, 7344, 80...</td>\n",
       "      <td>[3956, 280, 13599, 4613, 1347, 11224, 6626, 1]</td>\n",
       "      <td>[1, 6626, 11224, 1347, 4613, 13599, 280, 3956]</td>\n",
       "      <td>23295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101582</th>\n",
       "      <td>[4613, 11167, 5747, 11590, 1]</td>\n",
       "      <td>[7366, 7346, 7297, 9281, 12339, 9585, 2060, 26...</td>\n",
       "      <td>[1, 8229, 4009, 2675, 2060, 9585, 12339, 9281,...</td>\n",
       "      <td>101582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71446</th>\n",
       "      <td>[11852, 1030, 13272, 11355, 695, 3065, 1347, 1...</td>\n",
       "      <td>[12339, 12887, 4911, 9895, 128, 12339, 8084, 8...</td>\n",
       "      <td>[1, 8030, 8084, 12339, 128, 9895, 4911, 12887,...</td>\n",
       "      <td>71446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87551</th>\n",
       "      <td>[11050, 3956, 7167, 4911, 531, 3956, 13500, 73...</td>\n",
       "      <td>[7360, 13105, 5946, 7988, 13176, 8172, 3956, 8...</td>\n",
       "      <td>[1, 6626, 7647, 856, 3956, 8172, 13176, 7988, ...</td>\n",
       "      <td>87551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15204</th>\n",
       "      <td>[12049, 4031, 5266, 4157, 4613, 6626, 1634, 92...</td>\n",
       "      <td>[11050, 7346, 4157, 9653, 1253, 9653, 1]</td>\n",
       "      <td>[1, 9653, 1253, 9653, 4157, 7346, 11050]</td>\n",
       "      <td>15204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78598</th>\n",
       "      <td>[12049, 3849, 3956, 1558, 6626, 1]</td>\n",
       "      <td>[12339, 7946, 3956, 13500, 1]</td>\n",
       "      <td>[1, 13500, 3956, 7946, 12339]</td>\n",
       "      <td>78598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73529</th>\n",
       "      <td>[4031, 12333, 1599, 1634, 6178, 3561, 7346, 1]</td>\n",
       "      <td>[6926, 7346, 2445, 6568, 7346, 3561, 4031, 534...</td>\n",
       "      <td>[1, 560, 4965, 1599, 11845, 8084, 5344, 4031, ...</td>\n",
       "      <td>73529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73259</th>\n",
       "      <td>[1305, 1347, 4031, 11928, 3646, 6626, 1]</td>\n",
       "      <td>[6796, 5949, 3956, 7167, 4911, 9746, 1696, 116...</td>\n",
       "      <td>[1, 11610, 1696, 9746, 4911, 7167, 3956, 5949,...</td>\n",
       "      <td>73259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104990</th>\n",
       "      <td>[12661, 9275, 4613, 12661, 11924, 3651, 280, 1...</td>\n",
       "      <td>[3651, 280, 4501, 11845, 1696, 2446, 12339, 71...</td>\n",
       "      <td>[1, 9275, 6883, 11052, 2659, 7173, 12339, 2446...</td>\n",
       "      <td>104990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>[5283, 5708, 7346, 8578, 6626, 1]</td>\n",
       "      <td>[12339, 7173, 3561, 5102, 9589, 1]</td>\n",
       "      <td>[1, 9589, 5102, 3561, 7173, 12339]</td>\n",
       "      <td>4201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68728</th>\n",
       "      <td>[10099, 3226, 1028, 4503, 1]</td>\n",
       "      <td>[8084, 4031, 7790, 8872, 80, 1]</td>\n",
       "      <td>[1, 80, 8872, 7790, 4031, 8084]</td>\n",
       "      <td>68728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29463 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    alpha_Pair_0_encoding  \\\n",
       "11022                   [280, 6242, 4031, 11099, 6626, 1]   \n",
       "84499      [3651, 280, 10537, 7470, 8084, 11845, 4057, 1]   \n",
       "27462   [13272, 13044, 1195, 3849, 3956, 273, 12437, 6...   \n",
       "25199   [531, 181, 8206, 6336, 3849, 3956, 9746, 6626, 1]   \n",
       "102362          [12049, 6626, 12049, 7344, 7346, 6626, 1]   \n",
       "90493                   [9746, 3956, 7140, 1856, 6626, 1]   \n",
       "55216   [6796, 8286, 6381, 10805, 2446, 4116, 1347, 12...   \n",
       "73043   [12339, 5411, 3956, 1637, 4031, 897, 6612, 495...   \n",
       "21499   [531, 3956, 13500, 2675, 695, 5240, 2985, 6626...   \n",
       "96307      [3956, 169, 1696, 10394, 1599, 11489, 6626, 1]   \n",
       "60996                 [7346, 1347, 4501, 13166, 10747, 1]   \n",
       "102127  [2907, 4911, 4031, 1028, 10776, 8728, 1696, 82...   \n",
       "3743      [11050, 11355, 3956, 9227, 5240, 2103, 6626, 1]   \n",
       "55442            [3849, 3956, 10045, 6086, 3169, 6626, 1]   \n",
       "19964   [12339, 7167, 4911, 9058, 12049, 3265, 13272, ...   \n",
       "104353  [12339, 3018, 6288, 10562, 7698, 12340, 12887,...   \n",
       "24363   [12975, 10512, 5499, 7346, 1347, 10099, 11968,...   \n",
       "39474   [8229, 12339, 7173, 4501, 13599, 12339, 1959, ...   \n",
       "56183   [12339, 7946, 8081, 8457, 12460, 4031, 8898, 6...   \n",
       "73258              [3651, 280, 8684, 1599, 2446, 6626, 1]   \n",
       "76285            [3651, 10800, 4911, 6916, 5240, 5615, 1]   \n",
       "107654           [6288, 3849, 12339, 6288, 3849, 3956, 1]   \n",
       "72142   [12049, 4031, 5266, 12460, 3956, 92, 2809, 751...   \n",
       "39581                  [12049, 1347, 2445, 7170, 6626, 1]   \n",
       "79480           [11882, 6381, 7344, 12339, 10500, 951, 1]   \n",
       "74011        [2675, 7344, 181, 3956, 7366, 1128, 6626, 1]   \n",
       "5507                          [181, 8206, 13019, 6626, 1]   \n",
       "45315                 [12339, 8485, 10225, 8485, 3956, 1]   \n",
       "22751                  [12049, 4084, 7344, 4613, 6626, 1]   \n",
       "49007    [12339, 10500, 1704, 13500, 4031, 2802, 8006, 1]   \n",
       "...                                                   ...   \n",
       "105336  [12049, 12339, 3849, 10244, 9610, 10140, 12339...   \n",
       "39      [2489, 12339, 6278, 1696, 7850, 1696, 3956, 12...   \n",
       "93724                       [13272, 12887, 4911, 5741, 1]   \n",
       "39796   [11178, 6916, 8136, 695, 13106, 80, 12339, 234...   \n",
       "56201   [4965, 11958, 9533, 6626, 3961, 6381, 1622, 38...   \n",
       "26348          [11050, 10995, 6626, 3008, 12339, 6626, 1]   \n",
       "10269   [531, 3956, 12887, 4698, 6890, 7346, 1347, 403...   \n",
       "107247           [6381, 7329, 1305, 13272, 7344, 6626, 1]   \n",
       "106962       [12887, 3956, 8451, 7647, 3561, 80, 6626, 1]   \n",
       "68904                         [4613, 1347, 4501, 4166, 1]   \n",
       "45857   [5240, 10704, 11852, 13019, 11852, 4158, 9533,...   \n",
       "70676       [2161, 13272, 1347, 4698, 4913, 1028, 680, 1]   \n",
       "16863   [12339, 7173, 6784, 8987, 7167, 4911, 2376, 17...   \n",
       "42787   [12339, 9585, 9746, 5240, 9212, 2388, 2651, 19...   \n",
       "83562                   [12339, 7173, 1267, 9195, 768, 1]   \n",
       "17319   [1599, 4965, 8946, 7698, 6963, 12339, 2343, 10...   \n",
       "90787                  [1305, 12460, 3956, 1267, 6626, 1]   \n",
       "102020  [3956, 9746, 6220, 1146, 852, 1696, 1604, 2445...   \n",
       "64435   [10995, 8172, 3956, 8084, 2689, 7360, 12339, 5...   \n",
       "23295   [9556, 4031, 3442, 9230, 4031, 12928, 7344, 80...   \n",
       "101582                      [4613, 11167, 5747, 11590, 1]   \n",
       "71446   [11852, 1030, 13272, 11355, 695, 3065, 1347, 1...   \n",
       "87551   [11050, 3956, 7167, 4911, 531, 3956, 13500, 73...   \n",
       "15204   [12049, 4031, 5266, 4157, 4613, 6626, 1634, 92...   \n",
       "78598                  [12049, 3849, 3956, 1558, 6626, 1]   \n",
       "73529      [4031, 12333, 1599, 1634, 6178, 3561, 7346, 1]   \n",
       "73259            [1305, 1347, 4031, 11928, 3646, 6626, 1]   \n",
       "104990  [12661, 9275, 4613, 12661, 11924, 3651, 280, 1...   \n",
       "4201                    [5283, 5708, 7346, 8578, 6626, 1]   \n",
       "68728                        [10099, 3226, 1028, 4503, 1]   \n",
       "\n",
       "                                    alpha_Pair_1_encoding  \\\n",
       "11022   [8656, 5, 531, 4913, 4591, 2407, 4031, 8934, 2...   \n",
       "84499   [3956, 280, 7068, 1599, 7647, 12339, 13500, 39...   \n",
       "27462   [11050, 10624, 4031, 3309, 10007, 2289, 10364,...   \n",
       "25199                       [12339, 3140, 10500, 6744, 1]   \n",
       "102362  [7346, 1347, 5092, 8765, 695, 7647, 1696, 1161...   \n",
       "90493   [11050, 11487, 8766, 13217, 8018, 13272, 1347,...   \n",
       "55216   [11968, 6381, 325, 695, 4613, 4157, 4031, 1034...   \n",
       "73043   [3956, 6600, 4911, 11398, 552, 10274, 12049, 5...   \n",
       "21499   [11355, 3956, 2143, 4031, 10516, 8078, 11625, ...   \n",
       "96307     [12887, 4911, 7714, 8240, 12887, 4911, 7714, 1]   \n",
       "60996                 [11050, 7346, 1347, 4965, 10747, 1]   \n",
       "102127  [7346, 1767, 4911, 10776, 4031, 1028, 7346, 13...   \n",
       "3743                    [4698, 7441, 9227, 4331, 7834, 1]   \n",
       "55442                        [12887, 4911, 7329, 9533, 1]   \n",
       "19964   [13272, 1378, 1696, 11757, 3956, 531, 7647, 53...   \n",
       "104353    [5240, 140, 11852, 11178, 8172, 2376, 12789, 1]   \n",
       "24363   [1305, 3956, 9230, 1599, 4613, 7783, 4154, 118...   \n",
       "39474                 [5708, 12298, 11852, 13105, 820, 1]   \n",
       "56183   [3894, 3008, 2376, 7742, 1378, 12049, 3894, 97...   \n",
       "73258   [3894, 2060, 10273, 531, 7143, 11968, 4031, 82...   \n",
       "76285            [12339, 4409, 13272, 4157, 4031, 489, 1]   \n",
       "107654  [7758, 4613, 4157, 5240, 7954, 820, 2491, 1233...   \n",
       "72142   [12049, 3849, 3956, 7946, 3894, 280, 2809, 959...   \n",
       "39581   [7884, 3956, 6796, 8228, 5754, 181, 11355, 395...   \n",
       "79480       [3894, 280, 7519, 1696, 7338, 10157, 8353, 1]   \n",
       "74011              [2675, 7344, 181, 3956, 2060, 3065, 1]   \n",
       "5507                         [12339, 4571, 4911, 6890, 1]   \n",
       "45315      [6541, 12339, 2001, 4613, 2289, 2446, 6820, 1]   \n",
       "22751   [4031, 4084, 6989, 3956, 346, 2445, 3561, 4031...   \n",
       "49007        [4031, 2802, 7344, 695, 4324, 9912, 7716, 1]   \n",
       "...                                                   ...   \n",
       "105336              [3956, 280, 757, 4971, 4911, 3956, 1]   \n",
       "39      [12339, 1959, 7167, 4911, 7946, 12339, 6278, 1...   \n",
       "93724                      [11050, 13272, 12887, 4911, 1]   \n",
       "39796   [8084, 4031, 452, 8656, 3180, 8759, 11852, 480...   \n",
       "56201                        [11050, 6381, 1347, 7470, 1]   \n",
       "26348   [8094, 4529, 3956, 3477, 7647, 7346, 4157, 403...   \n",
       "10269                  [5591, 12049, 7344, 4613, 6626, 1]   \n",
       "107247          [12339, 7167, 4911, 7946, 6381, 12113, 1]   \n",
       "106962  [11500, 3894, 9746, 11050, 8766, 12049, 1347, ...   \n",
       "68904   [3635, 10995, 3849, 3956, 169, 1696, 856, 6626...   \n",
       "45857            [11852, 1030, 6768, 1634, 7370, 2282, 1]   \n",
       "70676            [13272, 9585, 6840, 3602, 7346, 1815, 1]   \n",
       "16863     [1770, 6626, 12339, 7173, 12339, 7173, 4442, 1]   \n",
       "42787   [7346, 1347, 1622, 11845, 7954, 8412, 3956, 28...   \n",
       "83562                  [12339, 9585, 5920, 1599, 3956, 1]   \n",
       "17319              [12339, 643, 5240, 358, 3956, 8172, 1]   \n",
       "90787       [8987, 3894, 9585, 9746, 1696, 7850, 9446, 1]   \n",
       "102020  [8494, 7346, 11050, 4154, 12339, 10500, 80, 79...   \n",
       "64435        [2179, 5920, 11852, 7647, 856, 7647, 905, 1]   \n",
       "23295      [3956, 280, 13599, 4613, 1347, 11224, 6626, 1]   \n",
       "101582  [7366, 7346, 7297, 9281, 12339, 9585, 2060, 26...   \n",
       "71446   [12339, 12887, 4911, 9895, 128, 12339, 8084, 8...   \n",
       "87551   [7360, 13105, 5946, 7988, 13176, 8172, 3956, 8...   \n",
       "15204            [11050, 7346, 4157, 9653, 1253, 9653, 1]   \n",
       "78598                       [12339, 7946, 3956, 13500, 1]   \n",
       "73529   [6926, 7346, 2445, 6568, 7346, 3561, 4031, 534...   \n",
       "73259   [6796, 5949, 3956, 7167, 4911, 9746, 1696, 116...   \n",
       "104990  [3651, 280, 4501, 11845, 1696, 2446, 12339, 71...   \n",
       "4201                   [12339, 7173, 3561, 5102, 9589, 1]   \n",
       "68728                     [8084, 4031, 7790, 8872, 80, 1]   \n",
       "\n",
       "                      alpha_Pair_1_encoding_reverse_order   Index  \n",
       "11022   [1, 6626, 2881, 8934, 4031, 2407, 4591, 4913, ...   11022  \n",
       "84499   [1, 12460, 3956, 13500, 12339, 7647, 1599, 706...   84499  \n",
       "27462   [1, 11178, 399, 10364, 2289, 10007, 3309, 4031...   27462  \n",
       "25199                       [1, 6744, 10500, 3140, 12339]   25199  \n",
       "102362  [1, 2675, 3956, 6890, 531, 11610, 1696, 7647, ...  102362  \n",
       "90493   [1, 6626, 11845, 1347, 13272, 8018, 13217, 876...   90493  \n",
       "55216   [1, 13489, 10341, 4031, 4157, 4613, 695, 325, ...   55216  \n",
       "73043   [1, 10394, 5240, 12049, 10274, 552, 11398, 491...   73043  \n",
       "21499   [1, 6626, 10060, 1577, 11852, 11625, 8078, 105...   21499  \n",
       "96307     [1, 7714, 4911, 12887, 8240, 7714, 4911, 12887]   96307  \n",
       "60996                 [1, 10747, 4965, 1347, 7346, 11050]   60996  \n",
       "102127  [1, 560, 1577, 3561, 13019, 4031, 10776, 1347,...  102127  \n",
       "3743                    [1, 7834, 4331, 9227, 7441, 4698]    3743  \n",
       "55442                        [1, 9533, 7329, 4911, 12887]   55442  \n",
       "19964   [1, 2780, 2675, 11845, 8759, 531, 7647, 531, 3...   19964  \n",
       "104353    [1, 12789, 2376, 8172, 11178, 11852, 140, 5240]  104353  \n",
       "24363   [1, 6626, 9066, 11852, 4154, 7783, 4613, 1599,...   24363  \n",
       "39474                 [1, 820, 13105, 11852, 12298, 5708]   39474  \n",
       "56183   [1, 9746, 3894, 12049, 1378, 7742, 2376, 3008,...   56183  \n",
       "73258   [1, 602, 11852, 2895, 5240, 8929, 3651, 820, 4...   73258  \n",
       "76285            [1, 489, 4031, 4157, 13272, 4409, 12339]   76285  \n",
       "107654  [1, 5508, 7409, 1347, 4613, 4613, 1558, 12339,...  107654  \n",
       "72142   [1, 6626, 9595, 2809, 280, 3894, 7946, 3956, 3...   72142  \n",
       "39581   [1, 6626, 10060, 4965, 1599, 12981, 3849, 3956...   39581  \n",
       "79480       [1, 8353, 10157, 7338, 1696, 7519, 280, 3894]   79480  \n",
       "74011              [1, 3065, 2060, 3956, 181, 7344, 2675]   74011  \n",
       "5507                         [1, 6890, 4911, 4571, 12339]    5507  \n",
       "45315      [1, 6820, 2446, 2289, 4613, 2001, 12339, 6541]   45315  \n",
       "22751   [1, 9973, 4031, 3561, 2445, 346, 3956, 6989, 4...   22751  \n",
       "49007        [1, 7716, 9912, 4324, 695, 7344, 2802, 4031]   49007  \n",
       "...                                                   ...     ...  \n",
       "105336              [1, 3956, 4911, 4971, 757, 280, 3956]  105336  \n",
       "39      [1, 4503, 679, 3956, 9230, 8679, 10829, 11487,...      39  \n",
       "93724                      [1, 4911, 12887, 13272, 11050]   93724  \n",
       "39796   [1, 4558, 4805, 11852, 8759, 3180, 8656, 452, ...   39796  \n",
       "56201                        [1, 7470, 1347, 6381, 11050]   56201  \n",
       "26348   [1, 643, 6835, 3956, 820, 489, 4031, 4157, 734...   26348  \n",
       "10269                  [1, 6626, 4613, 7344, 12049, 5591]   10269  \n",
       "107247          [1, 12113, 6381, 7946, 4911, 7167, 12339]  107247  \n",
       "106962  [1, 11845, 1267, 1347, 12049, 8766, 11050, 974...  106962  \n",
       "68904   [1, 6626, 856, 1696, 169, 3956, 3849, 10995, 3...   68904  \n",
       "45857            [1, 2282, 7370, 1634, 6768, 1030, 11852]   45857  \n",
       "70676            [1, 1815, 7346, 3602, 6840, 9585, 13272]   70676  \n",
       "16863     [1, 4442, 7173, 12339, 7173, 12339, 6626, 1770]   16863  \n",
       "42787   [1, 13106, 280, 3956, 8412, 7954, 11845, 1622,...   42787  \n",
       "83562                  [1, 3956, 1599, 5920, 9585, 12339]   83562  \n",
       "17319              [1, 8172, 3956, 358, 5240, 643, 12339]   17319  \n",
       "90787       [1, 9446, 7850, 1696, 9746, 9585, 3894, 8987]   90787  \n",
       "102020  [1, 7948, 80, 10500, 12339, 4154, 11050, 7346,...  102020  \n",
       "64435        [1, 905, 7647, 856, 7647, 11852, 5920, 2179]   64435  \n",
       "23295      [1, 6626, 11224, 1347, 4613, 13599, 280, 3956]   23295  \n",
       "101582  [1, 8229, 4009, 2675, 2060, 9585, 12339, 9281,...  101582  \n",
       "71446   [1, 8030, 8084, 12339, 128, 9895, 4911, 12887,...   71446  \n",
       "87551   [1, 6626, 7647, 856, 3956, 8172, 13176, 7988, ...   87551  \n",
       "15204            [1, 9653, 1253, 9653, 4157, 7346, 11050]   15204  \n",
       "78598                       [1, 13500, 3956, 7946, 12339]   78598  \n",
       "73529   [1, 560, 4965, 1599, 11845, 8084, 5344, 4031, ...   73529  \n",
       "73259   [1, 11610, 1696, 9746, 4911, 7167, 3956, 5949,...   73259  \n",
       "104990  [1, 9275, 6883, 11052, 2659, 7173, 12339, 2446...  104990  \n",
       "4201                   [1, 9589, 5102, 3561, 7173, 12339]    4201  \n",
       "68728                     [1, 80, 8872, 7790, 4031, 8084]   68728  \n",
       "\n",
       "[29463 rows x 4 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.Session().run(tf.equal(inf_out.T[1], df_all_train['alpha_Pair_1_encoding'].values[:2][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8656,     5,   531,  4913,  4591,  2407,  4031,  8934,  2881,\n",
       "         6626,     1,     0],\n",
       "       [ 3956, 12460,  7068,  1599,  7647, 12339, 13500,  3956,  3849,\n",
       "            1,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Session().run(tf.pad(t, paddings, \"CONSTANT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = inf_out.T\n",
    "paddings = [[0, 0], [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8656,     5,   531,  4913,  4591,  2407,  4031,  8934,  2881,\n",
       "         6626,     1],\n",
       "       [ 3956, 12460,  7068,  1599,  7647, 12339, 13500,  3956,  3849,\n",
       "            1,     0]], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " inf_out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape_3:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape([df_all_train['alpha_Pair_1_encoding'].values[:2][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_length = max(len(df_all_train['alpha_Pair_1_encoding'].values[:2][1]), len(inf_out.T[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all_train['alpha_Pair_1_encoding'].values[:2][1]), len(inf_out.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Equal_4:0' shape=(11,) dtype=bool>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(inf_out.T[0], df_all_train['alpha_Pair_1_encoding'].values[:2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.Session().run(tf.equal([x0, x1], [y0, y1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_train_targets_eos_mask = tf.one_hot(decoder_train_length - 1,\n",
    "                                                        decoder_train_targets_seq_len,\n",
    "                                                        on_value=EOS, off_value=PAD,\n",
    "                                                        dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 19 variables.\n",
      "Converted 19 variables to const ops.\n",
      "731 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "#Freeze Model\n",
    "with tf.Session() as session:\n",
    "    #session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    #saver = tf.train.import_meta_graph(\n",
    "#'d:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10-119.meta')\n",
    "\n",
    "    saver.restore(session, \\\n",
    "'d:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10-119')\n",
    "    \n",
    "#with tf.Session(graph=tf.Graph()) as sess:\n",
    "   # sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # We import the meta graph in the current default Graph\n",
    "      # We restore the weights\n",
    "   # saver.restore(sess, 'd:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_128_decode_256_vocab_7239_embedding_256_seq_3_49_batch_32_layers_2_enkeep_10_dekeep_10-119')\n",
    "  \n",
    "\n",
    "#    # We use a built-in TF helper to export variables to constants\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        session, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        ['Decoder/dynamic_rnn_decoder/Decoder/while/attention_decoder/Softmax', \n",
    "         'Decoder/dynamic_rnn_decoder_1/Decoder/while/attention_decoder_fn_inference/Softmax'])\n",
    "                # The output node names are used to select the usefull nodes\n",
    " #   ) \n",
    "    \n",
    "    # Finally we serialize and dump the output graph to the filesystem\n",
    "    with tf.gfile.GFile('frozen_model.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    \n",
    "    print(\"%d ops in the final graph.\" % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    dir(tf.contrib.legacy_seq2seq.attention_decoder)\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph\n",
    "\n",
    "load_graph('frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
