{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "vocab_size = 17322\n",
    "beam_width = 4\n",
    "\n",
    "time = 1\n",
    "n_grams = pickle.load(open('n_grams_test.pkl', 'rb'))\n",
    "\n",
    "n_grams_tf = tf.constant(n_grams[time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(n_grams[time], columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beam = tf.constant([[6178, 5729, 15173], \n",
    "#                    [2341, 16073, 5683], \n",
    "#                    [434, 9055, 2692], \n",
    "#                    [6178, 14056, 7441]]) #Current predicted steps, will specify at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = tf.constant([[ 617],\n",
    "        [ 440032],\n",
    "        [10359],\n",
    "        [1167832]]) #Current predicted steps, will specify at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_pad = tf.pad(beam, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "initial_beam_step = tf.constant(0)\n",
    "\n",
    "n_beams = tf.constant(beam_width) #will specify at run time\n",
    "\n",
    "#When you specify the axis of concat such a rank must exist! \n",
    "#Thus cannot specify axis=1 if the rank is 0!\n",
    "scatter_base = tf.constant([vocab_size]) #Size of dict for scatter base will specify at run time\n",
    "concat_base = tf.constant([[1.0 for i in range(vocab_size)]], dtype=tf.float64) #concat base will specify vocab size at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_lm_body(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    #This loops on each beam individually\n",
    "      \n",
    "    def grab_probs(n_grams_tf, y_equal_2): \n",
    "    \n",
    "        #print ('Grab Probabilities')\n",
    "        y_args = tf.where(y_equal_2)\n",
    "\n",
    "        #Grab the n_gram sequences that are matched\n",
    "        y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "        #Take the last token in each sequence and count their unique occurrences\n",
    "\n",
    "        last_token_pos = tf.shape(y_diff_gather)[-1]\n",
    "\n",
    "        y_last_token = y_diff_gather[:,0][:,last_token_pos-1]\n",
    "        y_last_token_unique = tf.unique_with_counts(y_last_token)\n",
    "\n",
    "        total_count = tf.reduce_sum(y_last_token_unique.count)\n",
    "\n",
    "        indices = tf.reshape(y_last_token_unique.y, [tf.shape(y_last_token_unique.y)[0], 1])\n",
    "\n",
    "        test_add_result = tf.scatter_nd(indices=indices, \n",
    "                    updates=y_last_token_unique.count, shape=scatter_base)/total_count\n",
    "\n",
    "        test_add_result = tf.log(test_add_result + 10e-10)\n",
    "\n",
    "        return tf.reshape(test_add_result, [1, 17322])\n",
    "\n",
    "    def dump_zeros(n_grams_tf, y_equal_2): \n",
    "        #print ('No matches found')\n",
    "        return tf.constant([[0. for i in range(vocab_size)]], dtype=tf.float64)\n",
    "\n",
    "    #Find where current beam matches n_gram sequence up to current seq pos, cast as int\n",
    "    y_test = tf.to_int32(tf.equal(n_grams_tf, beam_pad[current_beam]))\n",
    "    #Reduce across the length of the beam \n",
    "    y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n",
    "\n",
    "    y_empty = tf.reduce_sum(y_test_reduce_sum)\n",
    "\n",
    "    #Find args where the beam is matched to the n_gram combinations\n",
    "    y_equal_2  = tf.equal(time, y_test_reduce_sum)\n",
    "\n",
    "    #Why does cond proceed down both paths?\n",
    "    test_add = tf.cond(tf.equal(0, tf.reduce_sum(tf.to_int32(y_equal_2))),\n",
    "        true_fn=lambda: dump_zeros(n_grams_tf, y_equal_2),\n",
    "        false_fn=lambda : grab_probs(n_grams_tf, y_equal_2))\n",
    "\n",
    "    test = tf.concat([test, test_add], axis=0)\n",
    "    \n",
    "    return test, n_grams_tf, beam_pad, current_beam+1, n_beams\n",
    "\n",
    "def anti_lm_condition(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    return current_beam < n_beams #number of beams, i.e. beam width, will specify at run time\n",
    "\n",
    "anti_lm_outputs = tf.while_loop(anti_lm_condition, anti_lm_body, \n",
    "                        [concat_base, n_grams_tf, beam_pad, initial_beam_step, n_beams], \n",
    "                        shape_invariants=[tf.TensorShape([None, vocab_size]), \n",
    "                                          n_grams_tf.get_shape(),\n",
    "                                      beam_pad.get_shape(), initial_beam_step.get_shape(), n_beams.get_shape()])\n",
    "\n",
    "anti_beam_probs = anti_lm_outputs[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #q = sess.run(outputs[0].stack())\n",
    "    q = sess.run(anti_lm_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 17322, 617123, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(q[0]), np.max(q[1]), np.max(q[2]), np.max(q[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 11538, 11539, ...,  5783,  5769, 17321],\n",
       "       [    0, 11537, 11538, ...,  5773, 17321, 15979],\n",
       "       [    0, 11538, 11539, ...,  5783,  5769, 17321],\n",
       "       [    0, 11524, 11525, ..., 16911, 10036,  6178],\n",
       "       [    0, 11538, 11539, ...,  5783,  5769, 17321]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
