{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import create_model\n",
    "import pickle\n",
    "import time \n",
    "import copy\n",
    "import random\n",
    "import data_formatting\n",
    "\n",
    "\n",
    "def validate(train):\n",
    "    \n",
    "    if train == True:\n",
    "        \n",
    "        model = train_model\n",
    "        mode = 'TRAIN'\n",
    "        \n",
    "    else:\n",
    "        mode = 'DEV'\n",
    "        model = dev_model\n",
    "\n",
    "    encoder, decoder, predicted = session.run([model.encoder_inputs, model.decoder_targets, model.decoder_pred_train])            \n",
    "\n",
    "    print ('Current mode:%s' % mode)\n",
    "    for i, (e_in, dt_targ, dt_pred) in enumerate(zip( encoder, decoder, predicted)):\n",
    "\n",
    "        print('  sample {}:'.format(i + 1))\n",
    "        #print('    enc input           > {}'.format(e_in))\n",
    "        print('    enc input           > {}'.format(data_formatting.decodeSent(e_in, inv_map)))\n",
    "\n",
    "        #print('    dec input           > {}'.format(dt_targ))\n",
    "        print('    dec input           > {}'.format(data_formatting.decodeSent(dt_targ, inv_map)))\n",
    "\n",
    "        #print('    dec train predicted > {}'.format(dt_pred))\n",
    "        print('    dec train predicted > {}'.format(data_formatting.decodeSent(dt_pred, inv_map)))\n",
    "\n",
    "        if i >= 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'enron'\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl')\n",
    "\n",
    "dataset = 'twitter'\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_25_sample_1764604_questions.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_25_sample_1764604_questions.pkl')\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_4_15_sample_134241_full.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_4_15_sample_134241_full.pkl')\n",
    "\n",
    "vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_19_sample_21946_lem.pkl', 'rb'))\n",
    "df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_19_sample_21946_lem.pkl')\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_25_sample_1901567_full.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_25_sample_1901567_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = data_formatting.createInvMap(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probSeq(seq, pos, n_gram_list, freq_counts):\n",
    "    seq_len  = len(seq)\n",
    "\n",
    "    if pos==seq_len: \n",
    "\n",
    "        return freq_counts\n",
    "    \n",
    "    else:\n",
    "\n",
    "        token = seq[pos]\n",
    "        n_gram_list = [n_gram for n_gram in n_gram_list if n_gram[pos]==token]\n",
    "        freq_counts.append(len(n_gram_list))\n",
    "        \n",
    "        return probSeq(seq, pos+1, n_gram_list, freq_counts)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['alpha_Pair_0_encoding'] = df_all['alpha_Pair_0_tokens'].apply(lambda x: data_formatting.encodeSent(x, vocab_dict))\n",
    "df_all['alpha_Pair_1_encoding'] = df_all['alpha_Pair_1_tokens'].apply(lambda x: data_formatting.encodeSent(x, vocab_dict))\n",
    "df_all['Index'] = df_all.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train = df_all.sample(frac=0.97, random_state=1)\n",
    "\n",
    "df_all_dev = df_all[df_all['Index'].isin(df_all_train['Index'].values) == False]\n",
    "\n",
    "df_all_test = df_all_dev.sample(frac=0.10, random_state=1)\n",
    "\n",
    "df_all_dev = df_all_dev[df_all_dev['Index'].isin(df_all_test['Index'].values) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17690 17159 478 53 17322\n"
     ]
    }
   ],
   "source": [
    "print (df_all.shape[0], df_all_train.shape[0],  df_all_dev.shape[0], df_all_test.shape[0], len(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_formatting.prepare_train_batch(df_all_train['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_train['alpha_Pair_1_encoding'].values)\n",
    "\n",
    "dev_data = data_formatting.prepare_train_batch(df_all_dev['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_dev['alpha_Pair_1_encoding'].values)\n",
    "\n",
    "test_data = data_formatting.prepare_train_batch(df_all_test['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_test['alpha_Pair_1_encoding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_params = {'n_cells':256, 'num_layers':2, 'embedding_size':512, \n",
    "          'vocab_size':len(vocab_dict) + 1, 'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':10, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_model_params = train_model_params\n",
    "dev_model_params['encoder_input_keep'] = 1\n",
    "dev_model_params['encoder_output_keep'] = 1\n",
    "dev_model_params['decoder_input_keep'] = 1\n",
    "dev_model_params['decoder_output_keep'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = { 'vocab_lower':3, 'vocab_upper':train_model_params['vocab_size']-1, \n",
    "                    'n_epochs':500000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc input           > ['i', 'll', 'be', 'there', 'tomorrow', '<EOS>']\n",
    "#dec input           > ['last', 'game', 'of', 'the', 'regular', 'season', '<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import tensor_array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inf_model_1_params = {'n_cells':256, 'num_layers':2, 'embedding_size':512, \n",
    "          'vocab_size':len(vocab_dict) + 1, 'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':1, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1,\n",
    "         }\n",
    "\n",
    "inf_model_2_params = {'n_cells':2, 'num_layers':1, 'embedding_size':5, \n",
    "            'vocab_size':7,\n",
    "          'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':3, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1,\n",
    "         }\n",
    "\n",
    "\n",
    "inf_model_2_params = {'n_cells':256, 'num_layers':2, 'embedding_size':512, \n",
    "          'vocab_size':len(vocab_dict) + 1,\n",
    "          'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':3, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1, 'anti_lm_weight':0\n",
    "         }\n",
    "\n",
    "#with tf.variable_scope('training_model'):\n",
    "\n",
    "#    inf_model_1 = create_model.Model(inf_model_1_params, 'infer', None)\n",
    "    \n",
    "#with tf.variable_scope('training_model'):\n",
    "\n",
    "#    inf_model_2 = create_model.Model(inf_model_2_params, 'infer', None)   \n",
    "\n",
    "with tf.variable_scope('training_model'):\n",
    "\n",
    "    inf_train = create_model.Model(inf_model_2_params, 'debug', None)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names_to_vars_inf = [[v.op.name, v] for v in tf.all_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1261-97ea65a51c80>:1: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1261-97ea65a51c80>:1: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "names_to_vars = [[v.op.name, v] for v in tf.all_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i[0] for i in names_to_vars_inf if 'forget' in i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training_model/rnn/multi_rnn_cell/cell_0/layer_norm_basic_lstm_cell/forget/gamma',\n",
       " 'training_model/rnn/multi_rnn_cell/cell_0/layer_norm_basic_lstm_cell/forget/beta',\n",
       " 'training_model/rnn/multi_rnn_cell/cell_1/layer_norm_basic_lstm_cell/forget/gamma',\n",
       " 'training_model/rnn/multi_rnn_cell/cell_1/layer_norm_basic_lstm_cell/forget/beta',\n",
       " 'training_model/decoder/multi_rnn_cell/cell_0/layer_norm_basic_lstm_cell/forget/gamma',\n",
       " 'training_model/decoder/multi_rnn_cell/cell_0/layer_norm_basic_lstm_cell/forget/beta',\n",
       " 'training_model/decoder/multi_rnn_cell/cell_1/Attention_Wrapper/layer_norm_basic_lstm_cell/forget/gamma',\n",
       " 'training_model/decoder/multi_rnn_cell/cell_1/Attention_Wrapper/layer_norm_basic_lstm_cell/forget/beta']"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0] for i in names_to_vars if 'forget' in i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list(['and', 'it', 'be', 'the', 'one', 'going', 'for', 'one', 'stop', '<EOS>']),\n",
       "       list(['and', 'the', 'bus', 'omg', '<EOS>']),\n",
       "       list([8378, 13635, 14926, 7441, 6200, 9187, 434, 6200, 3425, 1]),\n",
       "       list([8378, 7441, 11483, 11526, 1]), 353842], dtype=object)"
      ]
     },
     "execution_count": 1264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_dev.values[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(df_all_dev.values[1][0], vocab_dict)\n",
    "#input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run(\n",
    "        inf_train.final_outputs, \n",
    "        #inf_model_2.decoder_pred_decode,\n",
    "        feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[data_formatting.decodeSent(q_0.predicted_ids.T[i][0], inv_map), \n",
    "          q_0.scores.T[i][0]]for i in range(inf_model_2_params['beam_width'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[data_formatting.decodeSent(q_0.predicted_ids.T[i][0], inv_map), \n",
    "          q_0.scores.T[i][0]]for i in range(inf_model_2_params['beam_width'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[data_formatting.decodeSent(q_0.predicted_ids.T[i][0], inv_map), \n",
    "          q_0.scores.T[i][0]]for i in range(inf_model_2_params['beam_width'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[data_formatting.decodeSent(q_0.predicted_ids.T[i][0], inv_map), \n",
    "          q_0.scores.T[i][0]]for i in range(inf_model_2_params['beam_width'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_formatting.decodeSent(q_0.beam_search_decoder_output.predicted_ids.T[0][0], inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = inf_model_2.inference_decoder._batch_size\n",
    "beam_width = inf_model_2.inference_decoder._beam_width\n",
    "end_token = inf_model_2.inference_decoder._end_token\n",
    "length_penalty_weight = inf_model_2.inference_decoder._length_penalty_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished, first_inputs, initial_state = inf_model_2.inference_decoder.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'training_model/embedding_lookup_1:0' shape=(?, 3, 512) dtype=float32>,\n",
       " BeamSearchDecoderState(cell_state=(LSTMStateTuple(c=<tf.Tensor 'training_model/Reshape:0' shape=(?, 3, 256) dtype=float32>, h=<tf.Tensor 'training_model/Reshape_1:0' shape=(?, 3, 256) dtype=float32>), AttentionWrapperState(cell_state=LSTMStateTuple(c=<tf.Tensor 'training_model/Reshape_2:0' shape=(?, 3, 256) dtype=float32>, h=<tf.Tensor 'training_model/Reshape_3:0' shape=(?, 3, 256) dtype=float32>), attention=<tf.Tensor 'training_model/Reshape_4:0' shape=(?, 3, 256) dtype=float32>, time=<tf.Tensor 'training_model/AttentionWrapperZeroState/zeros:0' shape=() dtype=int32>, alignments=<tf.Tensor 'training_model/Reshape_5:0' shape=(?, 3, ?) dtype=float32>, alignment_history=())), log_probs=<tf.Tensor 'zeros:0' shape=(?, 3) dtype=float32>, finished=<tf.Tensor 'training_model/zeros:0' shape=(?, 3) dtype=bool>, lengths=<tf.Tensor 'zeros_1:0' shape=(?, 3) dtype=int32>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_inputs, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_inputs\n",
    "#These are the word embeddings of the initial token (which for initialize should be from the encoder?)\n",
    "#Shape is [batch_size, embedding_size]\n",
    "#initial_state\n",
    "#This is the initial state of the decoder, a tuple consisting of \n",
    "#1. the LSTM cell and hiddens states\n",
    "#2. The attention states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we pass time !=0 to inference decoder, even with initial step results we get non-zero parent ids\n",
    "\n",
    "#beam_search_output, beam_search_state, next_inputs, finished = \\\n",
    "#                                                inf_model_2.inference_decoder.step(time, first_inputs, initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([first_inputs, initial_state, batch_size], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 512)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ops.name_scope(name, \"BeamSearchDecoderStep\", (time, first_inputs, initial_state)):\n",
    "    \n",
    "cell_state = initial_state.cell_state\n",
    "\n",
    "first_inputs = nest.map_structure(lambda inp: inf_model_2.inference_decoder._merge_batch_beams(inp, s=inp.shape[2:]), \n",
    "                                  first_inputs)\n",
    "\n",
    "cell_state = nest.map_structure(inf_model_2.inference_decoder._maybe_merge_batch_beams, cell_state, \n",
    "                                inf_model_2.inference_decoder._cell.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'training_model/Reshape:0' shape=(?, 3, 256) dtype=float32>, h=<tf.Tensor 'training_model/Reshape_1:0' shape=(?, 3, 256) dtype=float32>),\n",
       " AttentionWrapperState(cell_state=LSTMStateTuple(c=<tf.Tensor 'training_model/Reshape_2:0' shape=(?, 3, 256) dtype=float32>, h=<tf.Tensor 'training_model/Reshape_3:0' shape=(?, 3, 256) dtype=float32>), attention=<tf.Tensor 'training_model/Reshape_4:0' shape=(?, 3, 256) dtype=float32>, time=<tf.Tensor 'training_model/AttentionWrapperZeroState/zeros:0' shape=() dtype=int32>, alignments=<tf.Tensor 'training_model/Reshape_5:0' shape=(?, 3, ?) dtype=float32>, alignment_history=()))"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state.cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'Reshape_44:0' shape=(?,) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Reshape_44:0\", shape=(?,), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 270\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    271\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2707\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2786\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2787\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"Reshape_44:0\", shape=(?,), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1268-511cd125d8ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     q_0 = sess.run([first_inputs, initial_state], \n\u001b[0;32m      9\u001b[0m                  feed_dict={'training_model/encoder_inputs:0':[input_user], \n\u001b[1;32m---> 10\u001b[1;33m                          'training_model/encoder_inputs_length:0':[len(input_user)]})\n\u001b[0m",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1109\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \"\"\"\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 277\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    278\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Reshape_44:0' shape=(?,) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Reshape_44:0\", shape=(?,), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([first_inputs, initial_state], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This goes through _cell first\n",
    "#The output of cell_outputs is also present in the next_cell_state, the cell_outputs is the attention\n",
    "\n",
    "#The cell_state includes, the cell and hidden states of the LSTM, the attention states, the alignment history, and timestep, \n",
    "#what does alignment history and attention states really mean? need to internalize...\n",
    "\n",
    "cell_outputs, next_cell_state = inf_model_2.inference_decoder._cell(first_inputs, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'training_model/decoder/while/BeamSearchDecoderStep/output_projection/BiasAdd_1:0' shape=(?, 3, 17323) dtype=float32>"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'training_model/decoder/while/BeamSearchDecoderStep/output_projection/BiasAdd_1:0' shape=(?, 3, 17323) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"training_model/decoder/while/BeamSearchDecoderStep/output_projection/BiasAdd_1:0\", shape=(?, 3, 17323), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 270\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    271\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2707\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2786\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2787\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"training_model/decoder/while/BeamSearchDecoderStep/output_projection/BiasAdd_1:0\", shape=(?, 3, 17323), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1270-a7787407e5a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     q_0 = sess.run([cell_outputs, next_cell_state], \n\u001b[0;32m      9\u001b[0m                  feed_dict={'training_model/encoder_inputs:0':[input_user, input_user], \n\u001b[1;32m---> 10\u001b[1;33m                          'training_model/encoder_inputs_length:0':[len(input_user), len(input_user)]})\n\u001b[0m",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1109\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \"\"\"\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \"\"\"\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 277\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    278\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'training_model/decoder/while/BeamSearchDecoderStep/output_projection/BiasAdd_1:0' shape=(?, 3, 17323) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"training_model/decoder/while/BeamSearchDecoderStep/output_projection/BiasAdd_1:0\", shape=(?, 3, 17323), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([cell_outputs, next_cell_state], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user, input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user), len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_0[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected behavior when reshaping between beam width and batch size.  The reshaped tensor has shape: (?, 3, 3, 256).  We expected it to have shape (batch_size, beam_width, depth) == (?, 3, 256).  Perhaps you forgot to create a zero_state with batch_size=encoder_batch_size * beam_width?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1271-1e5bb7a5f34b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m next_cell_state = nest.map_structure(inf_model_2.inference_decoder._maybe_split_batch_beams, next_cell_state, \n\u001b[1;32m----> 9\u001b[1;33m                                      inf_model_2.inference_decoder._cell.state_size)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minf_model_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_layer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **check_types_dict)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 379\u001b[1;33m       structure[0], [func(*x) for x in entries])\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 379\u001b[1;33m       structure[0], [func(*x) for x in entries])\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\beam_search_decoder.py\u001b[0m in \u001b[0;36m_maybe_split_batch_beams\u001b[1;34m(self, t, s)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[0m_check_maybe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_split_batch_beams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\seq2seq\\python\\ops\\beam_search_decoder.py\u001b[0m in \u001b[0;36m_split_batch_beams\u001b[1;34m(self, t, s)\u001b[0m\n\u001b[0;32m    348\u001b[0m                        \u001b[1;34m\"forgot to create a zero_state with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m                        \u001b[1;34m\"batch_size=encoder_batch_size * beam_width?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                        % (reshaped_t.shape, expected_reshaped_shape))\n\u001b[0m\u001b[0;32m    351\u001b[0m     \u001b[0mreshaped_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_reshaped_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreshaped_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected behavior when reshaping between beam width and batch size.  The reshaped tensor has shape: (?, 3, 3, 256).  We expected it to have shape (batch_size, beam_width, depth) == (?, 3, 256).  Perhaps you forgot to create a zero_state with batch_size=encoder_batch_size * beam_width?"
     ]
    }
   ],
   "source": [
    "#These functions convert the shape of the cell outputs and states from [batch_size, beam_width, embedding_size]\n",
    "#to [batch_size*beam_width, embedding_size], essentially, reducing a dimensionality by flattening the nested structure\n",
    "#the map structure fn is used because cell state is a complex tuple structure, \n",
    "#outputs is a simpe structure (should be able to just call flatten?)\n",
    "cell_outputs = nest.map_structure(lambda out: inf_model_2.inference_decoder._split_batch_beams(out, out.shape[1:]), \n",
    "                                  cell_outputs)\n",
    "\n",
    "next_cell_state = nest.map_structure(inf_model_2.inference_decoder._maybe_split_batch_beams, next_cell_state, \n",
    "                                     inf_model_2.inference_decoder._cell.state_size)\n",
    "\n",
    "if inf_model_2.inference_decoder._output_layer is not None:\n",
    "    cell_outputs = inf_model_2.inference_decoder._output_layer(cell_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell_outputs_rnn_call, next_cell_state_rnn_call = inf_model_2.inference_decoder._cell.call(first_inputs, cell_state)\n",
    "\n",
    "#cell_outputs_rnn_call_call, next_cell_state_rnn_call_call = inf_model_2.inference_decoder._cell.call(cell_outputs_rnn_call, \n",
    "#                                                                                                     next_cell_state_rnn_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_batch_size = tensor_util.constant_value(batch_size)\n",
    "\n",
    "prediction_lengths = initial_state.lengths\n",
    "previously_finished = initial_state.finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token = data_formatting.EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_maybe(t):\n",
    "  if isinstance(t, tensor_array_ops.TensorArray):\n",
    "    raise TypeError(\n",
    "        \"TensorArray state is not supported by BeamSearchDecoder: %s\" % t.name)\n",
    "  if t.shape.ndims is None:\n",
    "    raise ValueError(\n",
    "        \"Expected tensor (%s) to have known rank, but ndims == None.\" % t)\n",
    "\n",
    "def _maybe_tensor_gather_helper(gather_indices, gather_from, batch_size,\n",
    "                                range_size, gather_shape):\n",
    "  \"\"\"Maybe applies _tensor_gather_helper.\n",
    "  This applies _tensor_gather_helper when the gather_from dims is at least as\n",
    "  big as the length of gather_shape. This is used in conjunction with nest so\n",
    "  that we don't apply _tensor_gather_helper to inapplicable values like scalars.\n",
    "  Args:\n",
    "    gather_indices: The tensor indices that we use to gather.\n",
    "    gather_from: The tensor that we are gathering from.\n",
    "    batch_size: The batch size.\n",
    "    range_size: The number of values in each range. Likely equal to beam_width.\n",
    "    gather_shape: What we should reshape gather_from to in order to preserve the\n",
    "      correct values. An example is when gather_from is the attention from an\n",
    "      AttentionWrapperState with shape [batch_size, beam_width, attention_size].\n",
    "      There, we want to preserve the attention_size elements, so gather_shape is\n",
    "      [batch_size * beam_width, -1]. Then, upon reshape, we still have the\n",
    "      attention_size as desired.\n",
    "  Returns:\n",
    "    output: Gathered tensor of shape tf.shape(gather_from)[:1+len(gather_shape)]\n",
    "      or the original tensor if its dimensions are too small.\n",
    "  \"\"\"\n",
    "  _check_maybe(gather_from)\n",
    "  if gather_from.shape.ndims >= len(gather_shape):\n",
    "    return _tensor_gather_helper(\n",
    "        gather_indices=gather_indices,\n",
    "        gather_from=gather_from,\n",
    "        batch_size=batch_size,\n",
    "        range_size=range_size,\n",
    "        gather_shape=gather_shape)\n",
    "  else:\n",
    "    return gather_from\n",
    "\n",
    "def _tensor_gather_helper(gather_indices, gather_from, batch_size,\n",
    "                          range_size, gather_shape):\n",
    "  \"\"\"Helper for gathering the right indices from the tensor.\n",
    "  This works by reshaping gather_from to gather_shape (e.g. [-1]) and then\n",
    "  gathering from that according to the gather_indices, which are offset by\n",
    "  the right amounts in order to preserve the batch order.\n",
    "  Args:\n",
    "    gather_indices: The tensor indices that we use to gather.\n",
    "    gather_from: The tensor that we are gathering from.\n",
    "    batch_size: The input batch size.\n",
    "    range_size: The number of values in each range. Likely equal to beam_width.\n",
    "    gather_shape: What we should reshape gather_from to in order to preserve the\n",
    "      correct values. An example is when gather_from is the attention from an\n",
    "      AttentionWrapperState with shape [batch_size, beam_width, attention_size].\n",
    "      There, we want to preserve the attention_size elements, so gather_shape is\n",
    "      [batch_size * beam_width, -1]. Then, upon reshape, we still have the\n",
    "      attention_size as desired.\n",
    "  Returns:\n",
    "    output: Gathered tensor of shape tf.shape(gather_from)[:1+len(gather_shape)]\n",
    "  \"\"\"\n",
    "  range_ = array_ops.expand_dims(math_ops.range(batch_size) * range_size, 1)\n",
    "  gather_indices = array_ops.reshape(gather_indices + range_, [-1])\n",
    "  output = array_ops.gather(\n",
    "      array_ops.reshape(gather_from, gather_shape), gather_indices)\n",
    "  final_shape = array_ops.shape(gather_from)[:1 + len(gather_shape)]\n",
    "  static_batch_size = tensor_util.constant_value(batch_size)\n",
    "  final_static_shape = (tensor_shape.TensorShape([static_batch_size])\n",
    "                        .concatenate(\n",
    "                            gather_from.shape[1:1 + len(gather_shape)]))\n",
    "  output = array_ops.reshape(output, final_shape)\n",
    "  output.set_shape(final_static_shape)\n",
    "  return output\n",
    "#Have to understand how this works!\n",
    "def _mask_probs(probs, eos_token, finished):\n",
    "  \"\"\"Masks log probabilities.\n",
    "  The result is that finished beams allocate all probability mass to eos and\n",
    "  unfinished beams remain unchanged.\n",
    "  Args:\n",
    "    probs: Log probabiltiies of shape `[batch_size, beam_width, vocab_size]`\n",
    "    eos_token: An int32 id corresponding to the EOS token to allocate\n",
    "      probability to.\n",
    "    finished: A boolean tensor of shape `[batch_size, beam_width]` that\n",
    "      specifies which\n",
    "      elements in the beam are finished already.\n",
    "  Returns:\n",
    "    A tensor of shape `[batch_size, beam_width, vocab_size]`, where unfinished\n",
    "    beams stay unchanged and finished beams are replaced with a tensor with all\n",
    "    probability on the EOS token.\n",
    "  \"\"\"\n",
    "  vocab_size = array_ops.shape(probs)[2]\n",
    "  finished_mask = array_ops.expand_dims(\n",
    "      math_ops.to_float(1. - math_ops.to_float(finished)), 2)\n",
    "  # These examples are not finished and we leave them\n",
    "  non_finished_examples = finished_mask * probs\n",
    "  # All finished examples are replaced with a vector that has all\n",
    "  # probability on EOS\n",
    "  finished_row = array_ops.one_hot(\n",
    "      eos_token,\n",
    "      vocab_size,\n",
    "      dtype=probs.dtype,\n",
    "      on_value=0.,\n",
    "      off_value=probs.dtype.min)\n",
    "  finished_examples = (1. - finished_mask) * finished_row\n",
    "  return finished_examples + non_finished_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = cell_outputs\n",
    "step_log_probs = nn_ops.log_softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([step_log_probs, logits, cell_outputs], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3, 17323), (1, 3, 17323), (1, 3, 17323))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0].shape, q_0[1].shape, q_0[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_15:0' shape=(?, 3, 17323) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_14:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(step_log_probs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_log_probs = _mask_probs(step_log_probs, end_token, previously_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_probs = array_ops.expand_dims(initial_state.log_probs, 2) + step_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_probs_1 = total_probs-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([total_probs, previously_finished], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3802, 11741, 13899, ..., 11678, 10359,  4400], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(q_0[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8556143"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0][0][0][4400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = logits.shape[-1].value or array_ops.shape(logits)[-1]\n",
    "\n",
    "lengths_to_add = array_ops.one_hot(\n",
    "      indices=array_ops.tile(\n",
    "          array_ops.reshape(end_token, [1, 1]), [batch_size, beam_width]),\n",
    "      depth=vocab_size,\n",
    "      on_value=0,\n",
    "      off_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_scores(log_probs, sequence_lengths, length_penalty_weight, time):\n",
    "    \"\"\"Calculates scores for beam search hypotheses.\n",
    "    Args:\n",
    "    log_probs: The log probabilities with shape\n",
    "    `[batch_size, beam_width, vocab_size]`.\n",
    "    sequence_lengths: The array of sequence lengths.\n",
    "    length_penalty_weight: Float weight to penalize length. Disabled with 0.0.\n",
    "    Returns:\n",
    "    The scores normalized by the length_penalty.\n",
    "    \"\"\"\n",
    "    length_penality_ = _length_penalty(sequence_lengths=sequence_lengths, penalty_factor=length_penalty_weight)\n",
    "\n",
    "    score = log_probs/length_penality_\n",
    "\n",
    "    current_time = tf.contrib.util.constant_value(time)\n",
    "\n",
    "    if current_time==0:\n",
    "        \n",
    "        sorted_tokens = sorted([i[0] for i in n_grams[0] if i[0] in inv_map.keys()])\n",
    "\n",
    "        X = tf.constant(sorted_tokens)\n",
    "        y, idx, cnts = tf.unique_with_counts(X)\n",
    "        cnts_prob = tf.log(cnts/len(sorted_tokens))\n",
    "\n",
    "        prob_T = {a[i]:b[i] for i in range(len(a))}\n",
    "\n",
    "        p_T = [-1000  if i not in a else prob_T[i] for i in range(len(inv_map))]\n",
    "        score = score + p_T\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _length_penalty(sequence_lengths, penalty_factor):\n",
    "  \"\"\"Calculates the length penalty. See https://arxiv.org/abs/1609.08144.\n",
    "  Args:\n",
    "    sequence_lengths: The sequence length of all hypotheses, a tensor\n",
    "      of shape [beam_size, vocab_size].\n",
    "    penalty_factor: A scalar that weights the length penalty.\n",
    "  Returns:\n",
    "    The length penalty factor, a tensor fo shape [beam_size].\n",
    "  \"\"\"\n",
    "  penalty_factor = ops.convert_to_tensor(penalty_factor, name=\"penalty_factor\")\n",
    "  penalty_factor.set_shape(())  # penalty should be a scalar.\n",
    "  static_penalty = tensor_util.constant_value(penalty_factor)\n",
    "  if static_penalty is not None and static_penalty == 0:\n",
    "    return 1.0\n",
    "  return math_ops.div((5. + math_ops.to_float(sequence_lengths))\n",
    "                      **penalty_factor, (5. + 1.)**penalty_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_mask = (1 - math_ops.to_int32(previously_finished))\n",
    "\n",
    "lengths_to_add = array_ops.expand_dims(add_mask, 2) * lengths_to_add\n",
    "\n",
    "new_prediction_lengths = (lengths_to_add + array_ops.expand_dims(prediction_lengths, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = pickle.load(open('n_grams_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tokens = sorted([i[0] for i in n_grams[0] if i[0] in inv_map.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= np.unique(sorted_tokens, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    3     5     6 ..., 17320 17321 17322]\n",
      "[  1.10949002e-05   5.54745011e-06   5.54745011e-05 ...,   1.66423503e-05\n",
      "   5.54745011e-06   1.10949002e-05]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = tf.constant(sorted_tokens)\n",
    "y, idx, cnts = tf.unique_with_counts(X)\n",
    "cnts_prob = cnts/len(sorted_tokens)\n",
    "with tf.Session() as sess:\n",
    "    a, _, b = sess.run([y, idx, cnts_prob])\n",
    "    print (a)\n",
    "    print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_T = {a[i]:np.log(b[i]/len(sorted_tokens)) for i in range(len(a))}\n",
    "\n",
    "p_T = [-100  if i not in a else prob_T[i]*0.1 for i in range(len(inv_map))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19000337662121669"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_T[4400]*.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = total_probs + p_T\n",
    "scores = total_probs\n",
    "scores_shape = array_ops.shape(scores)\n",
    "\n",
    "time = ops.convert_to_tensor(time, name=\"time\")\n",
    "\n",
    "scores_flat = control_flow_ops.cond(time > 0,\n",
    "      lambda: array_ops.reshape(scores, [batch_size, -1]), lambda: scores[:, 0])\n",
    "\n",
    "num_available_beam = control_flow_ops.cond(\n",
    "      time > 0, lambda: math_ops.reduce_prod(scores_shape[1:]),\n",
    "      lambda: math_ops.reduce_prod(scores_shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_flat = scores_flat + p_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the next beams according to the specified successors function\n",
    "next_beam_size = math_ops.minimum(\n",
    "  ops.convert_to_tensor(beam_width, dtype=dtypes.int32, name=\"beam_width\"),\n",
    "  num_available_beam)\n",
    "\n",
    "next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=next_beam_size)\n",
    "next_beam_scores.set_shape([static_batch_size, beam_width])\n",
    "word_indices.set_shape([static_batch_size, beam_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([scores_flat], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.7556474, -1.9000337662121667)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0][0][4400], p_T[4400] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.7556474, -2.7556497362121668)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0][0][4400], p_T[4400] + -0.85561597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.7556474, -2.7556497362121668)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0][0][4400], p_T[4400] + -0.85561597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 10150,  2557, ..., 17149, 10359,  4400]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(q_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-133.68927002, -127.15158081, -127.81147003, ...,  -19.06400108,\n",
       "          -28.31323433,  -30.63676834]], dtype=float32)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_beam_probs = _tensor_gather_helper(\n",
    "      gather_indices=word_indices,\n",
    "      gather_from=scores,\n",
    "      batch_size=batch_size,\n",
    "      range_size=beam_width * vocab_size,\n",
    "      gather_shape=[-1])\n",
    "\n",
    "#Here, word indices represents the positions of the flattened list of beams, which goes from 1 to beam_width*vocab_size\n",
    "#thus the word indices obtained are not the word indices of the 1 to N vocab but the flattened out list of logprobs from 1 to \n",
    "#beam_width*vocab_size\n",
    "next_word_ids = math_ops.to_int32(word_indices % vocab_size)\n",
    "#The beam_ids represent which beams these word indices (and thereby log prob values belong to), as\n",
    "#we have word indices extracted out of 1 to beam_width*vocab_size\n",
    "next_beam_ids = math_ops.to_int32(word_indices / vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([next_word_ids, next_beam_ids, scores, scores_flat, next_beam_scores, next_beam_probs,\n",
    "                    word_indices, next_beam_size], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last', 'hey', 'my']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_map[i] for i in q_0[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'last', 'hey']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_map[i] for i in [17149,  4400, 10359]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4400"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(q_0[2][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.42817593, -4.01685619, -2.75564575], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[3][0][np.argsort(q_0[3][0])[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.17919826"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-9.57212543 + -2.60707283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.80869818"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-7.75377798 + -2.0549202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.35237133"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-7.49675941 + -0.85561192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.42817593, -4.01685619, -2.75564575], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[3][0][np.argsort(q_0[3][0])[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-133.68927002, -127.15158844, -127.81147003, ...,  -19.06400299,\n",
       "         -28.31324005,  -30.63677025], dtype=float32),\n",
       " array([], dtype=float32),\n",
       " array([], dtype=float32))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[3][0][:vocab_size], q_0[3][0][vocab_size:vocab_size*2], q_0[3][0][vocab_size*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.75564575, -4.01685619, -4.42817593]], dtype=float32),\n",
       " array([[-0.85561204, -2.05491853, -2.74253583]], dtype=float32))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[4], q_0[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4400, 10359, 17149]]), array([[0, 0, 0]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0[0], q_0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "previously_finished = _tensor_gather_helper(\n",
    "      gather_indices=next_beam_ids,\n",
    "      gather_from=previously_finished,\n",
    "      batch_size=batch_size,\n",
    "      range_size=beam_width,\n",
    "      gather_shape=[-1])\n",
    "\n",
    "next_finished = math_ops.logical_or(previously_finished, math_ops.equal(next_word_ids, end_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_to_add = math_ops.to_int32(math_ops.not_equal(next_word_ids, end_token))\n",
    "lengths_to_add = (1 - math_ops.to_int32(next_finished)) * lengths_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([previously_finished, next_finished, lengths_to_add], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[False, False, False]], dtype=bool),\n",
       " array([[False, False, False]], dtype=bool),\n",
       " array([[1, 1, 1]])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_prediction_len = _tensor_gather_helper(\n",
    "      gather_indices=next_beam_ids,\n",
    "      gather_from=initial_state.lengths,\n",
    "      batch_size=batch_size,\n",
    "      range_size=beam_width,\n",
    "      gather_shape=[-1])\n",
    "\n",
    "next_prediction_len += lengths_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_1 = sess.run([next_prediction_len],\n",
    "                     feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 1, 1]])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cell_state = nest.map_structure(\n",
    "      lambda gather_from: _maybe_tensor_gather_helper(\n",
    "          gather_indices=next_beam_ids,\n",
    "          gather_from=gather_from,\n",
    "          batch_size=batch_size,\n",
    "          range_size=beam_width,\n",
    "          gather_shape=[batch_size * beam_width, -1]),\n",
    "      next_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_1 = sess.run([next_cell_state],\n",
    "                     feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the returns, next_state and output to the step function, but how exactly do we transpose this back and push it\n",
    "#into cell? Moreover what is teh mechanics that determines when the beams become different? I.E. are no longer identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_state = tf.contrib.seq2seq.BeamSearchDecoderState(\n",
    "      cell_state=next_cell_state,\n",
    "      log_probs=next_beam_probs,\n",
    "      lengths=next_prediction_len,\n",
    "      finished=next_finished)\n",
    "\n",
    "beam_search_output = tf.contrib.seq2seq.BeamSearchDecoderOutput(\n",
    "      scores=next_beam_scores,\n",
    "      predicted_ids=next_word_ids,\n",
    "      parent_ids=next_beam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_1 = sess.run([beam_search_state],\n",
    "                     feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define the returns\n",
    "finished = beam_search_state.finished\n",
    "next_finished = finished\n",
    "sample_ids = beam_search_output.predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is most important, look up the new seq terms and take their embedding\n",
    "#We pass that onto the decoder cell network in the next loop iteration\n",
    "\n",
    "next_inputs = tf.cond(tf.reduce_all(finished), lambda: inf_model_2.inference_decoder._start_inputs,\n",
    "              lambda: inf_model_2.inference_decoder._embedding_fn(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mod:0' shape=(?, 3) dtype=int32>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_output.predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape(batch_size, from_shape):\n",
    "    if not isinstance(from_shape, tf.TensorShape):\n",
    "        return tensor_shape.TensorShape(None)\n",
    "    else:\n",
    "        batch_size = tf.contrib.util.constant_value(tf.convert_to_tensor(batch_size, name=\"batch_size\"))\n",
    "        return tf.TensorShape([batch_size]).concatenate(from_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_ta(s, d):\n",
    "    return tf.TensorArray(\n",
    "        dtype=d, size=0, dynamic_size=True, element_shape=_shape(batch_size, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_outputs_ta = nest.map_structure(_create_ta, inf_model_2.inference_decoder.output_size,\n",
    "                                                    inf_model_2.inference_decoder.output_dtype)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return time, outputs, state, inputs, finished, sequence_lengths\n",
    "\n",
    "initial_outputs_ta = nest.map_structure(lambda ta, out: ta.write(time, out),\n",
    "                          initial_outputs_ta, beam_search_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_outputs = nest.map_structure(lambda ta: ta.stack(), initial_outputs_ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_1 = sess.run(final_outputs.predicted_ids,\n",
    "                     feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4400, 10359, 17149]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_outputs.predicted_ids , \n",
    "#array([[ 4400, 10359, 17149]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_sequence_lengths = tf.where(\n",
    "#  tf.logical_and(tf.logical_not(finished), next_finished),\n",
    "#      tf.fill(tf.shape(sequence_lengths), time + 1),\n",
    "#  sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = beam_search_state.finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = beam_search_output.predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-0d4c83fdda06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_ids' is not defined"
     ]
    }
   ],
   "source": [
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inputs = control_flow_ops.cond(math_ops.reduce_all(finished), \n",
    "                                    lambda: inf_model_2.inference_decoder._start_inputs,\n",
    "                                    lambda: inf_model_2.inference_decoder._embedding_fn(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_1 = sess.run([next_inputs, beam_search_state, sample_ids],\n",
    "                     feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4400, 10359, 11678]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 512)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-edf476c3c21b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mq_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "q_0[1][3].shape, q_1[1][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_0[1][2].shape, q_1[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_0[1][1].shape, q_1[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q_0[1][0]), len(q_1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_inputs\n",
    "#These are the chosen word ids which we have performed the embedding look up for\n",
    "first_inputs = next_inputs[0]#The [0] is for batch size, should not need it\n",
    "\n",
    "#next_states\n",
    "#these are the next states of the decoder network which pass back through the process\n",
    "initial_state = next_state\n",
    "\n",
    "finished = finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "time =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs.predicted_id at first pass time=1\n",
    "#array([[ 4400, 10359, 17149]])\n",
    "#time =1\n",
    "time = 2\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = pickle.load(open('n_grams_test.pkl', 'rb'))\n",
    "\n",
    "n_grams_tf = tf.constant(n_grams[time])\n",
    "\n",
    "beam_length = n_grams_tf.shape[1].value\n",
    "\n",
    "#test = tf.constant([4400, 10359, 17149])\n",
    "beam = tf.constant([[6178, 5729], [8847, 16625], [12377,  6605]])\n",
    "\n",
    "beam_pad = tf.pad(beam, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "n_grams_tf.shape[0].value\n",
    "\n",
    "multiply = tf.constant([1, n_grams_tf.shape[0].value])\n",
    "\n",
    "beam_pad_matrix = tf.tile(beam_pad, multiply)\n",
    "\n",
    "beam_pad_matrix_reshape = tf.reshape(beam_pad_matrix, \\\n",
    "                                     [beam_length, n_grams_tf.shape[0].value, beam_length])\n",
    "\n",
    "multiply = tf.constant([beam.shape[0].value, 1])\n",
    "\n",
    "matrix = tf.tile(n_grams_tf, multiply)\n",
    "\n",
    "matrix_reshape = tf.reshape(matrix, [beam_length, n_grams_tf.shape[0].value, beam_length])\n",
    "\n",
    "y_matrix_reshape = tf.subtract(matrix_reshape, beam_pad_matrix_reshape)\n",
    "\n",
    "y_indices = tf.to_int32(tf.equal(tf.zeros([1, beam_length], dtype=tf.int32), y_matrix_reshape))\n",
    "\n",
    "y_indices_reduce_sum = tf.reduce_sum(y_indices, axis=2)\n",
    "\n",
    "y_args = tf.where(tf.equal(2, y_indices_reduce_sum))\n",
    "\n",
    "mask_test = tf.boolean_mask(matrix_reshape, tf.equal(tf.zeros([1, beam_length], dtype=tf.int32), y_matrix_reshape))\n",
    "\n",
    "vocab_count_template = tf.Variable(tf.zeros([3, vocab_size], dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    q = sess.run([vocab_count_template, wwww, y_args, y_indices_reduce_sum, y_indices, y_matrix_reshape ,matrix_reshape, beam_pad_matrix_reshape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "time = 2\n",
    "n_grams = pickle.load(open('n_grams_test.pkl', 'rb'))\n",
    "\n",
    "n_grams_tf = tf.constant(n_grams[time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_length = time + 1\n",
    "\n",
    "#test = tf.constant([4400, 10359, 17149])\n",
    "beam = tf.constant([[6178, 5729], [8847, 16625], [12377,  6605]])\n",
    "\n",
    "beam_pad = tf.pad(beam, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_beam = tf.constant(0)\n",
    "n_beams = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = tf.subtract(n_grams_tf, beam_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test  = tf.Variable(np.reshape(np.array([0 for i in range(180261*3)]), (180261, 3)), dtype=tf.int32, name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.Variable([0 for i in range(17322)], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_beam_step = tf.constant(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = tf.contrib.util.constant_value(current_beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you specify the axis of concat such a rank must exist! \n",
    "#Thus cannot specify axis=1 if the rank is 0!\n",
    "scatter_base = tf.constant([17322])\n",
    "concat_base = tf.constant([[1 for i in range(17322)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    #This loops on each beam individually\n",
    "    \n",
    "    #test = tf.concat([test, beam[time]], axis=0)\n",
    "    \n",
    "    #Find where current beam matches n_gram sequence up to current seq pos, cast as int\n",
    "    y_test = tf.to_int32(tf.equal(n_grams_tf, beam_pad[current_beam]))\n",
    "    #Reduce across the length of the beam \n",
    "    y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n",
    "    #Find args where the beam is matched to the n_gram combinations\n",
    "    y_args = tf.where(tf.equal(2, y_test_reduce_sum))\n",
    "    #Grab the n_gram sequences that are matched\n",
    "    y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "    #Take the last token in each sequence and count their unique occurrences\n",
    "    y_last_token = y_diff_gather[:,0][:,time]\n",
    "    y_last_token_unique = tf.unique_with_counts(y_last_token)\n",
    "\n",
    "    stack_index = tf.fill([tf.shape(y_last_token_unique.y)[0]], current_beam)\n",
    "\n",
    "    #concat_y_last_token_unique_count = tf.stack([stack_index, y_last_token_unique.y], axis=1)\n",
    "\n",
    "    test_add = tf.scatter_nd(indices=y_last_token_unique.y, updates=y_last_token_unique.count, shape=scatter_base)\n",
    "    \n",
    "    test = tf.concat([test, [test_add]], axis=0)\n",
    "    \n",
    "    #Initialize and create a zero element vector of length vocabulary and add the obtained frequency counts\n",
    "    #to the indexes which represent token ids, normalize to get probability\n",
    "   # vocab = tf.Variable(tf.zeros([len(vocab_dict)], dtype=tf.int32))\n",
    "    #with tf.variable_scope('vocab', reuse=None):\n",
    "   # qq = tf.contrib.util.constant_value(current_beam)\n",
    "  # # vocab = tf.get_variable(name='vocab5_%d' % qq , \n",
    "   #                         shape=(len(vocab_dict)), dtype=tf.int32,\n",
    "   #                         initializer=tf.zeros_initializer())\n",
    "\n",
    "   # vocab_with_probs = tf.scatter_add(vocab, y_last_token_unique.y,\n",
    "      #                                    y_last_token_unique.count)/tf.reduce_sum(y_last_token_unique.count)\n",
    "    \n",
    "   # test = tf.to_float(vocab_with_probs)\n",
    "    #test = tf.concat([test, tf.to_float(vocab_with_probs)], axis=0)\n",
    "    \n",
    "    return test, n_grams_tf, beam_pad, current_beam+1, n_beams\n",
    "\n",
    "def condition(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    return current_beam < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.while_loop(condition, body, \n",
    "                        [concat_base, n_grams_tf, beam_pad, initial_beam_step, n_beams], \n",
    "                        shape_invariants=[tf.TensorShape([None, 17322]), n_grams_tf.get_shape(),\n",
    "                                      beam_pad.get_shape(), initial_beam_step.get_shape(), n_beams.get_shape()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #q = sess.run(outputs[0].stack())\n",
    "    q = sess.run(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 11537, 11538, ...,  5769,  5775, 15173], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(q[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0, 11494, 11495, ..., 14250, 15173,  3380], dtype=int64),\n",
       " 0.086065575)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(q[0]), q[0][3380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25819671"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0][0][3380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tf.constant(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = tf.Variable([[0 for i in range(17322)], [0 for i in range(17322)] ,[0 for i in range(17322)]], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find where current beam matches n_gram sequence up to current seq pos, cast as int\n",
    "y_test = tf.to_int32(tf.equal(n_grams_tf, beam_pad[0]))\n",
    "#Reduce across the length of the beam \n",
    "y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n",
    "#Find args where the beam is matched to the n_gram combinations\n",
    "y_args = tf.where(tf.equal(2, y_test_reduce_sum))\n",
    "#Grab the n_gram sequences that are matched\n",
    "y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "#Take the last token in each sequence and count their unique occurrences\n",
    "y_last_token = y_diff_gather[:,0][:,time]\n",
    "y_last_token_unique = tf.unique_with_counts(y_last_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and create a zero element vector of length vocabulary and add the obtained frequency counts\n",
    "#to the indexes which represent token ids, normalize to get probability\n",
    "#vocab = tf.Variable(tf.zeros([len(vocab_dict)], dtype=tf.int32))\n",
    "#vocab = tf.Variable(tf.zeros([len(vocab_dict)], dtype=tf.int32))\n",
    "#vocab = tf.get_variable(name='vocab_b', shape=(len(vocab_dict)), dtype=tf.int32,\n",
    "#                      initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_with_log_probs = tf.scatter_add(test_3, y_last_token_unique.y,\n",
    " #                                     y_last_token_unique.count)/tf.reduce_sum(y_last_token_unique.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, specify the dimensions of the scattered tensor, here this means its 3x4 ie\n",
    "# [0, 0, 0, 0\n",
    "#  0, 0, 0, 0\n",
    "#  0, 0, 0, 0]\n",
    "test_3 = tf.constant([17322])\n",
    "#Next indices specifies the coordinates\n",
    "#So [[0, 2], [1, 2]] specifies two indices\n",
    "#at zeroth row, 2nd column (counting from zero)\n",
    "#and first row, 2nd column\n",
    "indices = tf.constant([[    0, 15173],\n",
    "       [    0, 15259],\n",
    "       [    0, 11599]])\n",
    "#Next, specify the actual values, to be inserted into these positions\n",
    "updates = tf.constant([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_base = tf.constant([1 for i in range(17322)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack_index = tf.fill([tf.shape(y_last_token_unique.y)[0]], 2)\n",
    "\n",
    "#concat_y_last_token_unique_count = tf.stack([stack_index, y_last_token_unique.y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_add= tf.scatter_nd(indices=y_last_token_unique.y, updates=y_last_token_unique.count, shape=test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_base = tf.constant([[1 for i in range(17322)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_add_nest = [test_add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_concat = tf.concat([concat_base, [test_add]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    w = sess.run([tf_concat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(w[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0, 11537, 11538, ...,  5769,  5775, 15173], dtype=int64)"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First subtract the current (padded) beam from the list of n_gram combinations\n",
    "#y_diff = tf.subtract(n_grams_tf, beam_pad[0])\n",
    "#\n",
    "#y_segments = y_diff[:,0]\n",
    "#y_data = y_diff[:,1]\n",
    "#\n",
    "#y_indices = tf.to_int32(tf.equal(tf.zeros([1, beam_length], dtype=tf.int32), y_diff))\n",
    "#y_indices_reduce_sum = tf.reduce_sum(y_indices, axis=1)\n",
    "#y_args = tf.where(tf.equal(2, y_indices_reduce_sum))\n",
    "\n",
    "#y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "\n",
    "#y_last_token = y_diff_gather[:,0][:,time]\n",
    "\n",
    "#y_last_token_unique = tf.unique_with_counts(y_last_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tf.Variable(tf.zeros([len(vocab_dict)], dtype=tf.int32))\n",
    "\n",
    "vocab_with_log_probs = tf.scatter_add(vocab, y_last_token_unique.y, y_last_token_unique.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_segments_unique = tf.unique_with_counts(y_segments)\n",
    "\n",
    "#y_segments_unique_args = tf.where(tf.equal(2, y_segments_unique.count))\n",
    "\n",
    "#y_2_slice_y = tf.gather(n_grams_tf, tf.gather(y_segments_unique.y, y_segments_unique_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[3][3380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180261, 3), (732, 1), (180261,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[1].shape, q[0].shape, q[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply = tf.constant([1, n_grams_tf.shape[0].value])\n",
    "\n",
    "beam_pad_matrix = tf.tile(beam_pad, multiply)\n",
    "\n",
    "beam_pad_matrix_reshape = tf.reshape(beam_pad_matrix, \\\n",
    "                                     [beam_length, n_grams_tf.shape[0].value, beam_length])\n",
    "\n",
    "multiply = tf.constant([beam.shape[0].value, 1])\n",
    "\n",
    "matrix = tf.tile(n_grams_tf, multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_reshape = tf.reshape(matrix, [beam_length, n_grams_tf.shape[0].value, beam_length])\n",
    "\n",
    "y_matrix_reshape = tf.subtract(matrix_reshape, beam_pad_matrix_reshape)\n",
    "\n",
    "y_indices = tf.to_int32(tf.equal(tf.zeros([1, beam_length], dtype=tf.int32), y_matrix_reshape))\n",
    "\n",
    "#y_indices_reduce_sum = tf.reduce_sum(y_indices, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(180261)])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_indices_reduce_sum.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-b3aecea9a17a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmask_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_reshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_matrix_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mvocab_count_template\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "mask_test = tf.boolean_mask(matrix_reshape, tf.equal(tf.zeros([1, beam_length], dtype=tf.int32), y_matrix_reshape))\n",
    "\n",
    "vocab_count_template = tf.Variable(tf.zeros([3, vocab_size], dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, array([[ 1.,  1.],\n",
       "        [ 1.,  1.],\n",
       "        [ 1.,  1.],\n",
       "        [ 1.,  1.]], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwww = tf.as_string(www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = tf.unique_with_counts(www)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "www =tf.gather_nd(matrix_reshape, y_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.map_fn(lambda x: x, wwww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6178,  5729, 15173],\n",
       "       [ 6178,  5729, 15259],\n",
       "       [ 6178,  5729, 11599],\n",
       "       ..., \n",
       "       [ 8847, 16625, 15228],\n",
       "       [ 8847, 16625, 12377],\n",
       "       [12377,  6605, 14362]])"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 2, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]])"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6178,  5729, 15173],\n",
       "        [ 5729, 15173,  4193],\n",
       "        [15173,  4193,  1001],\n",
       "        ..., \n",
       "        [ 8847, 16625, 12377],\n",
       "        [16625, 12377,  6605],\n",
       "        [12377,  6605, 14362]],\n",
       "\n",
       "       [[ 6178,  5729, 15173],\n",
       "        [ 5729, 15173,  4193],\n",
       "        [15173,  4193,  1001],\n",
       "        ..., \n",
       "        [ 8847, 16625, 12377],\n",
       "        [16625, 12377,  6605],\n",
       "        [12377,  6605, 14362]],\n",
       "\n",
       "       [[ 6178,  5729, 15173],\n",
       "        [ 5729, 15173,  4193],\n",
       "        [15173,  4193,  1001],\n",
       "        ..., \n",
       "        [ 8847, 16625, 12377],\n",
       "        [16625, 12377,  6605],\n",
       "        [12377,  6605, 14362]]])"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_pad = tf.Variable(tf.zeros([time+1], dtype=tf.int32))\n",
    "#beam_zero_pad = tf.scatter_add(zero_pad, [i for i in range(time)], test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.where(tf.equal([0], n_grams_tf - vocab_with_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_segments = y[:,0]\n",
    "y_data = y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_segments_unique = tf.unique_with_counts(y_segments)\n",
    "\n",
    "y_segments_unique_args = tf.where(tf.equal(2, y_segments_unique.count))\n",
    "\n",
    "y_2_slice_y = tf.gather(n_grams_tf, tf.gather(y_segments_unique.y, y_segments_unique_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_last_seq_unique = tf.unique_with_counts(y_2_slice_y[:,0][:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_last_seq_prob = y_last_seq_unique.count/tf.shape(y_2_slice_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tf.Variable(tf.zeros([vocab_size], dtype=tf.int32))\n",
    "\n",
    "vocab_with_log_probs = tf.log(tf.scatter_add(vocab, y_last_seq_unique.y, y_last_seq_unique.count)/tf.shape(y_2_slice_y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    q = sess.run([y, y_segments_unique, y_segments_unique_args, y_2_slice_y, y_last_seq_unique, vocab_with_log_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.4526457875697787"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[5][3380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2_slice_y = tf.gather(y, y_2[:,0])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2_slice_y_slice_n_grams_tf = tf.gather(n_grams_tf, y_2_slice_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2_slice_y_slice_n_grams_tf_unique = tf.unique_with_counts(y_2_slice_y_slice_n_grams_tf[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_norm = y_2_slice_y_slice_n_grams_tf_unique.count/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tf.Variable(tf.zeros([vocab_size], dtype=tf.int32))\n",
    "\n",
    "vocab_with_probs = tf.scatter_add(vocab, y_2_slice_y_slice_n_grams_tf_unique.y, y_2_slice_y_slice_n_grams_tf_unique.count)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    t = sess.run([vocab_with_probs, vocab])\n",
    "    #q = sess.run(yy_string)\n",
    "    q = sess.run([y_2_slice_y_slice_n_grams_tf, y_2, y, n_grams_tf, test[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6178,  5729, 15173],\n",
       "        [ 6178,  5729, 15259],\n",
       "        [ 6178,  5729, 11599],\n",
       "        ..., \n",
       "        [ 6178,  5729, 17199],\n",
       "        [ 7338,  5729,  6957],\n",
       "        [ 6178,  5729, 17199]]), array([[   1,    1],\n",
       "        [  22,    1],\n",
       "        [  24,    1],\n",
       "        ..., \n",
       "        [5602,    1],\n",
       "        [5604,    1],\n",
       "        [5623,    1]], dtype=int64), array([[     0,      0],\n",
       "        [     0,      1],\n",
       "        [     9,      0],\n",
       "        ..., \n",
       "        [180183,      0],\n",
       "        [180183,      1],\n",
       "        [180233,      0]], dtype=int64), array([[ 6178,  5729, 15173],\n",
       "        [ 5729, 15173,  4193],\n",
       "        [15173,  4193,  1001],\n",
       "        ..., \n",
       "        [ 8847, 16625, 12377],\n",
       "        [16625, 12377,  6605],\n",
       "        [12377,  6605, 14362]]), array([6178, 5729])]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6178,  5729, 15173],\n",
       "       [ 5729, 15173,  4193],\n",
       "       [15173,  4193,  1001],\n",
       "       ..., \n",
       "       [ 8847, 16625, 12377],\n",
       "       [16625, 12377,  6605],\n",
       "       [12377,  6605, 14362]])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
