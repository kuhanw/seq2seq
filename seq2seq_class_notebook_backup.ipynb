{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import create_model\n",
    "import pickle\n",
    "import random\n",
    "import data_formatting\n",
    "\n",
    "def encodeSent(sent):\n",
    "\n",
    "    if type(sent) == str: sent = sent.split(' ')\n",
    "    \n",
    "    return [vocab_dict[word] if word in vocab_dict else 2 for word in sent]\n",
    "\n",
    "def decodeSent(sent):\n",
    "    return [inv_map[i] for i in sent]\n",
    "\n",
    "def validate(op, feed_dict):\n",
    "\n",
    "    for i, (e_in, dt_targ, dt_pred) in enumerate(zip(feed_dict['encoder_inputs:0'], \n",
    "                                                 feed_dict['decoder_targets:0'], \n",
    "                                                 session.run(op, feed_dict))):\n",
    "\n",
    "        print('  sample {}:'.format(i + 1))\n",
    "        #print('    enc input           > {}'.format(e_in))\n",
    "        print('    enc input           > {}'.format(' '.join([inv_map[i] for i in e_in if i!=0])))\n",
    "\n",
    "        #print('    dec input           > {}'.format(dt_targ))\n",
    "        print('    dec input           > {}'.format(' '.join([inv_map[i] for i in dt_targ if i!=0])))\n",
    "\n",
    "        #print('    dec train predicted > {}'.format(dt_pred))\n",
    "        print('    dec train predicted > {}'.format(' '.join([inv_map[i] for i in dt_pred if i!=0])))\n",
    "\n",
    "        if i >= 0: break\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_4_15_sample_134241_full.pkl', 'rb'))\n",
    "inv_map = {v: k for k, v in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'twitter'\n",
    "\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_4_15_sample_134241_full.pkl')\n",
    "\n",
    "#df_all['alpha_Pair_1_encoding'] =  df_all['alpha_Pair_1_tokens'].apply(encodeSent)\n",
    "#df_all['alpha_Pair_0_encoding'] = df_all['alpha_Pair_0_tokens'].apply(encodeSent)\n",
    "\n",
    "#df_all['Index'] = df_all.index.values\n",
    "\n",
    "#df_all_train = df_all.sample(frac=0.90, random_state=0)\n",
    "\n",
    "#df_all_dev = df_all[df_all['Index'].isin(df_all_train['Index'].values) == False]\n",
    "\n",
    "#df_all_test = df_all_dev.sample(frac=0.10, random_state=0)\n",
    "\n",
    "#df_all_dev = df_all_dev[df_all_dev['Index'].isin(df_all_test['Index'].values) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_train[['alpha_Pair_0_encoding', 'alpha_Pair_1_encoding']].to_pickle('../processed_data/queue_testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_cells':128, 'num_layers':2, 'embedding_size':1024, \n",
    "          'vocab_size':len(vocab_dict) + 1, 'minibatch_size':8,\n",
    "         # 'vocab_size':20 + 1,           \n",
    "          'beam_width':10, 'encoder_output_keep':0.95, 'decoder_output_keep':0.95, 'seq_low':4, 'seq_high':15\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = { 'vocab_lower':3, 'vocab_upper':model_params['vocab_size']-1, \n",
    "                    'n_epochs':1000, 'batches_in_epoch':1000}\n",
    "                   #'batches_in_epoch':int(df_all_train.shape[0]/model_params['minibatch_size'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_model = create_model.Model(model_params, 'train')\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.01\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, \\\n",
    "                                   training_params['n_epochs']*training_params['batches_in_epoch'], 0.0001, staircase=False)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(train_model.loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=train_model.decoder_train_targets,\n",
    "    logits=train_model.decoder_outputs_train.rnn_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(train_model.decoder_train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.pad_size = self.decoder_train_length - tf.shape(self.decoder_outputs_train.rnn_output)[1]\n",
    "        \n",
    "        #self.decoder_outputs_train_logit = tf.pad(self.decoder_outputs_train.rnn_output, [[0, 0], [0,  self.pad_size], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(train_model.pad_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "10.1939\n",
      "i: 100\n",
      "6.20184\n",
      "i: 200\n",
      "5.53671\n",
      "i: 300\n",
      "5.32172\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "   \n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for i in range(100000):\n",
    "        \n",
    "        session.run(train_op)\n",
    "        if i%100 == 0: \n",
    "            print ('i:', i)\n",
    "            print(session.run(train_model.loss))\n",
    "\n",
    "          #  saver.save(session, 'chkpt/seq2seq_twitter_test_queue', global_step = tf.train.global_step(session, global_step))\n",
    "\n",
    "           # print ('Session saved')\n",
    "        \n",
    "    coord.request_stop()\n",
    "    # ... and we wait for them to do so before releasing the main thread\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_train = pd.read_pickle('../processed_data/queue_testing.pkl')\n",
    "df_all_train = df_all_train[:5000]\n",
    "training_data = data_formatting.prepare_train_batch(df_all_train['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_train['alpha_Pair_1_encoding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23459, 22583,  7202,  6787, 24568, 24207,     1,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [26857,  5534,  2197,  1308, 25137, 12609, 24336,  8621, 13584,\n",
       "        19775,     1,     0,     0,     0,     0],\n",
       "       [13250, 26711,  3900, 14422,  9175,   562, 22595, 17636,     1,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [   21,  8333, 10409,  8587, 19570, 12684,     1,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [24413,  6918,  3836, 20716,  2762, 24336,  1068, 10675, 12983,\n",
       "         7616,  6618,     1,     0,     0,     0],\n",
       "       [  426, 11240,   233, 12609,  4512, 10600, 17237, 13374,     1,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [26331, 11417, 23426, 25276, 14982, 25934, 13694,  6093,  3060,\n",
       "            1,     0,     0,     0,     0,     0],\n",
       "       [23968, 19039, 16994, 10675, 13291, 24336, 14675, 19039,  1350,\n",
       "        13178, 21875,     1,     0,     0,     0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[2][16:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 16), (8, 13, 27132), (8, 16, 27132))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1[0].shape, results_1[1].shape, results_1[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_2:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(tf.pad(results_1[1], [[0, 0], [0, 5], [0, 0]], \"CONSTANT\"))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01233576, -0.00258708, -0.01116863, ..., -0.00037263,\n",
       "       -0.00256451, -0.00534932], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_1[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoder_outputs_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_parameters = np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding_matrix:0' shape=(27132, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'memory_layer/kernel:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(1152, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_1/Attention_Wrapper/lstm_cell/kernel:0' shape=(384, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_1/Attention_Wrapper/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_1/Attention_Wrapper/bahdanau_attention/query_layer/kernel:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_1/Attention_Wrapper/bahdanau_attention/attention_v:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/multi_rnn_cell/cell_1/Attention_Wrapper/attention_layer/kernel:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/output_projection/kernel:0' shape=(128, 27132) dtype=float32_ref>,\n",
       " <tf.Variable 'decoder/output_projection/bias:0' shape=(27132,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11234428"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0086031082312334906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_train.shape[0]/trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:0, global_step:755, learning rate:0.00991\n",
      "training minibatch loss:5.21919\n",
      "  sample 1:\n",
      "    enc input           > who would ve known life work in crazy way <EOS>\n",
      "    dec input           > omg what a throwback to think our daughter were born on the same day <EOS>\n",
      "    dec train predicted > i i s a to the <EOS> first <EOS> in to the debate <EOS> <EOS>\n",
      "dev minibatch loss:4.92515\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:1, global_step:1510, learning rate:0.00982\n",
      "training minibatch loss:4.93339\n",
      "  sample 1:\n",
      "    enc input           > that s why my mom doe it for me <EOS>\n",
      "    dec input           > i hate food shopping because it s always so expensive <EOS>\n",
      "    dec train predicted > i m the <EOS> <EOS> i s a <EOS> cute <EOS>\n",
      "dev minibatch loss:4.96667\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:2, global_step:2265, learning rate:0.00973\n",
      "training minibatch loss:4.67621\n",
      "  sample 1:\n",
      "    enc input           > true and it make you stronger <EOS>\n",
      "    dec input           > it brings better thing into your life <EOS>\n",
      "    dec train predicted > i s to to <EOS> the own <EOS>\n",
      "dev minibatch loss:4.88111\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:3, global_step:3020, learning rate:0.00964\n",
      "training minibatch loss:4.68164\n",
      "  sample 1:\n",
      "    enc input           > share pc dispenser bathroom set <EOS>\n",
      "    dec input           > this candle light bubba bath n this blunt finna send me to jesus himself <EOS>\n",
      "    dec train predicted > i is is <EOS> <EOS> <EOS> <EOS> is <EOS> be me <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.0314\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:4, global_step:3775, learning rate:0.00955\n",
      "training minibatch loss:4.50783\n",
      "  sample 1:\n",
      "    enc input           > my real parent brought me <EOS>\n",
      "    dec input           > this wa indirectly tweeted at u be my sugar daddy <EOS>\n",
      "    dec train predicted > i is a <EOS> you the <EOS> a best <EOS> <EOS>\n",
      "dev minibatch loss:4.99435\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:5, global_step:4530, learning rate:0.00946\n",
      "training minibatch loss:4.55685\n",
      "  sample 1:\n",
      "    enc input           > that nail color is lovely on you <EOS>\n",
      "    dec input           > the one i have been waiting for <EOS>\n",
      "    dec train predicted > i best is m a a for the\n",
      "dev minibatch loss:5.11215\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:6, global_step:5285, learning rate:0.00938\n",
      "training minibatch loss:4.48382\n",
      "  sample 1:\n",
      "    enc input           > could make them into christmas ornament <EOS>\n",
      "    dec input           > these are so cool <EOS>\n",
      "    dec train predicted > i are the good <EOS>\n",
      "dev minibatch loss:4.98674\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:7, global_step:6040, learning rate:0.00929\n",
      "training minibatch loss:4.4564\n",
      "  sample 1:\n",
      "    enc input           > oops didn t phrase that right better to be in ny than sf p <EOS>\n",
      "    dec input           > sf traffic is nothing compared to this p <EOS>\n",
      "    dec train predicted > i is is a to to the <EOS> <EOS>\n",
      "dev minibatch loss:5.00562\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:8, global_step:6795, learning rate:0.0092\n",
      "training minibatch loss:4.52054\n",
      "  sample 1:\n",
      "    enc input           > luckily it s plastic and not one of the old school metal one <EOS>\n",
      "    dec input           > i hope she s okay that trash can look huge <EOS>\n",
      "    dec train predicted > i m it wa a <EOS> s <EOS> t <EOS> <EOS>\n",
      "dev minibatch loss:4.99637\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:9, global_step:7550, learning rate:0.00912\n",
      "training minibatch loss:4.31769\n",
      "  sample 1:\n",
      "    enc input           > dude that s my pal <EOS>\n",
      "    dec input           > there is a spider on your kleenex <EOS>\n",
      "    dec train predicted > i s a good <EOS> the phone <EOS>\n",
      "dev minibatch loss:5.24446\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:10, global_step:8305, learning rate:0.00904\n",
      "training minibatch loss:4.45765\n",
      "  sample 1:\n",
      "    enc input           > i really want to see everything you cooked up <EOS>\n",
      "    dec input           > may the demo god look kindly on me this week <EOS>\n",
      "    dec train predicted > i i first ? i like <EOS> the <EOS> time <EOS>\n",
      "dev minibatch loss:4.95322\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:11, global_step:9060, learning rate:0.00895\n",
      "training minibatch loss:4.1651\n",
      "  sample 1:\n",
      "    enc input           > that d be awesome <EOS>\n",
      "    dec input           > i ll record it for you if you like <EOS>\n",
      "    dec train predicted > i m be a <EOS> the <EOS> you re a\n",
      "dev minibatch loss:5.28996\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:12, global_step:9815, learning rate:0.00887\n",
      "training minibatch loss:4.38326\n",
      "  sample 1:\n",
      "    enc input           > yall boutta get this work <EOS>\n",
      "    dec input           > should be a good <EOS>\n",
      "    dec train predicted > i i a collaborative thing\n",
      "dev minibatch loss:5.2164\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:13, global_step:10570, learning rate:0.00879\n",
      "training minibatch loss:4.23785\n",
      "  sample 1:\n",
      "    enc input           > for a song about kidnapping and murder it s very upbeat <EOS>\n",
      "    dec input           > this song is dope <EOS>\n",
      "    dec train predicted > i is is <EOS> <EOS>\n",
      "dev minibatch loss:5.3299\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:14, global_step:11325, learning rate:0.00871\n",
      "training minibatch loss:4.2211\n",
      "  sample 1:\n",
      "    enc input           > i just love when he go off without a snare sorry ? <EOS>\n",
      "    dec input           > oh i fuck with danny brown so count this black person in <EOS>\n",
      "    dec train predicted > i my m you the jackson wa much <EOS> is <EOS> <EOS> the\n",
      "dev minibatch loss:5.13662\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:15, global_step:12080, learning rate:0.00863\n",
      "training minibatch loss:4.21371\n",
      "  sample 1:\n",
      "    enc input           > if she is not for trump she is then she is good for america <EOS>\n",
      "    dec input           > huffington post not good for america <EOS>\n",
      "    dec train predicted > hillary she is a <EOS> hillary <EOS>\n",
      "dev minibatch loss:5.27148\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:16, global_step:12835, learning rate:0.00855\n",
      "training minibatch loss:4.08476\n",
      "  sample 1:\n",
      "    enc input           > yeh sure did <EOS>\n",
      "    dec input           > did you draw this ? ? <EOS>\n",
      "    dec train predicted > i you have this ? <EOS> ?\n",
      "dev minibatch loss:4.99327\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:17, global_step:13590, learning rate:0.00847\n",
      "training minibatch loss:4.24415\n",
      "  sample 1:\n",
      "    enc input           > going to the alley with meli <EOS>\n",
      "    dec input           > come over eat dinner lol <EOS>\n",
      "    dec train predicted > i on to the <EOS> <EOS>\n",
      "dev minibatch loss:5.02903\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:18, global_step:14345, learning rate:0.00839\n",
      "training minibatch loss:4.05716\n",
      "  sample 1:\n",
      "    enc input           > it s on my rib lol it say eternally young <EOS>\n",
      "    dec input           > what is the tattoo on your stomach ? <EOS>\n",
      "    dec train predicted > i do this first ? the phone ? <EOS>\n",
      "dev minibatch loss:5.49722\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:19, global_step:15100, learning rate:0.00832\n",
      "training minibatch loss:4.19473\n",
      "  sample 1:\n",
      "    enc input           > i m devastated truly thx for the memory burlington center lmao <EOS>\n",
      "    dec input           > gurl i walked by to get my eyebrow threaded that thang wa empty af <EOS>\n",
      "    dec train predicted > i i m in <EOS> <EOS> the pair <EOS> <EOS> s <EOS> a <EOS> <EOS>\n",
      "dev minibatch loss:5.29233\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:20, global_step:15855, learning rate:0.00824\n",
      "training minibatch loss:4.13809\n",
      "  sample 1:\n",
      "    enc input           > nah cry on the train <EOS>\n",
      "    dec input           > so i shouldn t listen to this at work ? <EOS>\n",
      "    dec train predicted > i i m t know to the <EOS> the <EOS> <EOS>\n",
      "dev minibatch loss:5.26274\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:21, global_step:16610, learning rate:0.00817\n",
      "training minibatch loss:4.17723\n",
      "  sample 1:\n",
      "    enc input           > i know i looked back at the picture and it wa changed <EOS>\n",
      "    dec input           > i cant pick out an avi so i keep switching it <EOS>\n",
      "    dec train predicted > i m imagine it the unbiased <EOS> i m up <EOS> <EOS>\n",
      "dev minibatch loss:5.2791\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:22, global_step:17365, learning rate:0.00809\n",
      "training minibatch loss:4.06984\n",
      "  sample 1:\n",
      "    enc input           > yes it is <EOS>\n",
      "    dec input           > is this happening in the u at the moment ? <EOS>\n",
      "    dec train predicted > i it a ? the dark ? rbc fri ? <EOS>\n",
      "dev minibatch loss:5.01254\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:23, global_step:18120, learning rate:0.00802\n",
      "training minibatch loss:4.13489\n",
      "  sample 1:\n",
      "    enc input           > doe trump need to blow his nose <EOS>\n",
      "    dec input           > she threw first punch <EOS>\n",
      "    dec train predicted > i s a to to\n",
      "dev minibatch loss:5.11523\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:24, global_step:18875, learning rate:0.00794\n",
      "training minibatch loss:4.1465\n",
      "  sample 1:\n",
      "    enc input           > did you enjoy it though <EOS>\n",
      "    dec input           > im so sad it over i never wanted it to end <EOS>\n",
      "    dec train predicted > i so excited <EOS> s <EOS> m want to <EOS> you <EOS>\n",
      "dev minibatch loss:5.38686\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:25, global_step:19630, learning rate:0.00787\n",
      "training minibatch loss:4.09137\n",
      "  sample 1:\n",
      "    enc input           > section row seat <EOS>\n",
      "    dec input           > went deep now to enter to win a <EOS>\n",
      "    dec train predicted > went deep captain for enter to win a chance\n",
      "dev minibatch loss:5.62783\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:26, global_step:20385, learning rate:0.0078\n",
      "training minibatch loss:3.95225\n",
      "  sample 1:\n",
      "    enc input           > people harbor all kind of illusion let me tell you <EOS>\n",
      "    dec input           > i don t get how people don t see that coming <EOS>\n",
      "    dec train predicted > i m t recall it to are t know you <EOS> <EOS>\n",
      "dev minibatch loss:5.23303\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:27, global_step:21140, learning rate:0.00773\n",
      "training minibatch loss:4.03911\n",
      "  sample 1:\n",
      "    enc input           > i might too <EOS>\n",
      "    dec input           > guess i m going to see tomorrow <EOS>\n",
      "    dec train predicted > i i m not to the you <EOS>\n",
      "dev minibatch loss:5.1979\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:28, global_step:21895, learning rate:0.00766\n",
      "training minibatch loss:3.95397\n",
      "  sample 1:\n",
      "    enc input           > im not sorry <EOS>\n",
      "    dec input           > this hurt my soul d <EOS>\n",
      "    dec train predicted > i is i name <EOS> <EOS>\n",
      "dev minibatch loss:5.60263\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:29, global_step:22650, learning rate:0.00759\n",
      "training minibatch loss:3.86102\n",
      "  sample 1:\n",
      "    enc input           > i know hopefully yeldon and murray get the job done <EOS>\n",
      "    dec input           > you benched crowell <EOS>\n",
      "    dec train predicted > i re carr <EOS>\n",
      "dev minibatch loss:5.36413\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:30, global_step:23405, learning rate:0.00752\n",
      "training minibatch loss:3.86503\n",
      "  sample 1:\n",
      "    enc input           > i can t too much hw <EOS>\n",
      "    dec input           > go to the tailgate <EOS>\n",
      "    dec train predicted > i to the bathroom <EOS>\n",
      "dev minibatch loss:5.479\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:31, global_step:24160, learning rate:0.00745\n",
      "training minibatch loss:3.85752\n",
      "  sample 1:\n",
      "    enc input           > brand new tune <EOS>\n",
      "    dec input           > w fm benin all in my head flex x <EOS>\n",
      "    dec train predicted > funx fm benin all <EOS> fast life <EOS> x <EOS>\n",
      "dev minibatch loss:5.33352\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:32, global_step:24915, learning rate:0.00738\n",
      "training minibatch loss:3.89527\n",
      "  sample 1:\n",
      "    enc input           > now that you mention it none of that make goddamn sense <EOS>\n",
      "    dec input           > that s logistically impossible <EOS>\n",
      "    dec train predicted > i s the <EOS> to\n",
      "dev minibatch loss:5.32555\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:33, global_step:25670, learning rate:0.00731\n",
      "training minibatch loss:4.00981\n",
      "  sample 1:\n",
      "    enc input           > i really wasn t trying to reach lol but got you <EOS>\n",
      "    dec input           > lol you reaching he said music wise he s trynna top that <EOS>\n",
      "    dec train predicted > i i s out s <EOS> <EOS> <EOS> s a be <EOS> <EOS>\n",
      "dev minibatch loss:5.7978\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:34, global_step:26425, learning rate:0.00724\n",
      "training minibatch loss:3.93653\n",
      "  sample 1:\n",
      "    enc input           > you been on point with this <EOS>\n",
      "    dec input           > freshly waxed buttholes <EOS>\n",
      "    dec train predicted > i is with on\n",
      "dev minibatch loss:5.69696\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:35, global_step:27180, learning rate:0.00718\n",
      "training minibatch loss:3.84858\n",
      "  sample 1:\n",
      "    enc input           > i play for keep bud <EOS>\n",
      "    dec input           > aw man why you harsh my mellow like that ? <EOS>\n",
      "    dec train predicted > i i i i re it as <EOS> a <EOS> <EOS>\n",
      "dev minibatch loss:5.3124\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:36, global_step:27935, learning rate:0.00711\n",
      "training minibatch loss:3.97028\n",
      "  sample 1:\n",
      "    enc input           > robin dont listen to this bozo <EOS>\n",
      "    dec input           > reading is fundamental clearly you didn t bother to read the story <EOS>\n",
      "    dec train predicted > i the the <EOS> not re t know me be <EOS> same <EOS>\n",
      "dev minibatch loss:5.28664\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:37, global_step:28690, learning rate:0.00705\n",
      "training minibatch loss:4.00904\n",
      "  sample 1:\n",
      "    enc input           > schedule look great trip away <EOS>\n",
      "    dec input           > headed to with <EOS>\n",
      "    dec train predicted > i to greece the\n",
      "dev minibatch loss:5.52784\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:38, global_step:29445, learning rate:0.00698\n",
      "training minibatch loss:4.07199\n",
      "  sample 1:\n",
      "    enc input           > well i work in the laundry so it s not a bad <EOS>\n",
      "    dec input           > damn that s hard work good luck <EOS>\n",
      "    dec train predicted > i i s why to <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.34705\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:39, global_step:30200, learning rate:0.00692\n",
      "training minibatch loss:3.93032\n",
      "  sample 1:\n",
      "    enc input           > tl dr von drake control them all <EOS>\n",
      "    dec input           > the fact that you have theory about blow my mind but go on <EOS>\n",
      "    dec train predicted > i first who s can a of the <EOS> knee <EOS> the <EOS> <EOS>\n",
      "dev minibatch loss:5.67343\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:40, global_step:30955, learning rate:0.00685\n",
      "training minibatch loss:4.00141\n",
      "  sample 1:\n",
      "    enc input           > you always kill the vibe <EOS>\n",
      "    dec input           > it ight my vibe wa ruined i muted everyone <EOS>\n",
      "    dec train predicted > i s pronounced as <EOS> a the love <EOS> <EOS>\n",
      "dev minibatch loss:5.44908\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:41, global_step:31710, learning rate:0.00679\n",
      "training minibatch loss:3.87398\n",
      "  sample 1:\n",
      "    enc input           > have submitted it no hope rel is our soon <EOS>\n",
      "    dec input           > right after it happens thanks <EOS>\n",
      "    dec train predicted > i now the <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.29895\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:42, global_step:32465, learning rate:0.00673\n",
      "training minibatch loss:3.91495\n",
      "  sample 1:\n",
      "    enc input           > oh the humanity dear god make it stop <EOS>\n",
      "    dec input           > unbelievably can t find anyone in sfo terminal selling gourmet cold pressed juice smh <EOS>\n",
      "    dec train predicted > i good i be duda else the <EOS> <EOS> the <EOS> gum <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.32891\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:43, global_step:33220, learning rate:0.00667\n",
      "training minibatch loss:3.93833\n",
      "  sample 1:\n",
      "    enc input           > like all the time i think of punching you while you sleep <EOS>\n",
      "    dec input           > i can see how someone might succumb to the darkest corner of their mind <EOS>\n",
      "    dec train predicted > i m t whether to is be the the same <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.33134\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:44, global_step:33975, learning rate:0.00661\n",
      "training minibatch loss:3.92065\n",
      "  sample 1:\n",
      "    enc input           > the great depression <EOS>\n",
      "    dec input           > until nigga got to college smh <EOS>\n",
      "    dec train predicted > i s i the be <EOS> <EOS>\n",
      "dev minibatch loss:5.88289\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:45, global_step:34730, learning rate:0.00655\n",
      "training minibatch loss:3.92667\n",
      "  sample 1:\n",
      "    enc input           > idk who i want to win i like both of them <EOS>\n",
      "    dec input           > about f n time <EOS>\n",
      "    dec train predicted > i to you i <EOS>\n",
      "dev minibatch loss:5.78448\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:46, global_step:35485, learning rate:0.00649\n",
      "training minibatch loss:3.99848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample 1:\n",
      "    enc input           > oh my god i bet they made bracelet out of dental floss <EOS>\n",
      "    dec input           > stahp i bet they made matching friendship lanyard <EOS>\n",
      "    dec train predicted > i s m i are me <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.58421\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:47, global_step:36240, learning rate:0.00643\n",
      "training minibatch loss:3.9788\n",
      "  sample 1:\n",
      "    enc input           > i should be so lucky thats a winning personality right there <EOS>\n",
      "    dec input           > careful and they are watching <EOS>\n",
      "    dec train predicted > i i i re going the\n",
      "dev minibatch loss:5.11879\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:48, global_step:36995, learning rate:0.00637\n",
      "training minibatch loss:3.84454\n",
      "  sample 1:\n",
      "    enc input           > this is such a weird show love it <EOS>\n",
      "    dec input           > and now for some to hopefully take my mind off it <EOS>\n",
      "    dec train predicted > i i this the dedicated the this <EOS> vest <EOS> <EOS> s\n",
      "dev minibatch loss:5.77557\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:49, global_step:37750, learning rate:0.00631\n",
      "training minibatch loss:3.92539\n",
      "  sample 1:\n",
      "    enc input           > just need a person with patience guide em <EOS>\n",
      "    dec input           > one boy s mum died and the other adhd nice kid <EOS>\n",
      "    dec train predicted > i of are the education <EOS> i <EOS> people <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.74227\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:50, global_step:38505, learning rate:0.00625\n",
      "training minibatch loss:3.81655\n",
      "  sample 1:\n",
      "    enc input           > islam allows child marriage you support it nice try pedo <EOS>\n",
      "    dec input           > yup keep making thing up a you go <EOS>\n",
      "    dec train predicted > plc plc plc feedback <EOS> plc plc are to\n",
      "dev minibatch loss:5.47729\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:51, global_step:39260, learning rate:0.00619\n",
      "training minibatch loss:3.78503\n",
      "  sample 1:\n",
      "    enc input           > what jason said tbh <EOS>\n",
      "    dec input           > rationality is flower upside down like a dumbass <EOS>\n",
      "    dec train predicted > i to a af a <EOS> a lot <EOS>\n",
      "dev minibatch loss:5.65391\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:52, global_step:40015, learning rate:0.00614\n",
      "training minibatch loss:3.87256\n",
      "  sample 1:\n",
      "    enc input           > welp you can t blame terrelle pryor for the brown loss <EOS>\n",
      "    dec input           > welp you can t blame terrelle pryor for the brown loss <EOS>\n",
      "    dec train predicted > i i can t get god smith <EOS> a devil <EOS> <EOS>\n",
      "dev minibatch loss:5.55211\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:53, global_step:40770, learning rate:0.00608\n",
      "training minibatch loss:3.83907\n",
      "  sample 1:\n",
      "    enc input           > have submitted it no hope rel is our soon <EOS>\n",
      "    dec input           > right after it happens thanks <EOS>\n",
      "    dec train predicted > i of the <EOS> <EOS> for\n",
      "dev minibatch loss:5.44913\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:54, global_step:41525, learning rate:0.00603\n",
      "training minibatch loss:3.91843\n",
      "  sample 1:\n",
      "    enc input           > other desk ? <EOS>\n",
      "    dec input           > what the hell ? <EOS>\n",
      "    dec train predicted > i s fuck is <EOS>\n",
      "dev minibatch loss:5.69012\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:55, global_step:42280, learning rate:0.00597\n",
      "training minibatch loss:3.93942\n",
      "  sample 1:\n",
      "    enc input           > omg thank you they didnt turn out bad im so happy <EOS>\n",
      "    dec input           > the purple look exquisite on you <EOS>\n",
      "    dec train predicted > i one birthday at <EOS> the <EOS>\n",
      "dev minibatch loss:5.39156\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:56, global_step:43035, learning rate:0.00592\n",
      "training minibatch loss:3.78998\n",
      "  sample 1:\n",
      "    enc input           > yaaaas adding to the list too <EOS>\n",
      "    dec input           > how could we forget to add this to the list to binge watch <EOS>\n",
      "    dec train predicted > daaamn do i get the spend the interactive the oven ? the ? <EOS>\n",
      "dev minibatch loss:5.86745\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:57, global_step:43790, learning rate:0.00586\n",
      "training minibatch loss:3.88338\n",
      "  sample 1:\n",
      "    enc input           > which one is your mom fam <EOS>\n",
      "    dec input           > my beautiful mom and sister <EOS>\n",
      "    dec train predicted > i boob girlfriend <EOS> i <EOS>\n",
      "dev minibatch loss:5.56454\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:58, global_step:44545, learning rate:0.00581\n",
      "training minibatch loss:3.78687\n",
      "  sample 1:\n",
      "    enc input           > i just love the name salem <EOS>\n",
      "    dec input           > if i have a girl someday i wan na name her salem <EOS>\n",
      "    dec train predicted > geek you love a vision <EOS> <EOS> love na be <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.76061\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:59, global_step:45300, learning rate:0.00575\n",
      "training minibatch loss:3.87901\n",
      "  sample 1:\n",
      "    enc input           > wait why ? what time you getting on ? <EOS>\n",
      "    dec input           > damn i m going to probably miss you then <EOS>\n",
      "    dec train predicted > i i m not to be <EOS> you <EOS> <EOS>\n",
      "dev minibatch loss:5.53041\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:60, global_step:46055, learning rate:0.0057\n",
      "training minibatch loss:4.01178\n",
      "  sample 1:\n",
      "    enc input           > one can only hope <EOS>\n",
      "    dec input           > yes hopefully they will turn it around <EOS>\n",
      "    dec train predicted > i i i re be up up <EOS>\n",
      "dev minibatch loss:5.36594\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:61, global_step:46810, learning rate:0.00565\n",
      "training minibatch loss:3.79144\n",
      "  sample 1:\n",
      "    enc input           > so many nfl joke can be made here <EOS>\n",
      "    dec input           > somebody punch me in the face smh <EOS>\n",
      "    dec train predicted > i s the to the world of <EOS>\n",
      "dev minibatch loss:5.97085\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:62, global_step:47565, learning rate:0.0056\n",
      "training minibatch loss:3.80204\n",
      "  sample 1:\n",
      "    enc input           > life they want to live homeless shouldn t equal death <EOS>\n",
      "    dec input           > pls share it save life <EOS>\n",
      "    dec train predicted > i to the <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.35162\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:63, global_step:48320, learning rate:0.00555\n",
      "training minibatch loss:3.91505\n",
      "  sample 1:\n",
      "    enc input           > wish i can go to this game with my son <EOS>\n",
      "    dec input           > it s game night <EOS>\n",
      "    dec train predicted > i s a of <EOS>\n",
      "dev minibatch loss:5.6651\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:64, global_step:49075, learning rate:0.0055\n",
      "training minibatch loss:3.82261\n",
      "  sample 1:\n",
      "    enc input           > cant wait til revis shuts you up <EOS>\n",
      "    dec input           > note to amp other writer revis island rebranded revis resort <EOS>\n",
      "    dec train predicted > i to be i and <EOS> shelby by <EOS> <EOS> to\n",
      "dev minibatch loss:5.49678\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:65, global_step:49830, learning rate:0.00545\n",
      "training minibatch loss:3.75487\n",
      "  sample 1:\n",
      "    enc input           > youre mine too bro <EOS>\n",
      "    dec input           > you re now my highest <EOS>\n",
      "    dec train predicted > i re not <EOS> favorite favorite\n",
      "dev minibatch loss:5.35107\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:66, global_step:50585, learning rate:0.0054\n",
      "training minibatch loss:3.83029\n",
      "  sample 1:\n",
      "    enc input           > you know it <EOS>\n",
      "    dec input           > you really every white girl ever lmao rt classy with red satin sheet <EOS>\n",
      "    dec train predicted > i re need transformer nacho <EOS> <EOS> <EOS> <EOS> <EOS> me <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:6.11483\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:67, global_step:51340, learning rate:0.00535\n",
      "training minibatch loss:3.81971\n",
      "  sample 1:\n",
      "    enc input           > dooo it you can wear them up to x <EOS>\n",
      "    dec input           > i really want the lash <EOS>\n",
      "    dec train predicted > i m enjoyed to hippie in\n",
      "dev minibatch loss:5.49589\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:68, global_step:52095, learning rate:0.0053\n",
      "training minibatch loss:3.80397\n",
      "  sample 1:\n",
      "    enc input           > she wiped the floor with you <EOS>\n",
      "    dec input           > just said a historic victory for trump nice <EOS>\n",
      "    dec train predicted > i booked the hell comment for the <EOS> <EOS>\n",
      "dev minibatch loss:5.98608\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:69, global_step:52850, learning rate:0.00525\n",
      "training minibatch loss:3.78129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample 1:\n",
      "    enc input           > deleting of thousand of email from her private server wasnt hiding evidence and the <EOS>\n",
      "    dec input           > a long a you re not a republican patriot anti hillary obama <EOS>\n",
      "    dec train predicted > i a a a <EOS> a even racist <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.49104\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:70, global_step:53605, learning rate:0.0052\n",
      "training minibatch loss:3.70549\n",
      "  sample 1:\n",
      "    enc input           > i guess my joke isnt funny anymore if it ever wa <EOS>\n",
      "    dec input           > gmail support medium query a of yesterday <EOS>\n",
      "    dec train predicted > i the the <EOS> <EOS> a course <EOS>\n",
      "dev minibatch loss:5.68992\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:71, global_step:54360, learning rate:0.00515\n",
      "training minibatch loss:3.86835\n",
      "  sample 1:\n",
      "    enc input           > cry you still at scammer bitch where my green pant ? <EOS>\n",
      "    dec input           > i wa a scammer for year but retired <EOS>\n",
      "    dec train predicted > i m in raccoon <EOS> the ago i <EOS>\n",
      "dev minibatch loss:5.50975\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:72, global_step:55115, learning rate:0.00511\n",
      "training minibatch loss:3.77015\n",
      "  sample 1:\n",
      "    enc input           > here s an article with some great suggestion <EOS>\n",
      "    dec input           > what should i plant in a garden in the fall <EOS>\n",
      "    dec train predicted > i s i do on this pdf ? chap chap ?\n",
      "dev minibatch loss:5.35057\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:73, global_step:55870, learning rate:0.00506\n",
      "training minibatch loss:3.86479\n",
      "  sample 1:\n",
      "    enc input           > i love you and yes i ll be home next weekend <EOS>\n",
      "    dec input           > omg i love you and your picture choice plz come home soon ty <EOS>\n",
      "    dec train predicted > i i love you <EOS> i friend <EOS> <EOS> <EOS> back <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.71007\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:74, global_step:56625, learning rate:0.00501\n",
      "training minibatch loss:3.93959\n",
      "  sample 1:\n",
      "    enc input           > how disgraceful amp shameful for your father too no scruple when it count <EOS>\n",
      "    dec input           > ted cruz is expected to endorse donald trump <EOS>\n",
      "    dec train predicted > i cruz say a to be to trump s\n",
      "dev minibatch loss:5.66333\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:75, global_step:57380, learning rate:0.00497\n",
      "training minibatch loss:3.73868\n",
      "  sample 1:\n",
      "    enc input           > my bad yeah just giving out consistent keep ya eye open for bag warning <EOS>\n",
      "    dec input           > are they all running normal ? <EOS>\n",
      "    dec train predicted > i you not the <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.58824\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:76, global_step:58135, learning rate:0.00492\n",
      "training minibatch loss:3.71371\n",
      "  sample 1:\n",
      "    enc input           > or they can light you up <EOS>\n",
      "    dec input           > they about to play a f with out my help <EOS>\n",
      "    dec train predicted > i re to be <EOS> long <EOS> the <EOS> bandage <EOS>\n",
      "dev minibatch loss:5.66002\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:77, global_step:58890, learning rate:0.00488\n",
      "training minibatch loss:3.73141\n",
      "  sample 1:\n",
      "    enc input           > she s unhealthy you wait and she ll end up being replaced <EOS>\n",
      "    dec input           > here s the procedure should the democratic national committee choose a replacement presidential candidate <EOS>\n",
      "    dec train predicted > hillary s how moderator cycle be herself herself hating <EOS> <EOS> biased manager nominee <EOS>\n",
      "dev minibatch loss:5.97352\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:78, global_step:59645, learning rate:0.00483\n",
      "training minibatch loss:3.84828\n",
      "  sample 1:\n",
      "    enc input           > i never want to be buff with your unfit as <EOS>\n",
      "    dec input           > oh im sorry should i say dog witcho wan na be buff as <EOS>\n",
      "    dec train predicted > i helll sorry <EOS> i be this <EOS> anger na <EOS> ashamed <EOS> <EOS>\n",
      "dev minibatch loss:5.76828\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:79, global_step:60400, learning rate:0.00479\n",
      "training minibatch loss:3.80284\n",
      "  sample 1:\n",
      "    enc input           > ii got beat check these out <EOS>\n",
      "    dec input           > im looking for free beat to kill them contact me <EOS>\n",
      "    dec train predicted > send beat at surfing beat beat beat me <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.69395\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:80, global_step:61155, learning rate:0.00474\n",
      "training minibatch loss:3.8185\n",
      "  sample 1:\n",
      "    enc input           > it the folsom street fair this weekend then lol <EOS>\n",
      "    dec input           > yup there s definitely some freaky shit going on downtown <EOS>\n",
      "    dec train predicted > i i is a a of <EOS> <EOS> to <EOS> <EOS>\n",
      "dev minibatch loss:5.50177\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:81, global_step:61910, learning rate:0.0047\n",
      "training minibatch loss:3.73314\n",
      "  sample 1:\n",
      "    enc input           > yes just show how big our family is <EOS>\n",
      "    dec input           > me too i m excited to see so many people for the first time <EOS>\n",
      "    dec train predicted > i if <EOS> m so <EOS> assume this much of else the season time <EOS>\n",
      "dev minibatch loss:5.40082\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:82, global_step:62665, learning rate:0.00466\n",
      "training minibatch loss:3.84185\n",
      "  sample 1:\n",
      "    enc input           > ip owner flag ? elaborate please ? <EOS>\n",
      "    dec input           > world s aside from ip owner flag it look okay <EOS>\n",
      "    dec train predicted > i is on to the station <EOS> undercut s like <EOS>\n",
      "dev minibatch loss:5.7868\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:83, global_step:63420, learning rate:0.00461\n",
      "training minibatch loss:3.79435\n",
      "  sample 1:\n",
      "    enc input           > good day all <EOS>\n",
      "    dec input           > you like poe huh ? <EOS>\n",
      "    dec train predicted > good re the day <EOS> <EOS>\n",
      "dev minibatch loss:5.74355\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:84, global_step:64175, learning rate:0.00457\n",
      "training minibatch loss:3.75138\n",
      "  sample 1:\n",
      "    enc input           > amazon driver you can go through to apply <EOS>\n",
      "    dec input           > what s the position called ? lol <EOS>\n",
      "    dec train predicted > i s up gender ? ? <EOS> <EOS>\n",
      "dev minibatch loss:5.8356\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:85, global_step:64930, learning rate:0.00453\n",
      "training minibatch loss:3.81555\n",
      "  sample 1:\n",
      "    enc input           > until you see the price <EOS>\n",
      "    dec input           > these are so heart eye emoji <EOS>\n",
      "    dec train predicted > i are the pretty <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.9321\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:86, global_step:65685, learning rate:0.00449\n",
      "training minibatch loss:3.61403\n",
      "  sample 1:\n",
      "    enc input           > out of the girl shes my winner <EOS>\n",
      "    dec input           > wow can t believe the winner if bb wa already announced <EOS>\n",
      "    dec train predicted > i i t ping i giant ? you ? ? ? <EOS>\n",
      "dev minibatch loss:5.86086\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:87, global_step:66440, learning rate:0.00445\n",
      "training minibatch loss:3.88483\n",
      "  sample 1:\n",
      "    enc input           > team look pathetic once again <EOS>\n",
      "    dec input           > we have reached the half <EOS>\n",
      "    dec train predicted > i re a the playoff of\n",
      "dev minibatch loss:6.06051\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:88, global_step:67195, learning rate:0.00441\n",
      "training minibatch loss:3.68341\n",
      "  sample 1:\n",
      "    enc input           > because honestly sometimes i wouldnt show up to hang out until or <EOS>\n",
      "    dec input           > idk why complains of this not like california ha shit open late either <EOS>\n",
      "    dec train predicted > why why i about you <EOS> <EOS> a <EOS> a <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:6.09587\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:89, global_step:67950, learning rate:0.00437\n",
      "training minibatch loss:3.80895\n",
      "  sample 1:\n",
      "    enc input           > saw this that one smart deer <EOS>\n",
      "    dec input           > the deer out here are getting reckless yo <EOS>\n",
      "    dec train predicted > i hubris of of <EOS> you a <EOS> <EOS>\n",
      "dev minibatch loss:5.63164\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:90, global_step:68705, learning rate:0.00433\n",
      "training minibatch loss:3.74445\n",
      "  sample 1:\n",
      "    enc input           > none better than <EOS>\n",
      "    dec input           > join me on on fri pm et with guest founder of <EOS>\n",
      "    dec train predicted > i u in the the island <EOS> <EOS> the <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.79702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:91, global_step:69460, learning rate:0.00429\n",
      "training minibatch loss:3.72008\n",
      "  sample 1:\n",
      "    enc input           > will try next time <EOS>\n",
      "    dec input           > i ve had that problem usually just killing the app store app work <EOS>\n",
      "    dec train predicted > i m been to passion <EOS> <EOS> sliding me stage <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.87981\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:92, global_step:70215, learning rate:0.00425\n",
      "training minibatch loss:3.69645\n",
      "  sample 1:\n",
      "    enc input           > good point kerry concedes <EOS>\n",
      "    dec input           > if boeing had never developed the then would not have been shot down <EOS>\n",
      "    dec train predicted > trump you with a fails a outrage <EOS> be be done involved <EOS> <EOS>\n",
      "dev minibatch loss:5.81734\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:93, global_step:70970, learning rate:0.00421\n",
      "training minibatch loss:3.6244\n",
      "  sample 1:\n",
      "    enc input           > tell that to hillary a we don t care a bit about that <EOS>\n",
      "    dec input           > continued hillary averaging in three state pres obama won <EOS>\n",
      "    dec train predicted > i to s in the of <EOS> obama clinton chop\n",
      "dev minibatch loss:5.62374\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:94, global_step:71725, learning rate:0.00417\n",
      "training minibatch loss:3.49676\n",
      "  sample 1:\n",
      "    enc input           > yes yes they are <EOS>\n",
      "    dec input           > these are our emojis <EOS>\n",
      "    dec train predicted > they are so retired <EOS>\n",
      "dev minibatch loss:5.73571\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:95, global_step:72480, learning rate:0.00413\n",
      "training minibatch loss:3.72692\n",
      "  sample 1:\n",
      "    enc input           > sometimes sleep is uncontrolled alright <EOS>\n",
      "    dec input           > babe always fall asleep on me <EOS>\n",
      "    dec train predicted > i is a asleep <EOS> the <EOS>\n",
      "dev minibatch loss:5.71154\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:96, global_step:73235, learning rate:0.00409\n",
      "training minibatch loss:3.74407\n",
      "  sample 1:\n",
      "    enc input           > bitch it wa there you tempted me smh <EOS>\n",
      "    dec input           > shut the fuck up <EOS>\n",
      "    dec train predicted > i up fuck <EOS> <EOS>\n",
      "dev minibatch loss:5.59445\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:97, global_step:73990, learning rate:0.00406\n",
      "training minibatch loss:3.8482\n",
      "  sample 1:\n",
      "    enc input           > im peeing my pant in excitement <EOS>\n",
      "    dec input           > i used to be able to do this without glass <EOS>\n",
      "    dec train predicted > i m to be in to go this <EOS> homeless <EOS>\n",
      "dev minibatch loss:5.77166\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:98, global_step:74745, learning rate:0.00402\n",
      "training minibatch loss:3.65088\n",
      "  sample 1:\n",
      "    enc input           > so did my cousin <EOS>\n",
      "    dec input           > i had a white one <EOS>\n",
      "    dec train predicted > i m a good girl <EOS>\n",
      "dev minibatch loss:5.81698\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:99, global_step:75500, learning rate:0.00398\n",
      "training minibatch loss:3.69328\n",
      "  sample 1:\n",
      "    enc input           > this is shocking where r the bernie supporter ? <EOS>\n",
      "    dec input           > bernie campaign for hillary in akron drawing massive person crowd <EOS>\n",
      "    dec train predicted > i is in the clinton the house <EOS> presidential <EOS> <EOS>\n",
      "dev minibatch loss:5.75623\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:100, global_step:76255, learning rate:0.00394\n",
      "training minibatch loss:3.75188\n",
      "  sample 1:\n",
      "    enc input           > i m screaming your cheekbone make me want to km <EOS>\n",
      "    dec input           > mirror mirror on be wall who s the baddest of them all <EOS>\n",
      "    dec train predicted > i up up the a <EOS> s a best <EOS> memorable <EOS> <EOS>\n",
      "dev minibatch loss:5.69389\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:101, global_step:77010, learning rate:0.00391\n",
      "training minibatch loss:3.80887\n",
      "  sample 1:\n",
      "    enc input           > you should it s really good it s like real life stuff haha <EOS>\n",
      "    dec input           > i saw that wa wondering if i should watch it <EOS>\n",
      "    dec train predicted > i m it <EOS> a i i m ve it <EOS>\n",
      "dev minibatch loss:5.84141\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:102, global_step:77765, learning rate:0.00387\n",
      "training minibatch loss:3.61917\n",
      "  sample 1:\n",
      "    enc input           > yeah same here my weekend is packed <EOS>\n",
      "    dec input           > jealous of anyone who actually ha time to game <EOS>\n",
      "    dec train predicted > i is course s s <EOS> to to get <EOS>\n",
      "dev minibatch loss:5.60968\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:103, global_step:78520, learning rate:0.00384\n",
      "training minibatch loss:3.61128\n",
      "  sample 1:\n",
      "    enc input           > always drink responsibly <EOS>\n",
      "    dec input           > this one for you a recommended by the <EOS>\n",
      "    dec train predicted > i is is the <EOS> little <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.6837\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:104, global_step:79275, learning rate:0.0038\n",
      "training minibatch loss:3.78853\n",
      "  sample 1:\n",
      "    enc input           > like i said predictable <EOS>\n",
      "    dec input           > roman is the new u champion <EOS>\n",
      "    dec train predicted > i empire a only one <EOS> <EOS>\n",
      "dev minibatch loss:5.97197\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:105, global_step:80030, learning rate:0.00377\n",
      "training minibatch loss:3.62668\n",
      "  sample 1:\n",
      "    enc input           > i don t hate you how s everything been <EOS>\n",
      "    dec input           > i know you hate me i just wanted to say hello <EOS>\n",
      "    dec train predicted > i don i re the <EOS> <EOS> realized to know it <EOS>\n",
      "dev minibatch loss:6.02153\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:106, global_step:80785, learning rate:0.00373\n",
      "training minibatch loss:3.67704\n",
      "  sample 1:\n",
      "    enc input           > we watched them be happy for about minute lol <EOS>\n",
      "    dec input           > we haven t watched the happy at all lol <EOS>\n",
      "    dec train predicted > i are t been a best birthday <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.98406\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:107, global_step:81540, learning rate:0.0037\n",
      "training minibatch loss:3.67781\n",
      "  sample 1:\n",
      "    enc input           > happy birthday to both of you <EOS>\n",
      "    dec input           > it came it came the birthday zit is real <EOS>\n",
      "    dec train predicted > happy s to s to birthday <EOS> to a <EOS>\n",
      "dev minibatch loss:5.72635\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:108, global_step:82295, learning rate:0.00366\n",
      "training minibatch loss:3.68821\n",
      "  sample 1:\n",
      "    enc input           > bro she keep asking me when am i going to with her <EOS>\n",
      "    dec input           > yea u need to give her some hookah and call it a day <EOS>\n",
      "    dec train predicted > i i i to get her a cod <EOS> she <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.75448\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:109, global_step:83050, learning rate:0.00363\n",
      "training minibatch loss:3.76187\n",
      "  sample 1:\n",
      "    enc input           > fb link acting a damn fool <EOS>\n",
      "    dec input           > ha well happy belated then <EOS>\n",
      "    dec train predicted > i a been to <EOS> <EOS>\n",
      "dev minibatch loss:5.76601\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:110, global_step:83805, learning rate:0.0036\n",
      "training minibatch loss:3.67282\n",
      "  sample 1:\n",
      "    enc input           > curious why is that ? <EOS>\n",
      "    dec input           > i hate him but i think they should allow him to come and speak <EOS>\n",
      "    dec train predicted > i m the <EOS> i m i were be <EOS> <EOS> be back <EOS> <EOS>\n",
      "dev minibatch loss:5.82054\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:111, global_step:84560, learning rate:0.00356\n",
      "training minibatch loss:3.72036\n",
      "  sample 1:\n",
      "    enc input           > she will trump is too stupid <EOS>\n",
      "    dec input           > clinton ha got win the at hofstra decisively or she will lose this election <EOS>\n",
      "    dec train predicted > trump is been a the debate debate <EOS> and secretary s be <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.98836\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:112, global_step:85315, learning rate:0.00353\n",
      "training minibatch loss:3.54547\n",
      "  sample 1:\n",
      "    enc input           > going to try and get more sleep <EOS>\n",
      "    dec input           > sniffle you don t care why <EOS>\n",
      "    dec train predicted > i me can t be about you\n",
      "dev minibatch loss:5.79641\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:113, global_step:86070, learning rate:0.0035\n",
      "training minibatch loss:3.62413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample 1:\n",
      "    enc input           > last i looked bill clinton isn t running for potus <EOS>\n",
      "    dec input           > defend her now poor liberal cant win <EOS>\n",
      "    dec train predicted > i the asset on millennial pepper be the\n",
      "dev minibatch loss:5.87594\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:114, global_step:86825, learning rate:0.00347\n",
      "training minibatch loss:3.73476\n",
      "  sample 1:\n",
      "    enc input           > we are expert in service in our portfolio email to leadscom <EOS>\n",
      "    dec input           > i m still developing it any website designer out there ? <EOS>\n",
      "    dec train predicted > any need looking looking any s more design <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.79397\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:115, global_step:87580, learning rate:0.00344\n",
      "training minibatch loss:3.76171\n",
      "  sample 1:\n",
      "    enc input           > yeah she wa assigned gr <EOS>\n",
      "    dec input           > omg i wa gon na say did sam choose him ? oh thank god <EOS>\n",
      "    dec train predicted > she she m deeply na be she she she her <EOS> <EOS> yeah you <EOS>\n",
      "dev minibatch loss:6.20738\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:116, global_step:88335, learning rate:0.0034\n",
      "training minibatch loss:3.67983\n",
      "  sample 1:\n",
      "    enc input           > oh of course i wa just watching that movie the other morning <EOS>\n",
      "    dec input           > megan fox date soon ? <EOS>\n",
      "    dec train predicted > i i news wa <EOS> <EOS>\n",
      "dev minibatch loss:5.59545\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:117, global_step:89090, learning rate:0.00337\n",
      "training minibatch loss:3.75741\n",
      "  sample 1:\n",
      "    enc input           > a blog post with fact about her blood bath <EOS>\n",
      "    dec input           > a blog post <EOS>\n",
      "    dec train predicted > i a is <EOS>\n",
      "dev minibatch loss:5.83245\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:118, global_step:89845, learning rate:0.00334\n",
      "training minibatch loss:3.71414\n",
      "  sample 1:\n",
      "    enc input           > um no dont fall in love <EOS>\n",
      "    dec input           > can t help falling in love with you <EOS>\n",
      "    dec train predicted > i you wait the up this ? this ?\n",
      "dev minibatch loss:6.05568\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:119, global_step:90600, learning rate:0.00331\n",
      "training minibatch loss:3.64092\n",
      "  sample 1:\n",
      "    enc input           > thanks so much come by when you are down here <EOS>\n",
      "    dec input           > congratulation on your new role you will be missed at twitter <EOS>\n",
      "    dec train predicted > i to the tweet virtual of re be happy <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:6.21523\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:120, global_step:91355, learning rate:0.00328\n",
      "training minibatch loss:3.60439\n",
      "  sample 1:\n",
      "    enc input           > hahaha hypocrisy in action <EOS>\n",
      "    dec input           > and when hillary clinton lie ? cause lying is definitely her game <EOS>\n",
      "    dec train predicted > i the you clinton is to <EOS> <EOS> <EOS> not the <EOS> <EOS>\n",
      "dev minibatch loss:5.72283\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:121, global_step:92110, learning rate:0.00325\n",
      "training minibatch loss:3.5407\n",
      "  sample 1:\n",
      "    enc input           > ah yes the plight of the pm am slot very good <EOS>\n",
      "    dec input           > sleep deprivation selfies swap hour <EOS>\n",
      "    dec train predicted > isnt ? ? in <EOS> <EOS>\n",
      "dev minibatch loss:5.93667\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:122, global_step:92865, learning rate:0.00322\n",
      "training minibatch loss:3.66128\n",
      "  sample 1:\n",
      "    enc input           > i just started <EOS>\n",
      "    dec input           > i need to watch <EOS>\n",
      "    dec train predicted > i m to be this\n",
      "dev minibatch loss:6.06762\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:123, global_step:93620, learning rate:0.00319\n",
      "training minibatch loss:3.73993\n",
      "  sample 1:\n",
      "    enc input           > better than shooting hunt over like some shoe <EOS>\n",
      "    dec input           > today shooting voiceovers for hunting adventure season <EOS>\n",
      "    dec train predicted > the s voiceovers <EOS> the secret and <EOS>\n",
      "dev minibatch loss:5.76058\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:124, global_step:94375, learning rate:0.00316\n",
      "training minibatch loss:3.68173\n",
      "  sample 1:\n",
      "    enc input           > rise of iron fall of the server <EOS>\n",
      "    dec input           > that s a new one <EOS>\n",
      "    dec train predicted > i s a good internship <EOS>\n",
      "dev minibatch loss:6.31019\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:125, global_step:95130, learning rate:0.00313\n",
      "training minibatch loss:3.65789\n",
      "  sample 1:\n",
      "    enc input           > flyer for our friday hotel utah gig w <EOS>\n",
      "    dec input           > have flyer courtesy of <EOS>\n",
      "    dec train predicted > i you ? of <EOS>\n",
      "dev minibatch loss:5.97935\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:126, global_step:95885, learning rate:0.0031\n",
      "training minibatch loss:3.69682\n",
      "  sample 1:\n",
      "    enc input           > it just the first little but after updating im sure itll get better soon <EOS>\n",
      "    dec input           > two week since watchos and my battery life is still <EOS>\n",
      "    dec train predicted > i hour of i <EOS> i heart <EOS> <EOS> so the\n",
      "dev minibatch loss:5.94082\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:127, global_step:96640, learning rate:0.00308\n",
      "training minibatch loss:3.53541\n",
      "  sample 1:\n",
      "    enc input           > i m in del rey and i don t drive you already know that <EOS>\n",
      "    dec input           > there is a wing stop in sanger <EOS>\n",
      "    dec train predicted > i s no bin <EOS> and the s\n",
      "dev minibatch loss:5.74354\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:128, global_step:97395, learning rate:0.00305\n",
      "training minibatch loss:3.58292\n",
      "  sample 1:\n",
      "    enc input           > i realize now that you re a troll carry on with your bizarre existence <EOS>\n",
      "    dec input           > smh ok man you re entitled to see it how you want <EOS>\n",
      "    dec train predicted > i i i i re a to the <EOS> <EOS> you are to\n",
      "dev minibatch loss:5.9128\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:129, global_step:98150, learning rate:0.00302\n",
      "training minibatch loss:3.61291\n",
      "  sample 1:\n",
      "    enc input           > x i think have to double check <EOS>\n",
      "    dec input           > i love this how big is it ? <EOS>\n",
      "    dec train predicted > i m you <EOS> s do this ? <EOS>\n",
      "dev minibatch loss:5.86957\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:130, global_step:98905, learning rate:0.00299\n",
      "training minibatch loss:3.69614\n",
      "  sample 1:\n",
      "    enc input           > clinton s entire campaign wa based on racism for instance this gem <EOS>\n",
      "    dec input           > im against racism no matter who spews it <EOS>\n",
      "    dec train predicted > backfire not hillary <EOS> one <EOS> s <EOS> <EOS>\n",
      "dev minibatch loss:5.90331\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:131, global_step:99660, learning rate:0.00296\n",
      "training minibatch loss:3.84098\n",
      "  sample 1:\n",
      "    enc input           > brand new tune <EOS>\n",
      "    dec input           > what other name is known by ? <EOS>\n",
      "    dec train predicted > playing do option ? on to the <EOS>\n",
      "dev minibatch loss:6.21365\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:132, global_step:100415, learning rate:0.00294\n",
      "training minibatch loss:3.66624\n",
      "  sample 1:\n",
      "    enc input           > yes and chlamydia give you no symptom of the time <EOS>\n",
      "    dec input           > so you can get rid of chlamydia quicker than a cold ? <EOS>\n",
      "    dec train predicted > you you re t a of you ? ? permission ? ? <EOS>\n",
      "dev minibatch loss:6.12568\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:133, global_step:101170, learning rate:0.00291\n",
      "training minibatch loss:3.76954\n",
      "  sample 1:\n",
      "    enc input           > i know right ? first baseball game in year amazing <EOS>\n",
      "    dec input           > picked a heck of a game to go to lol <EOS>\n",
      "    dec train predicted > i up fan ho the fan of be <EOS> napa <EOS>\n",
      "dev minibatch loss:5.70036\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:134, global_step:101925, learning rate:0.00288\n",
      "training minibatch loss:3.58799\n",
      "  sample 1:\n",
      "    enc input           > the cafeteria worker can t afford the rent <EOS>\n",
      "    dec input           > also reduced demand thanks to all the cafeteria <EOS>\n",
      "    dec train predicted > i the the the <EOS> the the noise <EOS>\n",
      "dev minibatch loss:5.84988\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:135, global_step:102680, learning rate:0.00286\n",
      "training minibatch loss:3.58947\n",
      "  sample 1:\n",
      "    enc input           > fuck protest vote what an ineffectual waste <EOS>\n",
      "    dec input           > yep it s more a protest vote he hate hillary <EOS>\n",
      "    dec train predicted > i i s not <EOS> lot <EOS> <EOS> s <EOS> <EOS>\n",
      "dev minibatch loss:6.43727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:136, global_step:103435, learning rate:0.00283\n",
      "training minibatch loss:3.55833\n",
      "  sample 1:\n",
      "    enc input           > i ll miss everyone around the office <EOS>\n",
      "    dec input           > good luck we ll miss you around the office <EOS>\n",
      "    dec train predicted > i morning i are be you <EOS> <EOS> jungle <EOS>\n",
      "dev minibatch loss:5.81347\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:137, global_step:104190, learning rate:0.00281\n",
      "training minibatch loss:3.59487\n",
      "  sample 1:\n",
      "    enc input           > folk who work on open source still got ta pay the bill somehow <EOS>\n",
      "    dec input           > just feel like a great open sourced project for motivated people <EOS>\n",
      "    dec train predicted > the ranking like a homophobe question university monitoring among the to are\n",
      "dev minibatch loss:6.15257\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:138, global_step:104945, learning rate:0.00278\n",
      "training minibatch loss:3.71126\n",
      "  sample 1:\n",
      "    enc input           > you b knowin the classic b <EOS>\n",
      "    dec input           > one of my favorite <EOS>\n",
      "    dec train predicted > meek of the artery vine\n",
      "dev minibatch loss:6.00981\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:139, global_step:105700, learning rate:0.00275\n",
      "training minibatch loss:3.63466\n",
      "  sample 1:\n",
      "    enc input           > when did you take up sportsball ? also which sportsball ? <EOS>\n",
      "    dec input           > lost our first match however one of those goal wa mine <EOS>\n",
      "    dec train predicted > i the stats game <EOS> <EOS> <EOS> the <EOS> <EOS> a <EOS>\n",
      "dev minibatch loss:6.05496\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:140, global_step:106455, learning rate:0.00273\n",
      "training minibatch loss:3.6048\n",
      "  sample 1:\n",
      "    enc input           > so glad to see you re here looking forward to meeting in person <EOS>\n",
      "    dec input           > inspired at listening to context matter now more than ever in marketing <EOS>\n",
      "    dec train predicted > looking on the to meeting <EOS> you <EOS> <EOS> a <EOS> the <EOS>\n",
      "dev minibatch loss:6.16094\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:141, global_step:107210, learning rate:0.0027\n",
      "training minibatch loss:3.72638\n",
      "  sample 1:\n",
      "    enc input           > i watched it until season i think <EOS>\n",
      "    dec input           > what about lost <EOS>\n",
      "    dec train predicted > i s organizing the\n",
      "dev minibatch loss:5.74043\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:142, global_step:107965, learning rate:0.00268\n",
      "training minibatch loss:3.56805\n",
      "  sample 1:\n",
      "    enc input           > yes but it wa hilarious to over hear at work <EOS>\n",
      "    dec input           > that s just called recursion <EOS>\n",
      "    dec train predicted > i wa a a humanity <EOS>\n",
      "dev minibatch loss:5.67578\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:143, global_step:108720, learning rate:0.00265\n",
      "training minibatch loss:3.66967\n",
      "  sample 1:\n",
      "    enc input           > who is winning ? ? <EOS>\n",
      "    dec input           > came out on the offensive early in her first debate with <EOS>\n",
      "    dec train predicted > i out with the team robot game the own nba <EOS> a\n",
      "dev minibatch loss:5.9634\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:144, global_step:109475, learning rate:0.00263\n",
      "training minibatch loss:3.69219\n",
      "  sample 1:\n",
      "    enc input           > wa just thinking of you did ya see ? ? <EOS>\n",
      "    dec input           > oakland considering sweeping change to parking requirement for new development <EOS>\n",
      "    dec train predicted > i is a the <EOS> be member for the york <EOS>\n",
      "dev minibatch loss:6.17584\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:145, global_step:110230, learning rate:0.00261\n",
      "training minibatch loss:3.61249\n",
      "  sample 1:\n",
      "    enc input           > good morning dope shit really dope <EOS>\n",
      "    dec input           > detailed and rearranged the majority of my shelf <EOS>\n",
      "    dec train predicted > good i i my morning of the morning <EOS>\n",
      "dev minibatch loss:6.24699\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:146, global_step:110985, learning rate:0.00258\n",
      "training minibatch loss:3.59811\n",
      "  sample 1:\n",
      "    enc input           > lol right ? <EOS>\n",
      "    dec input           > i m sure donald is seeking our sage advice <EOS>\n",
      "    dec train predicted > i m not i trump a <EOS> body <EOS> <EOS>\n",
      "dev minibatch loss:6.26079\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:147, global_step:111740, learning rate:0.00256\n",
      "training minibatch loss:3.56001\n",
      "  sample 1:\n",
      "    enc input           > so how doe houston have a better def ? <EOS>\n",
      "    dec input           > do u not see how soft they been today fam ? <EOS>\n",
      "    dec train predicted > i you awake graduate the to ? are awake ? <EOS> <EOS>\n",
      "dev minibatch loss:6.03835\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:148, global_step:112495, learning rate:0.00254\n",
      "training minibatch loss:3.63775\n",
      "  sample 1:\n",
      "    enc input           > i look forward to them when i get home from work at am <EOS>\n",
      "    dec input           > that s what i shoot for bless u <EOS>\n",
      "    dec train predicted > i s a i do <EOS> the <EOS> <EOS>\n",
      "dev minibatch loss:5.41576\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:149, global_step:113250, learning rate:0.00251\n",
      "training minibatch loss:3.66315\n",
      "  sample 1:\n",
      "    enc input           > and last but not least child cancer <EOS>\n",
      "    dec input           > even now a confusing world that sends most to hell <EOS>\n",
      "    dec train predicted > i a i lot <EOS> <EOS> is a honest the <EOS>\n",
      "dev minibatch loss:5.93401\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:150, global_step:114005, learning rate:0.00249\n",
      "training minibatch loss:3.60204\n",
      "  sample 1:\n",
      "    enc input           > all wine is gross <EOS>\n",
      "    dec input           > red wine is gross <EOS>\n",
      "    dec train predicted > i athlete is a <EOS>\n",
      "dev minibatch loss:6.17034\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:151, global_step:114760, learning rate:0.00247\n",
      "training minibatch loss:3.61102\n",
      "  sample 1:\n",
      "    enc input           > almost home i just got back from the airport <EOS>\n",
      "    dec input           > just got done icing wby ? <EOS>\n",
      "    dec train predicted > i a a with <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:6.12124\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:152, global_step:115515, learning rate:0.00244\n",
      "training minibatch loss:3.58073\n",
      "  sample 1:\n",
      "    enc input           > i m sure it ll get crazy markdown atleast <EOS>\n",
      "    dec input           > ah well there you go no <EOS>\n",
      "    dec train predicted > i exciting i is no to idea\n",
      "dev minibatch loss:6.10109\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:153, global_step:116270, learning rate:0.00242\n",
      "training minibatch loss:3.57565\n",
      "  sample 1:\n",
      "    enc input           > more like coming home from the airport robbery <EOS>\n",
      "    dec input           > that s like going to the airport money <EOS>\n",
      "    dec train predicted > intervention s why a to be intervention <EOS> <EOS>\n",
      "dev minibatch loss:6.15662\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:154, global_step:117025, learning rate:0.0024\n",
      "training minibatch loss:3.57353\n",
      "  sample 1:\n",
      "    enc input           > i condemn anyone who helped hitler <EOS>\n",
      "    dec input           > no answer ? <EOS>\n",
      "    dec train predicted > i one for <EOS>\n",
      "dev minibatch loss:6.16821\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:155, global_step:117780, learning rate:0.00238\n",
      "training minibatch loss:3.70773\n",
      "  sample 1:\n",
      "    enc input           > yes i hope so too <EOS>\n",
      "    dec input           > thank you beauty i hope to see you soon <EOS>\n",
      "    dec train predicted > i you so <EOS> m you get you <EOS> <EOS>\n",
      "dev minibatch loss:5.56571\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:156, global_step:118535, learning rate:0.00236\n",
      "training minibatch loss:3.64334\n",
      "  sample 1:\n",
      "    enc input           > i m thinking there <EOS>\n",
      "    dec input           > but zoom in on soma <EOS>\n",
      "    dec train predicted > i i is the the <EOS>\n",
      "dev minibatch loss:6.15737\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:157, global_step:119290, learning rate:0.00233\n",
      "training minibatch loss:3.79773\n",
      "  sample 1:\n",
      "    enc input           > you can say that lol i have him blocked on this account <EOS>\n",
      "    dec input           > he love you that much ? lol <EOS>\n",
      "    dec train predicted > i s him <EOS> s <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:6.42487\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:158, global_step:120045, learning rate:0.00231\n",
      "training minibatch loss:3.41776\n",
      "  sample 1:\n",
      "    enc input           > wow and both got solid like <EOS>\n",
      "    dec input           > hater will say you tweeted this twice by accident <EOS>\n",
      "    dec train predicted > i is be it re it <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:6.168\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:159, global_step:120800, learning rate:0.00229\n",
      "training minibatch loss:3.47863\n",
      "  sample 1:\n",
      "    enc input           > listen to this and you can get those player you need <EOS>\n",
      "    dec input           > yes sir must listen pre tuesday <EOS>\n",
      "    dec train predicted > i i i be to thing <EOS>\n",
      "dev minibatch loss:5.61197\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:160, global_step:121555, learning rate:0.00227\n",
      "training minibatch loss:3.52837\n",
      "  sample 1:\n",
      "    enc input           > bih it s homework <EOS>\n",
      "    dec input           > all i see on my snapchat is the trump and hillary thing <EOS>\n",
      "    dec train predicted > i of want this tumblr tl is bonnie best dab receiving <EOS> <EOS>\n",
      "dev minibatch loss:5.79507\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:161, global_step:122310, learning rate:0.00225\n",
      "training minibatch loss:3.56731\n",
      "  sample 1:\n",
      "    enc input           > it abt the sound not the name but signed producer get salary tho <EOS>\n",
      "    dec input           > i know producer online that make more leasing beat than producer that are signed <EOS>\n",
      "    dec train predicted > i m it is is is it sense <EOS> <EOS> i <EOS> s intriguing it\n",
      "dev minibatch loss:6.18033\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:162, global_step:123065, learning rate:0.00223\n",
      "training minibatch loss:3.65337\n",
      "  sample 1:\n",
      "    enc input           > slam head into wall stupid stupid stupid me <EOS>\n",
      "    dec input           > you know i can t say anything p <EOS>\n",
      "    dec train predicted > i are what m t believe i <EOS> <EOS>\n",
      "dev minibatch loss:6.11638\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:163, global_step:123820, learning rate:0.00221\n",
      "training minibatch loss:3.65465\n",
      "  sample 1:\n",
      "    enc input           > me reading libra <EOS>\n",
      "    dec input           > the tough life of leo <EOS>\n",
      "    dec train predicted > i whole song is the <EOS>\n",
      "dev minibatch loss:6.1364\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:164, global_step:124575, learning rate:0.00219\n",
      "training minibatch loss:3.57084\n",
      "  sample 1:\n",
      "    enc input           > he s starting to crack and sound like crazy donald <EOS>\n",
      "    dec input           > she got to him <EOS>\n",
      "    dec train predicted > trump s a be <EOS>\n",
      "dev minibatch loss:5.96414\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:165, global_step:125330, learning rate:0.00217\n",
      "training minibatch loss:3.59451\n",
      "  sample 1:\n",
      "    enc input           > everything in moderation except moderation <EOS>\n",
      "    dec input           > moderation feature in general are sorely lacking <EOS>\n",
      "    dec train predicted > i of embargo the <EOS> devil <EOS> in\n",
      "dev minibatch loss:6.45729\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:166, global_step:126085, learning rate:0.00215\n",
      "training minibatch loss:3.54355\n",
      "  sample 1:\n",
      "    enc input           > she will find out what we are on nov victorious <EOS>\n",
      "    dec input           > hillary meant that we are adorable not deplorable <EOS>\n",
      "    dec train predicted > i clinton to s ll talking <EOS> talked <EOS>\n",
      "dev minibatch loss:6.49294\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:167, global_step:126840, learning rate:0.00213\n",
      "training minibatch loss:3.42147\n",
      "  sample 1:\n",
      "    enc input           > clinton first big washington scandal these are despicable people thanks for reminder m noonan <EOS>\n",
      "    dec input           > travel back to an early clinton scandal by via <EOS>\n",
      "    dec train predicted > the to to the hour <EOS> <EOS> <EOS> the <EOS>\n",
      "dev minibatch loss:6.34928\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:168, global_step:127595, learning rate:0.00211\n",
      "training minibatch loss:3.57902\n",
      "  sample 1:\n",
      "    enc input           > what kind of man think that make sense not a bright one <EOS>\n",
      "    dec input           > what kind of man support hillary ? oh wait maybe your gender fluid <EOS>\n",
      "    dec train predicted > i s of thread is ? s <EOS> what <EOS> you name <EOS> ?\n",
      "dev minibatch loss:5.80645\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:169, global_step:128350, learning rate:0.00209\n",
      "training minibatch loss:3.61057\n",
      "  sample 1:\n",
      "    enc input           > live is a strong word <EOS>\n",
      "    dec input           > is that ur house where u live <EOS>\n",
      "    dec train predicted > i this a roster ? ? ? ?\n",
      "dev minibatch loss:6.16054\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:170, global_step:129105, learning rate:0.00207\n",
      "training minibatch loss:3.6008\n",
      "  sample 1:\n",
      "    enc input           > think of it a a kale substitute <EOS>\n",
      "    dec input           > i don t often eat meat but i m willing to make an exception <EOS>\n",
      "    dec train predicted > i m t know know it cleaver i m not to get it outlet <EOS>\n",
      "dev minibatch loss:5.96971\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:171, global_step:129860, learning rate:0.00205\n",
      "training minibatch loss:3.4643\n",
      "  sample 1:\n",
      "    enc input           > lmfaooo yooo i just died watching this <EOS>\n",
      "    dec input           > in case you guy missed this i really can t get over this lmfao <EOS>\n",
      "    dec train predicted > i the i re are me <EOS> m want t <EOS> it <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.99654\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:172, global_step:130615, learning rate:0.00203\n",
      "training minibatch loss:3.4983\n",
      "  sample 1:\n",
      "    enc input           > ii got beat check these out <EOS>\n",
      "    dec input           > im looking for free beat to kill them contact me <EOS>\n",
      "    dec train predicted > send beat for sample beat <EOS> beat beat <EOS> beat <EOS>\n",
      "dev minibatch loss:5.736\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:173, global_step:131370, learning rate:0.00201\n",
      "training minibatch loss:3.46842\n",
      "  sample 1:\n",
      "    enc input           > i love you too <EOS>\n",
      "    dec input           > have a good day at work beautiful i love you so much <EOS>\n",
      "    dec train predicted > i a great day <EOS> the <EOS> <EOS> love you <EOS> much <EOS>\n",
      "dev minibatch loss:6.0546\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:174, global_step:132125, learning rate:0.002\n",
      "training minibatch loss:3.6047\n",
      "  sample 1:\n",
      "    enc input           > what a neatly packaged article no thanks <EOS>\n",
      "    dec input           > on why american should acknowledge not avoid their difference of religion amp idea <EOS>\n",
      "    dec train predicted > kellyanne the you are have the a <EOS> surrogate <EOS> charity ahmadi occurring <EOS>\n",
      "dev minibatch loss:6.041\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:175, global_step:132880, learning rate:0.00198\n",
      "training minibatch loss:3.57194\n",
      "  sample 1:\n",
      "    enc input           > u making politics lit fam <EOS>\n",
      "    dec input           > it make every bit of sense <EOS>\n",
      "    dec train predicted > i s me day of me <EOS>\n",
      "dev minibatch loss:6.43873\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:176, global_step:133635, learning rate:0.00196\n",
      "training minibatch loss:3.62451\n",
      "  sample 1:\n",
      "    enc input           > fitz is deplorable absolutely awful game today i am beyond disgusted <EOS>\n",
      "    dec input           > just when you think it couldn t get any uglier turnover fitzpatrick with interception <EOS>\n",
      "    dec train predicted > i sickening they are marijuana s be be paid debt <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "dev minibatch loss:5.88272\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:177, global_step:134390, learning rate:0.00194\n",
      "training minibatch loss:3.52463\n",
      "  sample 1:\n",
      "    enc input           > the key lime blend is by far my fav <EOS>\n",
      "    dec input           > fall indulgence zero guilt with caramel apple limited batch chobani <EOS>\n",
      "    dec train predicted > i day the in <EOS> a <EOS> are edition of <EOS>\n",
      "dev minibatch loss:6.31953\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:178, global_step:135145, learning rate:0.00192\n",
      "training minibatch loss:3.49362\n",
      "  sample 1:\n",
      "    enc input           > mood unless i m aggy lol <EOS>\n",
      "    dec input           > thats dead your fave gif <EOS>\n",
      "    dec train predicted > coupon a <EOS> favorite cousin <EOS>\n",
      "dev minibatch loss:5.99195\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:179, global_step:135900, learning rate:0.00191\n",
      "training minibatch loss:3.69161\n",
      "  sample 1:\n",
      "    enc input           > i can be if the chick is worth it <EOS>\n",
      "    dec input           > who a freak on snap chat <EOS>\n",
      "    dec train predicted > i s ? ? the ? ?\n",
      "dev minibatch loss:6.1057\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:180, global_step:136655, learning rate:0.00189\n",
      "training minibatch loss:3.42129\n",
      "  sample 1:\n",
      "    enc input           > start in the usa on monday at pm est <EOS>\n",
      "    dec input           > same day and time here ? <EOS>\n",
      "    dec train predicted > i i in frustration to <EOS> <EOS>\n",
      "dev minibatch loss:6.24368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:181, global_step:137410, learning rate:0.00187\n",
      "training minibatch loss:3.55369\n",
      "  sample 1:\n",
      "    enc input           > he doe that a a joke he been wearing them for a minute <EOS>\n",
      "    dec input           > i wa just looking at this <EOS>\n",
      "    dec train predicted > pope m blinded a for cp <EOS>\n",
      "dev minibatch loss:5.93854\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:182, global_step:138165, learning rate:0.00185\n",
      "training minibatch loss:3.56465\n",
      "  sample 1:\n",
      "    enc input           > legitimate reason to have kid <EOS>\n",
      "    dec input           > i can t wait to have kid and eat all their leftover <EOS>\n",
      "    dec train predicted > i m t be to kfc worn <EOS> i <EOS> of <EOS> <EOS>\n",
      "dev minibatch loss:6.0006\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "epoch:183, global_step:138920, learning rate:0.00184\n",
      "training minibatch loss:3.50842\n",
      "  sample 1:\n",
      "    enc input           > tell him he ll be aight <EOS>\n",
      "    dec input           > he told me to tell u to stop taking screen shot of my snap <EOS>\n",
      "    dec train predicted > i s me he be me <EOS> be <EOS> a <EOS> <EOS> <EOS> brother <EOS>\n",
      "dev minibatch loss:6.05693\n",
      "Session saved\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "print_interval = 1\n",
    "save_interval = 3\n",
    "\n",
    "train_loss = []\n",
    "dev_loss = []\n",
    "learning_rate = []\n",
    "\n",
    "n_batch_size  = training_params['minibatch_size']\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    #saver.restore(session, 'chkpt/seq2seq_twitter_sample-12880')\n",
    "\n",
    "    for epoch in range(training_params['n_epochs']):\n",
    "        \n",
    "        df_all_train = df_all_train.sample(frac=1, random_state=tf.train.global_step(session, global_step))\n",
    "       \n",
    "        encoded_text = df_all_train['alpha_Pair_0_encoding'].values\n",
    "        decoded_text = df_all_train['alpha_Pair_1_encoding'].values\n",
    "        \n",
    "        text_index = df_all_train['Index'].values\n",
    "        \n",
    "        input_batches = ([encoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                 decoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                         text_index[block_idx*n_batch_size:(block_idx+1)*n_batch_size]]\\\n",
    "                    for block_idx in range(len(encoded_text)))\n",
    "        \n",
    "        for batch in range(training_params['batches_in_epoch']):\n",
    "            \n",
    "            if batch % 100 == 0: print (batch)\n",
    "            \n",
    "            epoch_batches = next(input_batches)\n",
    "\n",
    "            input_batch_data = epoch_batches[0]\n",
    "            target_batch_data = epoch_batches[1]\n",
    "            batch_data_index = epoch_batches[2]\n",
    "\n",
    "            fd = data_formatting.prepare_train_batch(input_batch_data, target_batch_data)\n",
    "\n",
    "            feed_dict = {'encoder_inputs:0': fd[0],\n",
    "                         'encoder_inputs_length:0': fd[1],\n",
    "                         'decoder_targets:0': fd[2],\n",
    "                         'decoder_targets_length:0': fd[3]}\n",
    "\n",
    "            results = session.run(train_op, feed_dict)\n",
    "\n",
    "        print ('epoch:%d, global_step:%s, learning rate:%.3g' % \n",
    "                   (epoch, tf.train.global_step(session, global_step), session.run(optimizer._lr)))\n",
    "        \n",
    "        train_minibatch_loss = session.run(train_model.loss, feed_dict)\n",
    "        \n",
    "        train_loss.append([tf.train.global_step(session, global_step),train_minibatch_loss])  \n",
    "        \n",
    "        print ('training minibatch loss:%.6g' % (train_minibatch_loss))\n",
    "\n",
    "        df_sample = df_all_dev.sample(n=n_batch_size, random_state=tf.train.global_step(session, global_step))\n",
    "\n",
    "        input_batch_data = df_sample['alpha_Pair_0_encoding'].values\n",
    "        target_batch_data = df_sample['alpha_Pair_1_encoding'].values\n",
    "\n",
    "        fd_dev = data_formatting.prepare_train_batch(input_batch_data, target_batch_data)\n",
    "\n",
    "        feed_dict_dev = {'encoder_inputs:0': fd_dev[0],\n",
    "                         'encoder_inputs_length:0': fd_dev[1],\n",
    "                         'decoder_targets:0': fd_dev[2],\n",
    "                         'decoder_targets_length:0': fd_dev[3]}\n",
    "\n",
    "        dev_minibatch_loss = session.run(train_model.loss, feed_dict_dev)\n",
    "\n",
    "        validate(train_model.decoder_pred_train, feed_dict_dev) \n",
    "\n",
    "        print ('dev minibatch loss:%.6g' % (dev_minibatch_loss))\n",
    "\n",
    "        dev_loss.append([tf.train.global_step(session, global_step), dev_minibatch_loss])\n",
    "        \n",
    "        learning_rate.append([tf.train.global_step(session, global_step), session.run(optimizer._lr)])\n",
    "        \n",
    "        if epoch % save_interval == 0: \n",
    "\n",
    "            saver.save(session, 'chkpt/seq2seq_twitter_sample', global_step = tf.train.global_step(session, global_step))\n",
    "\n",
    "            print ('Session saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_model = create_model.Model(model_params, 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from chkpt/seq2seq_twitter_sample-30200\n",
      "e_in ['no', 'he', 'wa', 'just', 'some', 'nigger', 'that', 'obama', 'used', 'to', 'hang', 'with', '<EOS>']\n",
      "d_in ['obama', 'hired', 'van', 'jones', 'too', 'wasn', 't', 'he', 'a', 'communist', '?', '<EOS>']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, 'chkpt/seq2seq_twitter_sample-30200')\n",
    "    \n",
    "    #ran_seq = generateRandomSeqBatchMajor(length_from=training_params['seq_low'], length_to=training_params['seq_high'],\n",
    "    #                                       vocab_lower=2, vocab_upper=training_params['vocab_upper'],\n",
    "    #                                       batch_size=training_params['minibatch_size'])\n",
    "    \n",
    "    #input_batch_data = ran_seq\n",
    "    \n",
    "    df_sample = df_all_dev.sample(n=1, random_state=0)\n",
    "#    df_sample = df_all_train.sample(n=1)\n",
    "\n",
    "    input_batch_data = df_sample['alpha_Pair_0_encoding'].values\n",
    "    target_batch_data = df_sample['alpha_Pair_1_encoding'].values\n",
    "    \n",
    "    fd = data_formatting.prepare_train_batch(input_batch_data, target_batch_data)\n",
    "\n",
    "    fd_inf = data_formatting.prepare_batch(input_batch_data)\n",
    "    \n",
    "    feed_dict_inf = {'encoder_inputs:0': fd_inf[0],\n",
    "                     'encoder_inputs_length:0': fd_inf[1]}\n",
    "    \n",
    "    #inf_out = session.run([inf_model.decoder_pred_decode, inf_model.decoder_pred_decode_prob], feed_dict_inf)\n",
    "    inf_out = session.run([inf_model.decoder_pred_decode], feed_dict_inf)\n",
    "    \n",
    "    for (e_in, dt_in, dt_inf) in zip(fd[0], fd[2], inf_out[0]):\n",
    "        print ('e_in', decodeSent(e_in))\n",
    "        print ('d_in', decodeSent(dt_in))        \n",
    "        #print ('_inf', decodeSent(dt_inf))\n",
    "        print (' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHY DOES BEAM SEARCH PRODUCE A -1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map[-1] = 'NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump',\n",
       " 's',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'civility',\n",
       " '<EOS>',\n",
       " 'NULL',\n",
       " 'NULL',\n",
       " 'NULL',\n",
       " 'NULL',\n",
       " 'NULL',\n",
       " 'NULL']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inv_map[i] for i in list(zip(*inf_out[0][0]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from chkpt/seq2seq_twitter_sample-236096\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    #session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, 'chkpt/seq2seq_twitter_sample-236096')\n",
    "    inf_out = session.run([inf_model.decoder_outputs_decode], \n",
    "                          feed_dict_inf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have',\n",
       " 'you',\n",
       " 'been',\n",
       " 'toggling',\n",
       " 'off',\n",
       " 'the',\n",
       " 'bluetooth',\n",
       " 'radio',\n",
       " 'or',\n",
       " 'is',\n",
       " 'it',\n",
       " 'always',\n",
       " 'on',\n",
       " '?',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodeSent(feed_dict_inf['encoder_inputs:0'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'bose',\n",
       " 'headphone',\n",
       " 'are',\n",
       " 'so',\n",
       " 'constantly',\n",
       " 'disconnecting',\n",
       " 'randomly',\n",
       " 'from',\n",
       " 'my',\n",
       " 'iphone',\n",
       " 'but',\n",
       " 'not',\n",
       " 'any',\n",
       " 'other',\n",
       " 'device',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodeSent(list(zip(*q.beam_search_decoder_output.predicted_ids[0]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_map[13983]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13983, 10486,  1006,  7185, 16110, 11633],\n",
       "       [ 7881,  7881,  7881, 14596,  7881, 16584],\n",
       "       [ 2915,  2915, 14575, 16584,  4785, 15563],\n",
       "       [ 6297,  6297,  6297, 13473,  6297,  6297],\n",
       "       [15464, 14856,  7524,  4569, 16749, 15283],\n",
       "       [10829, 15464, 11589, 15464,  6063,  7773],\n",
       "       [ 8320, 10829,  7524, 10673,  9781,  5053],\n",
       "       [15563,  8320,     1, 12302,  4378, 13983],\n",
       "       [16749, 15563,     1, 13983,  3104,  6824],\n",
       "       [13983, 16749,  6385,     1,  2175,  8748],\n",
       "       [16584, 13983,  1655,     1,  1972, 11172],\n",
       "       [ 1655, 11172, 16584, 13983,     1, 10486],\n",
       "       [11773,     1,  1655,  7881,     1,  2175],\n",
       "       [ 3104,     1, 11773,  2915,     1, 14215],\n",
       "       [ 2175,     1,  1492,  3104, 16451,     1],\n",
       "       [ 7218,     1,     1,  2175, 16451,     1],\n",
       "       [    1,     1,     1,     1,  7218,     1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.beam_search_decoder_output.predicted_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'the', 'your', 'it', 'their', 'this']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodeSent(q.beam_search_decoder_output.predicted_ids[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.035850089,\n",
       "  -0.035851996,\n",
       "  -0.038993467,\n",
       "  -0.039482821,\n",
       "  -0.35288915,\n",
       "  -0.3532013,\n",
       "  -0.35320261,\n",
       "  -0.35321036,\n",
       "  -0.35325852,\n",
       "  -0.35838923,\n",
       "  -0.36694854,\n",
       "  -0.67802882,\n",
       "  -0.68024153,\n",
       "  -0.68467307,\n",
       "  -0.68513405,\n",
       "  -0.69088089,\n",
       "  -0.69419718),\n",
       " (-3.3503947,\n",
       "  -3.3508077,\n",
       "  -3.5386569,\n",
       "  -3.5386579,\n",
       "  -1.4511024,\n",
       "  -1.7200738,\n",
       "  -1.7201383,\n",
       "  -1.7316133,\n",
       "  -1.7316157,\n",
       "  -2.0672543,\n",
       "  -2.0672672,\n",
       "  -1.7039001,\n",
       "  -1.7039022,\n",
       "  -1.7039022,\n",
       "  -1.7039022,\n",
       "  -1.7039022,\n",
       "  -1.7039022),\n",
       " (-8.9498634,\n",
       "  -8.9612808,\n",
       "  -5.4555082,\n",
       "  -5.8360171,\n",
       "  -3.8721921,\n",
       "  -3.3295441,\n",
       "  -3.6099124,\n",
       "  -4.0482016,\n",
       "  -4.0482016,\n",
       "  -3.0341046,\n",
       "  -3.0658193,\n",
       "  -2.0685022,\n",
       "  -2.0700371,\n",
       "  -2.1878219,\n",
       "  -2.651706,\n",
       "  -2.883266,\n",
       "  -2.883266),\n",
       " (-11.533058,\n",
       "  -11.431015,\n",
       "  -6.8540144,\n",
       "  -6.8631053,\n",
       "  -3.9936094,\n",
       "  -3.8760388,\n",
       "  -3.9421754,\n",
       "  -4.2694464,\n",
       "  -4.6147184,\n",
       "  -4.0482016,\n",
       "  -4.0482016,\n",
       "  -3.2055624,\n",
       "  -3.2584443,\n",
       "  -3.288914,\n",
       "  -3.2263942,\n",
       "  -3.2267132,\n",
       "  -3.3478928),\n",
       " (-13.323359,\n",
       "  -11.533113,\n",
       "  -7.0203815,\n",
       "  -6.8664236,\n",
       "  -5.0726089,\n",
       "  -4.0405722,\n",
       "  -4.0666785,\n",
       "  -4.3873162,\n",
       "  -5.6668005,\n",
       "  -5.6887541,\n",
       "  -5.5268912,\n",
       "  -4.0482016,\n",
       "  -4.0482016,\n",
       "  -4.0482016,\n",
       "  -3.2890604,\n",
       "  -3.3477957,\n",
       "  -3.537257),\n",
       " (-13.663095,\n",
       "  -12.553688,\n",
       "  -7.2248149,\n",
       "  -7.0404048,\n",
       "  -5.9452543,\n",
       "  -4.3421021,\n",
       "  -4.5275702,\n",
       "  -4.5065293,\n",
       "  -5.7755489,\n",
       "  -5.8911247,\n",
       "  -6.5263944,\n",
       "  -6.0815678,\n",
       "  -6.2003884,\n",
       "  -4.7698684,\n",
       "  -4.0482016,\n",
       "  -4.0482016,\n",
       "  -4.0482016)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*q.beam_search_decoder_output.scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.035852  ,  -3.35080767,  -8.96128082, -11.43101501,\n",
       "       -11.53311253, -12.55368805], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.beam_search_decoder_output.scores[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BeamSearchDecoder.step of <tensorflow.contrib.seq2seq.python.ops.beam_search_decoder.BeamSearchDecoder object at 0x000002A304336400>>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_model.inference_decoder.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = inf_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inf_out[0][0]) #hidden states and cell states of single LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inf_out[0][0][0]) #tile duplicates of the LSTM equal to beam_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inf_out[0][0][0][0]) #number of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
