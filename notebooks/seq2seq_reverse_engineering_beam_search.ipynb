{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import create_model\n",
    "import pickle\n",
    "import time \n",
    "import copy\n",
    "import random\n",
    "import data_formatting\n",
    "\n",
    "\n",
    "def validate(train):\n",
    "    \n",
    "    if train == True:\n",
    "        \n",
    "        model = train_model\n",
    "        mode = 'TRAIN'\n",
    "        \n",
    "    else:\n",
    "        mode = 'DEV'\n",
    "        model = dev_model\n",
    "\n",
    "    encoder, decoder, predicted = session.run([model.encoder_inputs, model.decoder_targets, model.decoder_pred_train])            \n",
    "\n",
    "    print ('Current mode:%s' % mode)\n",
    "    for i, (e_in, dt_targ, dt_pred) in enumerate(zip( encoder, decoder, predicted)):\n",
    "\n",
    "        print('  sample {}:'.format(i + 1))\n",
    "        #print('    enc input           > {}'.format(e_in))\n",
    "        print('    enc input           > {}'.format(data_formatting.decodeSent(e_in, inv_map)))\n",
    "\n",
    "        #print('    dec input           > {}'.format(dt_targ))\n",
    "        print('    dec input           > {}'.format(data_formatting.decodeSent(dt_targ, inv_map)))\n",
    "\n",
    "        #print('    dec train predicted > {}'.format(dt_pred))\n",
    "        print('    dec train predicted > {}'.format(data_formatting.decodeSent(dt_pred, inv_map)))\n",
    "\n",
    "        if i >= 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'enron'\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl')\n",
    "\n",
    "dataset = 'twitter'\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_25_sample_1764604_questions.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_25_sample_1764604_questions.pkl')\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_4_15_sample_134241_full.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_4_15_sample_134241_full.pkl')\n",
    "\n",
    "vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_19_sample_21946_lem.pkl', 'rb'))\n",
    "df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_19_sample_21946_lem.pkl')\n",
    "\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_25_sample_1901567_full.pkl', 'rb'))\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_25_sample_1901567_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = data_formatting.createInvMap(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_params = {'n_cells':256, 'num_layers':2, 'embedding_size':512, \n",
    "          'vocab_size':len(vocab_dict) + 1, 'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':10, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1, 'anti_lm_weight':0.5,\n",
    "                      'anti_lm_max_step':3\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_model_params = train_model_params\n",
    "dev_model_params['encoder_input_keep'] = 1\n",
    "dev_model_params['encoder_output_keep'] = 1\n",
    "dev_model_params['decoder_input_keep'] = 1\n",
    "dev_model_params['decoder_output_keep'] = 1\n",
    "\n",
    "training_params = { 'vocab_lower':3, 'vocab_upper':train_model_params['vocab_size']-1, \n",
    "                    'n_epochs':500000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17690 17159 478 53 17322\n"
     ]
    }
   ],
   "source": [
    "df_all['alpha_Pair_0_encoding'] = df_all['alpha_Pair_0_tokens'].apply(lambda x: data_formatting.encodeSent(x, vocab_dict))\n",
    "df_all['alpha_Pair_1_encoding'] = df_all['alpha_Pair_1_tokens'].apply(lambda x: data_formatting.encodeSent(x, vocab_dict))\n",
    "df_all['Index'] = df_all.index.values\n",
    "\n",
    "df_all_train = df_all.sample(frac=0.97, random_state=1)\n",
    "\n",
    "df_all_dev = df_all[df_all['Index'].isin(df_all_train['Index'].values) == False]\n",
    "\n",
    "df_all_test = df_all_dev.sample(frac=0.10, random_state=1)\n",
    "\n",
    "df_all_dev = df_all_dev[df_all_dev['Index'].isin(df_all_test['Index'].values) == False]\n",
    "\n",
    "print (df_all.shape[0], df_all_train.shape[0],  df_all_dev.shape[0], df_all_test.shape[0], len(vocab_dict))\n",
    "\n",
    "train_data = data_formatting.prepare_train_batch(df_all_train['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_train['alpha_Pair_1_encoding'].values)\n",
    "\n",
    "dev_data = data_formatting.prepare_train_batch(df_all_dev['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_dev['alpha_Pair_1_encoding'].values)\n",
    "\n",
    "test_data = data_formatting.prepare_train_batch(df_all_test['alpha_Pair_0_encoding'].values, \n",
    "                                                    df_all_test['alpha_Pair_1_encoding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.variable_scope('training_model'):\n",
    "    \n",
    "    train_model = create_model.Model(train_model_params, 'train', train_data)\n",
    "\n",
    "with tf.variable_scope('training_model', reuse=True):\n",
    "\n",
    "    dev_model = create_model.Model(dev_model_params, 'train', dev_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "starter_learning_rate = tf.placeholder(tf.float32, shape=(), name='starter_learning_rate')\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, \\\n",
    "                                   training_params['n_epochs'], 0.98, staircase=False)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(train_model.loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, global_step:1, learning rate:0.001\n",
      "training minibatch loss:9.72985\n",
      "training minibatch accuracy:0.0120773\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['so', '?', '?', '?', 'hillary', 's', 'mentor', 'senator', 'byrd', 'wa', 'a', 'dragon', 'for', 'kkk', '<EOS>']\n",
      "    dec input           > ['is', 'the', 'picture', 'fake', '?', 'you', 'no', 'is', 'not', 'is', 'a', 'true', 'picture', 'and', 'a', 'fact', '<EOS>']\n",
      "    dec train predicted > ['backpage', 'backpage', 'backpage', 'backpage', 'backpage', 'backpage', '<EOS>', '<EOS>', '<EOS>', '<EOS>', 'backpage', 'trek', '<EOS>', 'suicide', 'swears', 'swears', 'er']\n",
      "dev minibatch loss:9.72967\n",
      "dev minibatch accuracy:0.0136799\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['oh', 'please', 'i', 'm', 'trying', 'to', 'keep', 'up', 'with', 'you', '<EOS>']\n",
      "    dec input           > ['so', 'proud', 'of', 'my', 'friend', 'and', 'amazing', 'journalist', 'for', 'winning', 'an', 'emmy', 'who', 'are', 'you', '?', 'haha', '<EOS>']\n",
      "    dec train predicted > ['erase', 'the', 'incorrect', 'nosy', 'the', 'nosy', 'memo', 'memo', 'memo', 'memo', 'memo', 'hiit', 'hiit', 'stagnant', 'guap', 'stagnant', 'stagnant']\n",
      "Epoch:0 finished, time:2.811\n",
      "Session saved\n",
      "epoch:100, global_step:101, learning rate:0.001\n",
      "training minibatch loss:5.85928\n",
      "training minibatch accuracy:0.174877\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['oh', 'it', 's', 'lit', '<EOS>']\n",
      "    dec input           > ['new', 'chief', 'keef', 'breakfast', 'club', 'interview', '<EOS>']\n",
      "    dec train predicted > ['i', 'i', 'the', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "dev minibatch loss:6.24478\n",
      "dev minibatch accuracy:0.170513\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['th', 'avenue', 'and', 'th', 'a', 'minute', 'ago', '<EOS>']\n",
      "    dec input           > ['where', 'is', 'this', '?', '?', '?', '?', '<EOS>']\n",
      "    dec train predicted > ['i', 'i', 'the', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "Epoch:100 finished, time:1.435\n",
      "epoch:200, global_step:201, learning rate:0.001\n",
      "training minibatch loss:5.94541\n",
      "training minibatch accuracy:0.183463\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['no', 'way', 'he', 'wa', 'hoh', 'twice', 'and', 'did', 'nt', 'put', 'nat', 'up', 'even', 'when', 'paulie', 'told', 'him', 'to', '<EOS>']\n",
      "    dec input           > ['v', 'wanted', 'n', 'out', 'since', 'first', 'buyback', 'n', 'would', 'have', 'been', 'gone', 'pre', 'jury', 'w', 'out', 'j', '<EOS>']\n",
      "    dec train predicted > ['i', 'is', '<EOS>', '<EOS>', '<EOS>', 'the', '<EOS>', '<EOS>', '<EOS>', 'the', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n",
      "dev minibatch loss:6.04608\n",
      "dev minibatch accuracy:0.194149\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['lt', 'you', 'too', '<EOS>']\n",
      "    dec input           > ['that', 's', 'a', 'lot', 'of', 'mistake', '<EOS>']\n",
      "    dec train predicted > ['i', 't', 'the', 'the', '<EOS>', 'the', '<EOS>']\n",
      "Epoch:200 finished, time:1.451\n",
      "epoch:300, global_step:301, learning rate:0.001\n",
      "training minibatch loss:5.43617\n",
      "training minibatch accuracy:0.224185\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['of', 'course', 'lmao', 'i', 'already', 'know', '<EOS>']\n",
      "    dec input           > ['hope', 'you', 'got', 'ta', 'henny', 'bottle', 'with', 'our', 'name', 'on', 'it', 'lmao', '<EOS>']\n",
      "    dec train predicted > ['i', 'i', 'have', 'the', 'the', '<EOS>', '<EOS>', 'the', '<EOS>', '<EOS>', 'the', '<EOS>', '<EOS>']\n",
      "dev minibatch loss:5.79537\n",
      "dev minibatch accuracy:0.20125\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['it', 's', 'worth', 'going', 'back', 'again', 'they', 'put', 'olive', 'oil', 'on', 'it', 'too', 'delicious', '<EOS>']\n",
      "    dec input           > ['didn', 't', 'get', 'the', 'asparagus', 'flavor', '<EOS>']\n",
      "    dec train predicted > ['i', 't', 'have', 'the', 'best', '<EOS>', '<EOS>']\n",
      "Epoch:300 finished, time:1.457\n",
      "epoch:400, global_step:401, learning rate:0.001\n",
      "training minibatch loss:5.70527\n",
      "training minibatch accuracy:0.209536\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['he', 'ha', 'the', 'most', 'apology', 'the', 'best', '<EOS>']\n",
      "    dec input           > ['trump', 'would', 'also', 'win', 'staffer', 'must', 'apologize', 'for', 'what', 'their', 'candidate', 'doe', '<EOS>']\n",
      "    dec train predicted > ['i', 's', 'be', 'a', 'a', 'a', 'be', 'to', 'the', 's', 'debate', '<EOS>', '<EOS>']\n",
      "dev minibatch loss:5.68663\n",
      "dev minibatch accuracy:0.221477\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['fancy', 'shit', 'kicker', 'right', 'there', '<EOS>']\n",
      "    dec input           > ['this', 'is', 'some', 'serious', 'rich', 'people', 'shit', 'here', 'on', 'michigan', 'avenue', '<EOS>']\n",
      "    dec train predicted > ['i', 's', 'the', 'a', '<EOS>', '<EOS>', '<EOS>', '<EOS>', 's', '<EOS>', '<EOS>', '<EOS>']\n",
      "Epoch:400 finished, time:1.428\n",
      "epoch:500, global_step:501, learning rate:0.001\n",
      "training minibatch loss:5.30186\n",
      "training minibatch accuracy:0.233375\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['he', 'really', 'is', 'ugh', 'i', 'miss', 'him', '<EOS>']\n",
      "    dec input           > ['yes', 'and', 'he', 'is', 'so', 'beautiful', '<EOS>']\n",
      "    dec train predicted > ['he', 'you', 'trump', 's', 'a', 'the', '<EOS>']\n",
      "dev minibatch loss:5.39858\n",
      "dev minibatch accuracy:0.231394\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['lmaooo', 'that', 'make', 'two', 'of', 'u', 'baby', 'girl', '<EOS>']\n",
      "    dec input           > ['i', 'm', 'not', 'that', 'ratchet', 'but', 'my', 'phone', 'cracked', 'lol', '<EOS>']\n",
      "    dec train predicted > ['i', 'm', 'sure', 'a', '<EOS>', '<EOS>', 'i', 'birthday', '<EOS>', '<EOS>', '<EOS>']\n",
      "Epoch:500 finished, time:1.44\n",
      "epoch:600, global_step:601, learning rate:0.001\n",
      "training minibatch loss:5.03525\n",
      "training minibatch accuracy:0.249319\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['thanks', 'for', 'this', 'article', 'great', 'read', '<EOS>']\n",
      "    dec input           > ['life', 'changing', 'lesson', 'adventure', 'ha', 'taught', 'me', 'via', '<EOS>']\n",
      "    dec train predicted > ['happy', 'for', 'the', 'of', '<EOS>', 'on', 'you', 'a', '<EOS>']\n",
      "dev minibatch loss:5.59181\n",
      "dev minibatch accuracy:0.258367\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['but', 'not', 'really', 'because', 'woman', 'do', 'it', 'all', 'the', 'tine', '<EOS>']\n",
      "    dec input           > ['if', 'this', 'woman', 'is', 'lying', 'on', 'derrick', 'rose', 'that', 's', 'crazy', '<EOS>']\n",
      "    dec train predicted > ['i', 'you', 'is', 'is', 'the', 'to', 'the', 's', 'than', 's', 'a', 'the']\n",
      "Epoch:600 finished, time:1.44\n",
      "epoch:700, global_step:701, learning rate:0.001\n",
      "training minibatch loss:4.82131\n",
      "training minibatch accuracy:0.24968\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['yea', 'especially', 'since', 'i', 'looked', 'like', 'that', 'nigga', 'tj', '<EOS>']\n",
      "    dec input           > ['this', 'awkward', '<EOS>']\n",
      "    dec train predicted > ['i', 'is', 'is']\n",
      "dev minibatch loss:5.56422\n",
      "dev minibatch accuracy:0.217044\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['you', 'mean', 'ignore', 'the', 'threatening', 'one', 'scumbag', '<EOS>']\n",
      "    dec input           > ['why', 'cant', 'you', 'guy', 'read', 'hadith', 'like', 'these', '?', '<EOS>']\n",
      "    dec train predicted > ['i', 'have', 'you', 'have', 'to', 'the', '<EOS>', 'the', '<EOS>', '<EOS>']\n",
      "Epoch:700 finished, time:1.426\n",
      "epoch:800, global_step:801, learning rate:0.001\n",
      "training minibatch loss:4.55996\n",
      "training minibatch accuracy:0.269693\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['?', '?', '?', 'no', 'way', 'check', 'the', 'poll', '<EOS>']\n",
      "    dec input           > ['who', 'won', 'the', 'debate', '?', 'betting', 'market', 'say', 'clinton', '<EOS>']\n",
      "    dec train predicted > ['i', 's', 'you', 'other', '?', '<EOS>', 'to', 'the', 'you', 's']\n",
      "dev minibatch loss:5.82656\n",
      "dev minibatch accuracy:0.209068\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['i', 'm', 'actually', 'sick', '<EOS>']\n",
      "    dec input           > ['why', 'you', 'faking', 'itlol', '<EOS>']\n",
      "    dec train predicted > ['i', 'do', 'can', '?', 'a']\n",
      "Epoch:800 finished, time:1.436\n",
      "epoch:900, global_step:901, learning rate:0.001\n",
      "training minibatch loss:4.43368\n",
      "training minibatch accuracy:0.264228\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['can', 'you', 'throw', 'some', 'bar', 'one', 'in', 'your', 'carry', 'on', '?', '<EOS>']\n",
      "    dec input           > ['follow', 'me', 'on', 'snapchat', 'a', 'i', 'embark', 'on', 'a', 'hr', 'journey', 'to', 'boston', 'with', 'this', 'injured', 'little', 'thing', '<EOS>']\n",
      "    dec train predicted > ['i', 'the', 'and', 'the', 'i', 'new', 'll', 'to', 'the', '<EOS>', 'board', 'to', 'mar', 'sourced', 'the', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev minibatch loss:5.69666\n",
      "dev minibatch accuracy:0.22486\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['yes', 'they', 'can', 'it', 's', 'happened', 'before', '<EOS>']\n",
      "    dec input           > ['don', 't', 'think', 'both', 'sec', 'on', 'cbs', 'and', 'college', 'gameday', 'can', 'be', 'there', '<EOS>']\n",
      "    dec train predicted > ['i', 't', 'be', 'that', '?', 'endorse', 'the', 'of', 'victim', '<EOS>', '<EOS>', 'you', 'a', '<EOS>']\n",
      "Epoch:900 finished, time:1.44\n",
      "epoch:1000, global_step:1001, learning rate:0.001\n",
      "training minibatch loss:4.20113\n",
      "training minibatch accuracy:0.276301\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['horrible', 'what', 'happened', 'to', 'bochy', '?', 'why', 'would', 'you', 'take', 'madbum', 'out', 'with', 'a', 'hitter', 'and', 'pitch', '<EOS>']\n",
      "    dec input           > ['i', 'literally', 'could', 'not', 'bring', 'myself', 'to', 'watch', 'and', 'thankfully', 'so', '<EOS>']\n",
      "    dec train predicted > ['i', 'm', 'found', 'have', 'a', 'to', 'for', 'see', 'and', 'i', 'and', '<EOS>']\n",
      "dev minibatch loss:6.09836\n",
      "dev minibatch accuracy:0.219608\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['thank', 'you', '<EOS>']\n",
      "    dec input           > ['on', 'greeting', 'from', 'time', 'square', '<EOS>']\n",
      "    dec train predicted > ['happy', 'the', 'birthday', 'the', 'and', 's']\n",
      "Epoch:1000 finished, time:1.414\n",
      "Session saved\n",
      "epoch:1100, global_step:1101, learning rate:0.001\n",
      "training minibatch loss:4.29534\n",
      "training minibatch accuracy:0.295541\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['your', 'gon', 'na', 'be', 'on', 'my', 'couch', 'with', 'an', 'l', 'pun', 'intended', '<EOS>']\n",
      "    dec input           > ['it', 'going', 'to', 'be', 'another', 'l', 'for', 'you', 'amp', 'i', 'hate', 'it', 'had', 'to', 'be', 'you', '<EOS>']\n",
      "    dec train predicted > ['i', 'wa', 'to', 'be', 'in', 'day', '<EOS>', 'the', '<EOS>', 'can', 'm', 'you', '<EOS>', '<EOS>', 'be', 'up', '<EOS>']\n",
      "dev minibatch loss:6.03038\n",
      "dev minibatch accuracy:0.221918\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['no', 'one', 's', 'gon', 'na', 'respect', 'me', 'in', 'the', 'morning', '<EOS>']\n",
      "    dec input           > ['ha', 'everyone', 'lost', 'all', 'respect', 'for', 'me', '<EOS>']\n",
      "    dec train predicted > ['the', 'a', 'like', 'the', 'day', '<EOS>', 'friday', '<EOS>']\n",
      "Epoch:1100 finished, time:1.433\n",
      "epoch:1200, global_step:1201, learning rate:0.001\n",
      "training minibatch loss:3.82918\n",
      "training minibatch accuracy:0.321384\n",
      "Current mode:TRAIN\n",
      "  sample 1:\n",
      "    enc input           > ['whenever', 'they', 'do', 'it', 'for', 'real', 'though', 'oh', 'man', 'oh', 'man', '<EOS>']\n",
      "    dec input           > ['wwe', 'keep', 'teasing', 'u', '<EOS>']\n",
      "    dec train predicted > ['i', 'the', 'on', 'me', '<EOS>']\n",
      "dev minibatch loss:6.61656\n",
      "dev minibatch accuracy:0.187886\n",
      "Current mode:DEV\n",
      "  sample 1:\n",
      "    enc input           > ['me', 'too', 'you', 'should', 'read', 'this', '<EOS>']\n",
      "    dec input           > ['i', 'still', 'get', 'forgot', 'to', 'go', 'to', 'a', 'class', 'all', 'semester', 'dream', '<EOS>']\n",
      "    dec train predicted > ['i', 'm', 'sends', 'to', 'i', 'do', 'to', 'my', 'car', 'car', 'of', '<EOS>', '<EOS>']\n",
      "Epoch:1200 finished, time:1.419\n"
     ]
    }
   ],
   "source": [
    "print_interval = 100\n",
    "save_interval = 1000\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "train_loss = []\n",
    "dev_loss = []\n",
    "\n",
    "train_accuracy = []\n",
    "dev_accuracy = []\n",
    "\n",
    "learning_rate = []\n",
    "\n",
    "with tf.Session() as session:\n",
    "\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    #saver.restore(session, 'chkpt/seq2seq_twitter_test_2-5001')\n",
    "\n",
    "\n",
    "    for epoch in range(training_params['n_epochs']):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        session.run(train_op, feed_dict={'starter_learning_rate:0':lr})\n",
    "        #session.run(train_op)\n",
    "\n",
    "        if epoch % print_interval == 0: \n",
    "\n",
    "            print ('epoch:%d, global_step:%s, learning rate:%.3g' % \n",
    "                       (epoch, tf.train.global_step(session, global_step), \n",
    "                        session.run(optimizer._lr, feed_dict={'starter_learning_rate:0':lr})))\n",
    "\n",
    "            train_minibatch_loss,  train_minibatch_accuracy = session.run([train_model.loss, train_model.accuracy], \n",
    "                                                                          feed_dict={'starter_learning_rate:0':lr})\n",
    "\n",
    "            train_loss.append([tf.train.global_step(session, global_step), train_minibatch_loss])  \n",
    "            train_accuracy.append([tf.train.global_step(session, global_step), train_minibatch_accuracy])  \n",
    "\n",
    "            print ('training minibatch loss:%.6g' % (train_minibatch_loss))\n",
    "            print ('training minibatch accuracy:%.6g' % (train_minibatch_accuracy))\n",
    "\n",
    "            validate(train=True)\n",
    "\n",
    "            dev_model_loss, dev_model_accuracy = session.run([dev_model.loss, dev_model.accuracy])            \n",
    "\n",
    "            print ('dev minibatch loss:%.6g' %  (dev_model_loss))\n",
    "            print ('dev minibatch accuracy:%.6g' %  (dev_model_accuracy))\n",
    "\n",
    "            dev_loss.append([tf.train.global_step(session, global_step), dev_model_loss])\n",
    "\n",
    "            dev_accuracy.append([tf.train.global_step(session, global_step), dev_model_accuracy])\n",
    "\n",
    "            learning_rate.append([tf.train.global_step(session, global_step), \n",
    "                                  session.run(optimizer._lr, feed_dict={'starter_learning_rate:0':lr})])\n",
    "\n",
    "            validate(train=False)\n",
    "\n",
    "            print ('Epoch:%d finished, time:%.4g' % (epoch, time.time() - start_time))\n",
    "\n",
    "        if (epoch % save_interval == 0):# & (epoch!=0): \n",
    "\n",
    "            saver.save(session, '../chkpt/seq2seq_twitter_antilm_precise', global_step = tf.train.global_step(session, global_step))\n",
    "\n",
    "            print ('Session saved')\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import tensor_array_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inf_model_1_params = {'n_cells':256, 'num_layers':2, 'embedding_size':512, \n",
    "          'vocab_size':len(vocab_dict) + 1, 'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':1, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1,\n",
    "         }\n",
    "\n",
    "inf_model_2_params = {'n_cells':256, 'num_layers':2, 'embedding_size':512, \n",
    "          'vocab_size':len(vocab_dict) + 1,\n",
    "          'minibatch_size':64, 'n_threads':128,\n",
    "          'beam_width':2, 'limit_decode_steps': None,\n",
    "          'encoder_input_keep':1, 'decoder_input_keep':1,\n",
    "          'encoder_output_keep':1, 'decoder_output_keep':1, 'anti_lm_weight':0,\n",
    "           'anti_lm_max_step':3\n",
    "         }\n",
    "\n",
    "#with tf.variable_scope('training_model'):\n",
    "\n",
    "#    inf_model_1 = create_model.Model(inf_model_1_params, 'infer', None)\n",
    "    \n",
    "with tf.variable_scope('training_model'):\n",
    "\n",
    "    inf_model_2 = create_model.Model(inf_model_2_params, 'infer', None)   \n",
    "\n",
    "#with tf.variable_scope('training_model'):\n",
    "\n",
    "    #inf_train = create_model.Model(inf_model_2_params, 'debug', None)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['yeah', 'i', 'am', 'what', 'the', 'fuc', '<EOS>']),\n",
       "       list(['good', 'taste', 'also', 'ur', 'location', 'is', 'on', 'are', 'u', 'in', 'ny', 'rn', '?', '?', '<EOS>']),\n",
       "       list([15653, 6178, 7228, 10036, 7441, 8452, 1]),\n",
       "       list([5414, 3593, 16021, 14506, 14758, 9503, 7255, 5123, 14290, 14250, 4970, 15839, 10150, 10150, 1]),\n",
       "       208888], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_train.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(df_all_train.values[0][0], vocab_dict)\n",
    "#input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run(\n",
    "        #inf_train.final_outputs, \n",
    "        inf_model_2.decoder_pred_decode,\n",
    "        feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lmfao', 'matt', 'can', 't', 'figure', 'me', 'this', '<EOS>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_formatting.decodeSent(list(zip(*q_0[0]))[0], inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ list(['lmfao', 'matt', 'can', 't', 'figure', 'me', 'being', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']),\n",
       "        array([-0.30946836, -0.59456718, -1.12294447, -1.54447973, -1.60471201,\n",
       "       -1.72047746, -1.94635522, -3.12297106, -3.81752348, -3.81752348,\n",
       "       -3.81752348, -3.81752348, -3.81752348, -3.81752348, -3.81752348,\n",
       "       -3.81752348, -3.81752348, -3.81752348], dtype=float32)],\n",
       "       [ list(['lmao', 'lt', 'could', 'be', 'back', 'out', 'this', 'lil', 'lil', 'lil', 'rn', 'i', 'kinda', 'know', 'you', 'despise', '<EOS>']),\n",
       "        array([-2.40578365, -2.42967963, -2.79503226, -3.8350358 , -3.99922132,\n",
       "       -4.58851814, -3.67495298, -3.33830309, -4.33860493, -4.62443542,\n",
       "       -4.99635792, -6.18057013, -6.7805233 , -7.7966733 , -7.9359169 ,\n",
       "       -8.63088417, -8.73140526, -9.02580833], dtype=float32)]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[data_formatting.decodeSent(q_0.predicted_ids.T[i][0], inv_map), \n",
    "          q_0.scores.T[i][0]]for i in range(inf_model_2_params['beam_width'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['lmfao', 'i', 'can', 't', 'wait', 'to', 'the', 'hour', 'of',\n",
       "         'tom', '<EOS>', '<EOS>'],\n",
       "        ['-8.885274887084961', '-12.870537757873535', '-16.43918228149414',\n",
       "         '-16.441207885742188', '-17.833393096923828',\n",
       "         '-17.837202072143555', '-18.269447326660156',\n",
       "         '-18.885576248168945', '-19.51644515991211', '-19.57634925842285',\n",
       "         '-20.141868591308594', '-20.141868591308594']],\n",
       "\n",
       "       [['lol', 'i', 'didn', 't', 'figure', 'about', 'die', 'at', 'this',\n",
       "         'birthday', '?', '<EOS>'],\n",
       "        ['-9.484236717224121', '-13.55785846710205', '-17.84384536743164',\n",
       "         '-17.843873977661133', '-17.946748733520508',\n",
       "         '-18.235815048217773', '-18.977397918701172',\n",
       "         '-19.61638069152832', '-20.050893783569336', '-21.70056915283203',\n",
       "         '-21.28431510925293', '-21.285179138183594']]],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[data_formatting.decodeSent(q_0.predicted_ids.T[i][0], inv_map), \n",
    "          q_0.scores.T[i][0]]for i in range(inf_model_2_params['beam_width'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_formatting.decodeSent(q_0.beam_search_decoder_output.predicted_ids.T[0][0], inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape(batch_size, from_shape):\n",
    "    if not isinstance(from_shape, tf.TensorShape):\n",
    "        return tensor_shape.TensorShape(None)\n",
    "    else:\n",
    "        batch_size = tf.contrib.util.constant_value(tf.convert_to_tensor(batch_size, name=\"batch_size\"))\n",
    "        return tf.TensorShape([batch_size]).concatenate(from_shape)\n",
    "\n",
    "def _create_ta(s, d):\n",
    "    return tf.TensorArray(\n",
    "        dtype=d, size=0, dynamic_size=True, element_shape=_shape(batch_size, s)\n",
    "        , clear_after_read=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tf.constant(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = inf_model_2.inference_decoder._batch_size\n",
    "beam_width = inf_model_2.inference_decoder._beam_width\n",
    "end_token = inf_model_2.inference_decoder._end_token\n",
    "length_penalty_weight = inf_model_2.inference_decoder._length_penalty_weight\n",
    "n_grams = pickle.load(open('n_grams_test.pkl', 'rb'))\n",
    "vocab_size = inf_model_2_params['vocab_size']\n",
    "beam_width = inf_model_2_params['beam_width']\n",
    "\n",
    "name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_inputs\n",
    "#These are the word embeddings of the initial token (which for initialize should be from the encoder?)\n",
    "#Shape is [batch_size, embedding_size]\n",
    "#initial_state\n",
    "#This is the initial state of the decoder, a tuple consisting of \n",
    "#1. the LSTM cell and hiddens states\n",
    "#2. The attention states\n",
    "\n",
    "initial_finished, first_inputs, initial_state = inf_model_2.inference_decoder.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_outputs_ta = nest.map_structure(_create_ta, inf_model_2.inference_decoder.output_size,\n",
    "                                                        inf_model_2.inference_decoder.output_dtype)\n",
    "\n",
    "initial_sequence_lengths = tf.zeros_like(initial_finished, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we pass time !=0 to inference decoder, even with initial step results we get non-zero parent ids\n",
    "\n",
    "#beam_search_output, beam_search_state, next_inputs, finished = \\\n",
    "#                                                inf_model_2.inference_decoder.step(time, first_inputs, initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ops.name_scope(name, \"BeamSearchDecoderStep\", (time, first_inputs, initial_state)):\n",
    "    \n",
    "cell_state = initial_state.cell_state\n",
    "\n",
    "first_inputs = nest.map_structure(lambda inp: inf_model_2.inference_decoder._merge_batch_beams(inp, s=inp.shape[2:]), \n",
    "                                  first_inputs)\n",
    "\n",
    "cell_state = nest.map_structure(inf_model_2.inference_decoder._maybe_merge_batch_beams, cell_state, \n",
    "                                inf_model_2.inference_decoder._cell.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This goes through _cell first\n",
    "#The output of cell_outputs is also present in the next_cell_state, the cell_outputs is the attention\n",
    "\n",
    "#The cell_state includes, the cell and hidden states of the LSTM, the attention states, the alignment history, and timestep, \n",
    "#what does alignment history and attention states really mean? need to internalize...\n",
    "\n",
    "cell_outputs, next_cell_state = inf_model_2.inference_decoder._cell(first_inputs, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions convert the shape of the cell outputs and states from [batch_size, beam_width, embedding_size]\n",
    "#to [batch_size*beam_width, embedding_size], essentially, reducing a dimensionality by flattening the nested structure\n",
    "#the map structure fn is used because cell state is a complex tuple structure, \n",
    "#outputs is a simpe structure (should be able to just call flatten?)\n",
    "cell_outputs = nest.map_structure(lambda out: inf_model_2.inference_decoder._split_batch_beams(out, out.shape[1:]), \n",
    "                                  cell_outputs)\n",
    "\n",
    "next_cell_state = nest.map_structure(inf_model_2.inference_decoder._maybe_split_batch_beams, next_cell_state, \n",
    "                                     inf_model_2.inference_decoder._cell.state_size)\n",
    "\n",
    "#This is a dense layer that takes the cell output with dimension [beam_width, number of cells] to\n",
    "#[beam_width, vocab_size]\n",
    "\n",
    "if inf_model_2.inference_decoder._output_layer is not None:\n",
    "    cell_outputs = inf_model_2.inference_decoder._output_layer(cell_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell_outputs_rnn_call, next_cell_state_rnn_call = inf_model_2.inference_decoder._cell.call(first_inputs, cell_state)\n",
    "\n",
    "#cell_outputs_rnn_call_call, next_cell_state_rnn_call_call = inf_model_2.inference_decoder._cell.call(cell_outputs_rnn_call, \n",
    "#                                                                                                     next_cell_state_rnn_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_batch_size = tensor_util.constant_value(batch_size)\n",
    "\n",
    "prediction_lengths = initial_state.lengths\n",
    "previously_finished = initial_state.finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_token = data_formatting.EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _length_penalty(sequence_lengths, penalty_factor):\n",
    "  \"\"\"Calculates the length penalty. See https://arxiv.org/abs/1609.08144.\n",
    "  Args:\n",
    "    sequence_lengths: The sequence length of all hypotheses, a tensor\n",
    "      of shape [beam_size, vocab_size].\n",
    "    penalty_factor: A scalar that weights the length penalty.\n",
    "  Returns:\n",
    "    The length penalty factor, a tensor fo shape [beam_size].\n",
    "  \"\"\"\n",
    "  penalty_factor = ops.convert_to_tensor(penalty_factor, name=\"penalty_factor\")\n",
    "  penalty_factor.set_shape(())  # penalty should be a scalar.\n",
    "  static_penalty = tensor_util.constant_value(penalty_factor)\n",
    "  if static_penalty is not None and static_penalty == 0:\n",
    "    return 1.0\n",
    "  return math_ops.div((5. + math_ops.to_float(sequence_lengths))\n",
    "                      **penalty_factor, (5. + 1.)**penalty_factor)\n",
    "\n",
    "def _check_maybe(t):\n",
    "  if isinstance(t, tensor_array_ops.TensorArray):\n",
    "    raise TypeError(\n",
    "        \"TensorArray state is not supported by BeamSearchDecoder: %s\" % t.name)\n",
    "  if t.shape.ndims is None:\n",
    "    raise ValueError(\n",
    "        \"Expected tensor (%s) to have known rank, but ndims == None.\" % t)\n",
    "\n",
    "def _maybe_tensor_gather_helper(gather_indices, gather_from, batch_size,\n",
    "                                range_size, gather_shape):\n",
    "  \"\"\"Maybe applies _tensor_gather_helper.\n",
    "  This applies _tensor_gather_helper when the gather_from dims is at least as\n",
    "  big as the length of gather_shape. This is used in conjunction with nest so\n",
    "  that we don't apply _tensor_gather_helper to inapplicable values like scalars.\n",
    "  Args:\n",
    "    gather_indices: The tensor indices that we use to gather.\n",
    "    gather_from: The tensor that we are gathering from.\n",
    "    batch_size: The batch size.\n",
    "    range_size: The number of values in each range. Likely equal to beam_width.\n",
    "    gather_shape: What we should reshape gather_from to in order to preserve the\n",
    "      correct values. An example is when gather_from is the attention from an\n",
    "      AttentionWrapperState with shape [batch_size, beam_width, attention_size].\n",
    "      There, we want to preserve the attention_size elements, so gather_shape is\n",
    "      [batch_size * beam_width, -1]. Then, upon reshape, we still have the\n",
    "      attention_size as desired.\n",
    "  Returns:\n",
    "    output: Gathered tensor of shape tf.shape(gather_from)[:1+len(gather_shape)]\n",
    "      or the original tensor if its dimensions are too small.\n",
    "  \"\"\"\n",
    "  _check_maybe(gather_from)\n",
    "  if gather_from.shape.ndims >= len(gather_shape):\n",
    "    return _tensor_gather_helper(\n",
    "        gather_indices=gather_indices,\n",
    "        gather_from=gather_from,\n",
    "        batch_size=batch_size,\n",
    "        range_size=range_size,\n",
    "        gather_shape=gather_shape)\n",
    "  else:\n",
    "    return gather_from\n",
    "\n",
    "def _tensor_gather_helper(gather_indices, gather_from, batch_size,\n",
    "                          range_size, gather_shape):\n",
    "  \"\"\"Helper for gathering the right indices from the tensor.\n",
    "  This works by reshaping gather_from to gather_shape (e.g. [-1]) and then\n",
    "  gathering from that according to the gather_indices, which are offset by\n",
    "  the right amounts in order to preserve the batch order.\n",
    "  Args:\n",
    "    gather_indices: The tensor indices that we use to gather.\n",
    "    gather_from: The tensor that we are gathering from.\n",
    "    batch_size: The input batch size.\n",
    "    range_size: The number of values in each range. Likely equal to beam_width.\n",
    "    gather_shape: What we should reshape gather_from to in order to preserve the\n",
    "      correct values. An example is when gather_from is the attention from an\n",
    "      AttentionWrapperState with shape [batch_size, beam_width, attention_size].\n",
    "      There, we want to preserve the attention_size elements, so gather_shape is\n",
    "      [batch_size * beam_width, -1]. Then, upon reshape, we still have the\n",
    "      attention_size as desired.\n",
    "  Returns:\n",
    "    output: Gathered tensor of shape tf.shape(gather_from)[:1+len(gather_shape)]\n",
    "  \"\"\"\n",
    "  range_ = array_ops.expand_dims(math_ops.range(batch_size) * range_size, 1)\n",
    "  gather_indices = array_ops.reshape(gather_indices + range_, [-1])\n",
    "  output = array_ops.gather(\n",
    "      array_ops.reshape(gather_from, gather_shape), gather_indices)\n",
    "  final_shape = array_ops.shape(gather_from)[:1 + len(gather_shape)]\n",
    "  static_batch_size = tensor_util.constant_value(batch_size)\n",
    "  final_static_shape = (tensor_shape.TensorShape([static_batch_size])\n",
    "                        .concatenate(\n",
    "                            gather_from.shape[1:1 + len(gather_shape)]))\n",
    "  output = array_ops.reshape(output, final_shape)\n",
    "  output.set_shape(final_static_shape)\n",
    "  return output\n",
    "#Have to understand how this works!\n",
    "def _mask_probs(probs, eos_token, finished):\n",
    "  \"\"\"Masks log probabilities.\n",
    "  The result is that finished beams allocate all probability mass to eos and\n",
    "  unfinished beams remain unchanged.\n",
    "  Args:\n",
    "    probs: Log probabiltiies of shape `[batch_size, beam_width, vocab_size]`\n",
    "    eos_token: An int32 id corresponding to the EOS token to allocate\n",
    "      probability to.\n",
    "    finished: A boolean tensor of shape `[batch_size, beam_width]` that\n",
    "      specifies which\n",
    "      elements in the beam are finished already.\n",
    "  Returns:\n",
    "    A tensor of shape `[batch_size, beam_width, vocab_size]`, where unfinished\n",
    "    beams stay unchanged and finished beams are replaced with a tensor with all\n",
    "    probability on the EOS token.\n",
    "  \"\"\"\n",
    "  vocab_size = array_ops.shape(probs)[2]\n",
    "  finished_mask = array_ops.expand_dims(\n",
    "      math_ops.to_float(1. - math_ops.to_float(finished)), 2)\n",
    "  # These examples are not finished and we leave them\n",
    "  non_finished_examples = finished_mask * probs\n",
    "  # All finished examples are replaced with a vector that has all\n",
    "  # probability on EOS\n",
    "  finished_row = array_ops.one_hot(\n",
    "      eos_token,\n",
    "      vocab_size,\n",
    "      dtype=probs.dtype,\n",
    "      on_value=0.,\n",
    "      off_value=probs.dtype.min)\n",
    "  finished_examples = (1. - finished_mask) * finished_row\n",
    "  return finished_examples + non_finished_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = cell_outputs\n",
    "step_log_probs = nn_ops.log_softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_log_probs = _mask_probs(step_log_probs, end_token, previously_finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_probs = array_ops.expand_dims(initial_state.log_probs, 2) + step_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = logits.shape[-1].value or array_ops.shape(logits)[-1]\n",
    "\n",
    "lengths_to_add = array_ops.one_hot(\n",
    "      indices=array_ops.tile(\n",
    "          array_ops.reshape(end_token, [1, 1]), [batch_size, beam_width]),\n",
    "      depth=vocab_size,\n",
    "      on_value=0,\n",
    "      off_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_lm_body(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    #This loops on each beam individually\n",
    "      \n",
    "    def grab_probs(n_grams_tf, y_equal_2): \n",
    "    \n",
    "        #print ('Grab Probabilities')\n",
    "        y_args = tf.where(y_equal_2)\n",
    "\n",
    "        #Grab the n_gram sequences that are matched\n",
    "        y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "        #Take the last token in each sequence and count their unique occurrences\n",
    "\n",
    "        last_token_pos = tf.shape(y_diff_gather)[-1]\n",
    "\n",
    "        y_last_token = y_diff_gather[:,0][:,last_token_pos-1]\n",
    "        y_last_token_unique = tf.unique_with_counts(y_last_token)\n",
    "\n",
    "        total_count = tf.reduce_sum(y_last_token_unique.count)\n",
    "\n",
    "        indices = tf.reshape(y_last_token_unique.y, [tf.shape(y_last_token_unique.y)[0], 1])\n",
    "\n",
    "        test_add_result = tf.scatter_nd(indices=indices, \n",
    "                    updates=y_last_token_unique.count, shape=scatter_base)/total_count\n",
    "\n",
    "        test_add_result = tf.log(test_add_result + 10e-10)\n",
    "\n",
    "        return tf.reshape(test_add_result, [1, vocab_size])\n",
    "\n",
    "    def dump_zeros(n_grams_tf, y_equal_2): \n",
    "        #print ('No matches found')\n",
    "        return tf.constant([[0. for i in range(vocab_size)]], dtype=tf.float64)\n",
    "    \n",
    "    scatter_base = tf.constant([vocab_size]) #Size of dict for scatter base will specify at run time\n",
    "\n",
    "    #Find where current beam matches n_gram sequence up to current seq pos, cast as int\n",
    "    y_test = tf.to_int32(tf.equal(n_grams_tf, beam_pad[current_beam]))\n",
    "    #Reduce across the length of the beam \n",
    "    y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n",
    "\n",
    "    y_empty = tf.reduce_sum(y_test_reduce_sum)\n",
    "\n",
    "    #Find args where the beam is matched to the n_gram combinations\n",
    "    y_equal_2  = tf.equal(time, y_test_reduce_sum)\n",
    "\n",
    "    #Why does cond proceed down both paths? okay, understand this now...\n",
    "    test_add = tf.cond(tf.equal(0, tf.reduce_sum(tf.to_int32(y_equal_2))),\n",
    "        true_fn=lambda: dump_zeros(n_grams_tf, y_equal_2),\n",
    "        false_fn=lambda : grab_probs(n_grams_tf, y_equal_2))\n",
    "\n",
    "    test = tf.concat([test, test_add], axis=0)\n",
    "    \n",
    "    return test, n_grams_tf, beam_pad, current_beam+1, n_beams\n",
    "\n",
    "def anti_lm_condition(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    return current_beam < n_beams #number of beams, i.e. beam width, will specify at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_scores(log_probs, sequence_lengths, length_penalty_weight, time):\n",
    "    \"\"\"Calculates scores for beam search hypotheses.\n",
    "    Args:\n",
    "    log_probs: The log probabilities with shape\n",
    "    `[batch_size, beam_width, vocab_size]`.\n",
    "    sequence_lengths: The array of sequence lengths.\n",
    "    length_penalty_weight: Float weight to penalize length. Disabled with 0.0.\n",
    "    Returns:\n",
    "    The scores normalized by the length_penalty.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fn1(): return tf.constant(n_grams[1])\n",
    "    def fn2(): return tf.constant(n_grams[2])\n",
    "    def fn3(): return tf.constant(n_grams[3])\n",
    "    def fn_default(): return tf.constant(-1)\n",
    "        \n",
    "    def time_zero_anti_lm(score):\n",
    "        n_grams_tf = tf.constant(n_grams[0])\n",
    "        scatter_base = tf.constant([vocab_size]) #Size of dict for scatter base will specify at run time\n",
    "\n",
    "        y_unique_with_counts = tf.unique_with_counts(tf.reshape(n_grams_tf, [1, tf.shape(n_grams_tf)[0]])[0])\n",
    "\n",
    "        total_count = tf.reduce_sum(y_unique_with_counts.count)\n",
    "        \n",
    "        indices = tf.reshape(y_unique_with_counts.y, [tf.shape(y_unique_with_counts.y)[0], 1])\n",
    "\n",
    "        test_add = tf.scatter_nd(indices=indices, \n",
    "                    updates=y_unique_with_counts.count, shape=scatter_base)/total_count\n",
    "\n",
    "        #Add small value for numerically stability\n",
    "        test_add = tf.log(test_add + 10e-10)    \n",
    "\n",
    "        test_add_tile = tf.reshape(tf.tile(test_add, multiples=[beam_width]), shape=[1, beam_width, vocab_size])\n",
    "        \n",
    "        score = score + tf.to_float(test_add_tile)\n",
    "        \n",
    "        return score, n_grams_tf\n",
    "    \n",
    "    def time_not_zero_anti_lm(score):\n",
    "        #No anti-lm correction past 4th sequence position\n",
    "        n_grams_tf = tf.case({tf.equal(time,1): fn1, \n",
    "                     tf.equal(time,2): fn2,\n",
    "                     tf.equal(time,3): fn3}, default=fn_default, exclusive=True)\n",
    "\n",
    "        #When you specify the axis of concat such a rank must exist! \n",
    "        #Thus cannot specify axis=1 if the rank is 0!\n",
    "\n",
    "        concat_base = tf.constant([[1.0 for i in range(vocab_size)]], dtype=tf.float64) #concat base will specify vocab size at run time\n",
    "\n",
    "        beam = tf.transpose(initial_outputs_ta.predicted_ids.concat())\n",
    "\n",
    "        beam_pad = tf.pad(beam, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "        initial_beam_step = tf.constant(0)  #This starting the loop from the first beam\n",
    "\n",
    "        n_beams = tf.constant(beam_width) #will specify at run time\n",
    "        \n",
    "        anti_lm_outputs = tf.while_loop(anti_lm_condition, anti_lm_body, \n",
    "                        [concat_base, n_grams_tf, beam_pad, initial_beam_step, n_beams], \n",
    "                        shape_invariants=[tf.TensorShape([None, vocab_size]), \n",
    "                                          n_grams_tf.get_shape(),\n",
    "                                      beam_pad.get_shape(), initial_beam_step.get_shape(), n_beams.get_shape()])\n",
    "\n",
    "        anti_beam_probs = anti_lm_outputs[0][1:]\n",
    "        score = score + tf.to_float(anti_beam_probs)\n",
    "        \n",
    "        return score, n_grams_tf\n",
    "    \n",
    "    length_penality_ = tf_helpers._length_penalty(sequence_lengths=sequence_lengths, penalty_factor=length_penalty_weight)\n",
    "\n",
    "    score = log_probs/length_penality_\n",
    "    \n",
    "    score, n_grams_tf = tf.cond(tf.equal(0, time), \n",
    "                                lambda : time_zero_anti_lm(score), lambda: time_not_zero_anti_lm(score))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_mask = (1 - math_ops.to_int32(previously_finished))\n",
    "\n",
    "lengths_to_add = array_ops.expand_dims(add_mask, 2) * lengths_to_add\n",
    "\n",
    "new_prediction_lengths = (lengths_to_add + array_ops.expand_dims(prediction_lengths, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_total_probs(total_probs):\n",
    "    return total_probs\n",
    "\n",
    "scores = tf.cond(time < 4, \n",
    "                 true_fn=lambda: _get_scores(log_probs=total_probs,\n",
    "                 sequence_lengths=new_prediction_lengths, length_penalty_weight=0.5, time=time), \n",
    "                 false_fn=lambda: score_total_probs(total_probs) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([scores], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = total_probs + p_T\n",
    "scores_x = _get_scores(log_probs=total_probs,\n",
    "                         sequence_lengths=new_prediction_lengths,\n",
    "                          length_penalty_weight=0, time=time)\n",
    "scores_y = total_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_shape = array_ops.shape(scores)\n",
    "\n",
    "time = ops.convert_to_tensor(time, name=\"time\")\n",
    "\n",
    "scores_flat = control_flow_ops.cond(time > 0,\n",
    "      lambda: array_ops.reshape(scores, [batch_size, -1]), lambda: scores[:, 0])\n",
    "\n",
    "num_available_beam = control_flow_ops.cond(\n",
    "      time > 0, lambda: math_ops.reduce_prod(scores_shape[1:]),\n",
    "      lambda: math_ops.reduce_prod(scores_shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the next beams according to the specified successors function\n",
    "next_beam_size = math_ops.minimum(\n",
    "  ops.convert_to_tensor(beam_width, dtype=dtypes.int32, name=\"beam_width\"),\n",
    "  num_available_beam)\n",
    "\n",
    "next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=next_beam_size)\n",
    "next_beam_scores.set_shape([static_batch_size, beam_width])\n",
    "word_indices.set_shape([static_batch_size, beam_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_beam_probs = _tensor_gather_helper(\n",
    "      gather_indices=word_indices,\n",
    "      gather_from=scores,\n",
    "      batch_size=batch_size,\n",
    "      range_size=beam_width * vocab_size,\n",
    "      gather_shape=[-1])\n",
    "\n",
    "#Here, word indices represents the positions of the flattened list of beams, which goes from 1 to beam_width*vocab_size\n",
    "#thus the word indices obtained are not the word indices of the 1 to N vocab but the flattened out list of logprobs from 1 to \n",
    "#beam_width*vocab_size\n",
    "next_word_ids = math_ops.to_int32(word_indices % vocab_size)\n",
    "#The beam_ids represent which beams these word indices (and thereby log prob values belong to), as\n",
    "#we have word indices extracted out of 1 to beam_width*vocab_size\n",
    "next_beam_ids = math_ops.to_int32(word_indices / vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Invalid reduction dimension (1 for input with 1 dimension(s)\n\t [[Node: cond_1/while/Sum = Sum[T=DT_INT32, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](cond_1/while/ToInt32/_185, cond_1/while/Sum/reduction_indices)]]\n\t [[Node: training_model/BahdanauAttention/strided_slice_3/_305 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_827_training_model/BahdanauAttention/strided_slice_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'cond_1/while/Sum', defined at:\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-2f7f8324f347>\", line 4, in <module>\n    length_penalty_weight=0, time=time)\n  File \"<ipython-input-30-e5b85335f7be>\", line 74, in _get_scores\n    lambda : time_zero_anti_lm(score), lambda: time_not_zero_anti_lm(score))\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 296, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1828, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1694, in BuildCondBranch\n    original_result = fn()\n  File \"<ipython-input-30-e5b85335f7be>\", line 74, in <lambda>\n    lambda : time_zero_anti_lm(score), lambda: time_not_zero_anti_lm(score))\n  File \"<ipython-input-30-e5b85335f7be>\", line 62, in time_not_zero_anti_lm\n    beam_pad.get_shape(), initial_beam_step.get_shape(), n_beams.get_shape()])\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2775, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2604, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2554, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"<ipython-input-29-cba09930f497>\", line 38, in anti_lm_body\n    y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\n    name=name)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\n    keep_dims=keep_dims, name=name)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Invalid reduction dimension (1 for input with 1 dimension(s)\n\t [[Node: cond_1/while/Sum = Sum[T=DT_INT32, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](cond_1/while/ToInt32/_185, cond_1/while/Sum/reduction_indices)]]\n\t [[Node: training_model/BahdanauAttention/strided_slice_3/_305 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_827_training_model/BahdanauAttention/strided_slice_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension (1 for input with 1 dimension(s)\n\t [[Node: cond_1/while/Sum = Sum[T=DT_INT32, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](cond_1/while/ToInt32/_185, cond_1/while/Sum/reduction_indices)]]\n\t [[Node: training_model/BahdanauAttention/strided_slice_3/_305 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_827_training_model/BahdanauAttention/strided_slice_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-98408044d66c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                     word_indices, next_beam_size], \n\u001b[0;32m     10\u001b[0m                  feed_dict={'training_model/encoder_inputs:0':[input_user], \n\u001b[1;32m---> 11\u001b[1;33m                          'training_model/encoder_inputs_length:0':[len(input_user)]})\n\u001b[0m",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Invalid reduction dimension (1 for input with 1 dimension(s)\n\t [[Node: cond_1/while/Sum = Sum[T=DT_INT32, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](cond_1/while/ToInt32/_185, cond_1/while/Sum/reduction_indices)]]\n\t [[Node: training_model/BahdanauAttention/strided_slice_3/_305 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_827_training_model/BahdanauAttention/strided_slice_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'cond_1/while/Sum', defined at:\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-2f7f8324f347>\", line 4, in <module>\n    length_penalty_weight=0, time=time)\n  File \"<ipython-input-30-e5b85335f7be>\", line 74, in _get_scores\n    lambda : time_zero_anti_lm(score), lambda: time_not_zero_anti_lm(score))\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 296, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1828, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 1694, in BuildCondBranch\n    original_result = fn()\n  File \"<ipython-input-30-e5b85335f7be>\", line 74, in <lambda>\n    lambda : time_zero_anti_lm(score), lambda: time_not_zero_anti_lm(score))\n  File \"<ipython-input-30-e5b85335f7be>\", line 62, in time_not_zero_anti_lm\n    beam_pad.get_shape(), initial_beam_step.get_shape(), n_beams.get_shape()])\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2775, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2604, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 2554, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"<ipython-input-29-cba09930f497>\", line 38, in anti_lm_body\n    y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1278, in reduce_sum\n    name=name)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2656, in _sum\n    keep_dims=keep_dims, name=name)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Invalid reduction dimension (1 for input with 1 dimension(s)\n\t [[Node: cond_1/while/Sum = Sum[T=DT_INT32, Tidx=DT_INT32, keep_dims=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](cond_1/while/ToInt32/_185, cond_1/while/Sum/reduction_indices)]]\n\t [[Node: training_model/BahdanauAttention/strided_slice_3/_305 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_827_training_model/BahdanauAttention/strided_slice_3\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "input_user = data_formatting.encodeSent(['i', 'll', 'be', 'there', 'tomorrow', '<EOS>'], vocab_dict)\n",
    "with tf.Session() as sess:\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    #tf.set_random_seed(1)\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_0 = sess.run([next_word_ids, next_beam_ids, scores, scores_flat, next_beam_scores, next_beam_probs,\n",
    "                    word_indices, next_beam_size], \n",
    "                 feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "previously_finished = _tensor_gather_helper(\n",
    "      gather_indices=next_beam_ids,\n",
    "      gather_from=previously_finished,\n",
    "      batch_size=batch_size,\n",
    "      range_size=beam_width,\n",
    "      gather_shape=[-1])\n",
    "\n",
    "next_finished = math_ops.logical_or(previously_finished, math_ops.equal(next_word_ids, end_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_to_add = math_ops.to_int32(math_ops.not_equal(next_word_ids, end_token))\n",
    "lengths_to_add = (1 - math_ops.to_int32(next_finished)) * lengths_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_prediction_len = _tensor_gather_helper(\n",
    "      gather_indices=next_beam_ids,\n",
    "      gather_from=initial_state.lengths,\n",
    "      batch_size=batch_size,\n",
    "      range_size=beam_width,\n",
    "      gather_shape=[-1])\n",
    "\n",
    "next_prediction_len += lengths_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_cell_state = nest.map_structure(\n",
    "      lambda gather_from: _maybe_tensor_gather_helper(\n",
    "          gather_indices=next_beam_ids,\n",
    "          gather_from=gather_from,\n",
    "          batch_size=batch_size,\n",
    "          range_size=beam_width,\n",
    "          gather_shape=[batch_size * beam_width, -1]),\n",
    "      next_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../chkpt/seq2seq_twitter_testing-5501\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "   \n",
    "    saver.restore(sess, '../chkpt/seq2seq_twitter_testing-5501')\n",
    "    q_1 = sess.run([next_cell_state],\n",
    "                     feed_dict={'training_model/encoder_inputs:0':[input_user], \n",
    "                         'training_model/encoder_inputs_length:0':[len(input_user)]})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LSTMStateTuple(c=array([[[-0.36518568,  0.15221889,  1.43084002,  1.26691902,  0.97570741,\n",
       "         -1.65228498,  0.2762605 ,  0.70097274, -0.82302231, -0.39878359,\n",
       "         -0.47339875,  0.56113648,  1.45701504, -0.58288693,  0.2458801 ,\n",
       "          0.45721632,  1.06034863, -0.53341776,  0.84067792, -2.14312649,\n",
       "         -0.3462446 , -2.72415495, -0.09161211,  1.36289251, -0.41485611,\n",
       "         -0.77971447, -1.01373613, -0.1626246 , -0.42198175,  0.79769164,\n",
       "         -1.44223773, -0.12655784, -1.03397453, -0.45727509,  0.49624717,\n",
       "         -0.71556503, -0.1682298 , -0.59325242, -0.70525527, -1.19461775,\n",
       "         -0.71584553,  0.53623444, -0.3736887 ,  1.55030262,  1.60065281,\n",
       "          0.76959068, -0.15846567, -1.26996934, -0.51451391,  3.21015644,\n",
       "          0.56469333, -0.01150133, -0.63608539,  1.63232625,  0.79776645,\n",
       "         -1.23871732,  1.50188172, -2.6774683 , -0.78931975,  2.26646423,\n",
       "         -0.78553116, -0.80997407, -2.48717618,  0.68119168,  0.8132056 ,\n",
       "         -1.28822863, -2.88833523,  0.83390176,  0.81359005, -3.02969098,\n",
       "         -1.45608449,  0.73327887,  0.46216714, -1.21760285, -0.88643456,\n",
       "         -0.16009162, -0.05131016, -1.2398665 ,  1.26644671, -1.85426843,\n",
       "         -0.48938414, -1.80787313, -0.96174258,  0.06884354,  0.86313117,\n",
       "         -0.76070666,  0.23424664, -1.3372674 ,  1.13816643, -2.40523314,\n",
       "         -0.24595876, -1.66424239,  2.50199819, -1.05133498,  0.23005067,\n",
       "          0.58664685, -0.12653551, -1.44397938,  0.63974887,  0.59677935,\n",
       "          0.99322683,  0.73863834,  0.83573169,  0.6846534 , -0.60061622,\n",
       "          1.30651975,  0.96681696, -0.28715456,  0.4871031 ,  0.4615131 ,\n",
       "          1.20956671, -0.3524448 , -0.69220591,  0.51897836,  1.35255611,\n",
       "          1.18860102,  0.59409761, -0.44446456,  0.57377261,  1.07380784,\n",
       "         -0.5396173 ,  1.29594088, -1.64649999,  0.01832975, -0.54834509,\n",
       "         -0.97932547, -0.5084886 ,  1.26888013,  0.67323208,  1.23540676,\n",
       "         -1.35237968, -2.55779409,  0.04607544,  2.3447082 ,  3.09416747,\n",
       "          0.56896818,  0.86122769, -1.60043681, -2.14458013,  1.97490084,\n",
       "          0.03745326, -0.39925012, -0.80294549, -2.0629313 , -0.46313852,\n",
       "         -0.49812478,  0.68334311,  0.00655386, -0.77015394, -1.23381484,\n",
       "          1.01175678, -0.36246684,  0.52225554,  1.24580204, -1.46016181,\n",
       "          0.04937675,  0.70928645, -0.20652056,  2.17807913, -1.68953943,\n",
       "         -0.86724073,  1.87069964, -0.85359269,  3.07351708, -0.03299142,\n",
       "         -0.04739387,  0.21676657,  1.4390732 , -2.37568784,  0.32569155,\n",
       "         -0.81851864,  1.61703956,  0.21590379,  0.60416704, -2.07363892,\n",
       "          0.8355087 , -0.43277776, -2.88542151, -0.55715644, -0.56335068,\n",
       "          1.95831561,  1.28196001, -0.526721  , -1.96805036, -0.46565181,\n",
       "          0.06379982,  0.45799738, -0.08458561,  0.78623831,  0.21500267,\n",
       "         -0.23961999,  1.01931572,  0.95593464, -0.29365852,  2.86096334,\n",
       "         -1.77160883,  0.37693226, -0.31364751,  1.65181804, -1.28376651,\n",
       "         -1.1035316 , -3.20644689,  1.76025105, -0.8092041 ,  2.38129473,\n",
       "         -0.47894984,  0.50409406, -1.49359727, -1.08082211, -0.75100583,\n",
       "          1.62493849,  0.69335008, -0.73280334, -0.32057393,  0.84868354,\n",
       "         -1.15941226, -0.3370946 , -0.57790774, -0.86461353,  0.11845934,\n",
       "         -1.36979568,  0.82500368, -1.25845003, -0.95406049,  0.41481182,\n",
       "          3.16715813, -0.544918  , -0.93068439, -0.18395753, -0.41275263,\n",
       "         -0.37137023, -0.41223958,  0.16171619,  0.53642803,  0.9791106 ,\n",
       "          0.89049894,  0.62282807,  0.17264558,  0.90789205,  0.2433041 ,\n",
       "          0.38073772,  3.14931154, -0.3775062 , -0.1477332 , -0.5181396 ,\n",
       "          0.62846172, -0.36489281, -0.21416543,  1.93022835,  1.24246371,\n",
       "          2.09657168, -1.58406627,  1.11383212,  1.39228344, -0.3793326 ,\n",
       "          0.99690652],\n",
       "        [-0.36518583,  0.15221891,  1.43084013,  1.26691902,  0.97570729,\n",
       "         -1.65228498,  0.2762605 ,  0.70097274, -0.82302231, -0.39878359,\n",
       "         -0.47339875,  0.56113666,  1.45701504, -0.58288693,  0.2458801 ,\n",
       "          0.45721626,  1.06034839, -0.53341776,  0.84067792, -2.14312649,\n",
       "         -0.34624466, -2.72415495, -0.09161211,  1.36289263, -0.41485608,\n",
       "         -0.77971435, -1.01373613, -0.1626246 , -0.42198175,  0.79769164,\n",
       "         -1.44223714, -0.12655804, -1.03397441, -0.45727509,  0.49624717,\n",
       "         -0.7155652 , -0.16822985, -0.59325242, -0.70525551, -1.19461775,\n",
       "         -0.71584541,  0.53623444, -0.37368858,  1.55030239,  1.60065269,\n",
       "          0.76959068, -0.15846564, -1.26996934, -0.51451391,  3.21015644,\n",
       "          0.56469333, -0.01150132, -0.63608527,  1.63232613,  0.79776651,\n",
       "         -1.23871744,  1.50188148, -2.67746758, -0.78931969,  2.26646423,\n",
       "         -0.78553128, -0.80997401, -2.48717594,  0.6811915 ,  0.8132056 ,\n",
       "         -1.28822851, -2.88833499,  0.83390182,  0.81359005, -3.02969098,\n",
       "         -1.45608449,  0.73327893,  0.46216714, -1.21760261, -0.88643456,\n",
       "         -0.16009168, -0.05131011, -1.2398665 ,  1.26644659, -1.85426843,\n",
       "         -0.48938414, -1.80787313, -0.96174258,  0.06884356,  0.86313117,\n",
       "         -0.76070642,  0.23424679, -1.33726752,  1.13816643, -2.40523314,\n",
       "         -0.24595876, -1.66424239,  2.50199819, -1.05133498,  0.23005064,\n",
       "          0.5866468 , -0.12653553, -1.44397938,  0.63974893,  0.59677935,\n",
       "          0.99322695,  0.73863834,  0.83573169,  0.6846534 , -0.60061586,\n",
       "          1.30651951,  0.96681696, -0.28715456,  0.48710316,  0.4615131 ,\n",
       "          1.20956695, -0.35244471, -0.69220591,  0.5189783 ,  1.35255587,\n",
       "          1.1886009 ,  0.59409779, -0.4444645 ,  0.57377249,  1.07380784,\n",
       "         -0.5396173 ,  1.29594088, -1.64649999,  0.01832975, -0.54834515,\n",
       "         -0.97932547, -0.5084886 ,  1.26888013,  0.67323208,  1.23540664,\n",
       "         -1.3523798 , -2.55779409,  0.04607547,  2.3447082 ,  3.09416747,\n",
       "          0.56896818,  0.86122757, -1.60043645, -2.14457989,  1.97490084,\n",
       "          0.03745321, -0.39925018, -0.80294567, -2.06293106, -0.4631384 ,\n",
       "         -0.49812466,  0.68334323,  0.00655391, -0.770154  , -1.2338146 ,\n",
       "          1.01175654, -0.36246687,  0.52225578,  1.24580193, -1.46016181,\n",
       "          0.04937677,  0.70928651, -0.20652045,  2.17807913, -1.68953931,\n",
       "         -0.86724067,  1.87069964, -0.85359263,  3.07351708, -0.0329914 ,\n",
       "         -0.04739406,  0.21676657,  1.43907285, -2.37568784,  0.32569155,\n",
       "         -0.81851864,  1.61703956,  0.21590379,  0.60416704, -2.07363892,\n",
       "          0.83550864, -0.4327777 , -2.88542151, -0.55715644, -0.56335062,\n",
       "          1.95831561,  1.28196013, -0.52672094, -1.96805048, -0.46565187,\n",
       "          0.06379984,  0.45799738, -0.08458556,  0.78623831,  0.21500267,\n",
       "         -0.23961994,  1.01931524,  0.95593476, -0.29365852,  2.86096311,\n",
       "         -1.77160883,  0.37693226, -0.31364751,  1.65181804, -1.28376639,\n",
       "         -1.10353148, -3.20644689,  1.76025057, -0.8092041 ,  2.38129449,\n",
       "         -0.47894979,  0.50409395, -1.49359667, -1.08082211, -0.75100589,\n",
       "          1.62493801,  0.69335008, -0.73280329, -0.32057387,  0.84868354,\n",
       "         -1.15941226, -0.33709455, -0.5779075 , -0.86461323,  0.11845936,\n",
       "         -1.36979556,  0.8250038 , -1.25844991, -0.95406038,  0.41481173,\n",
       "          3.16715765, -0.54491812, -0.93068439, -0.18395752, -0.41275257,\n",
       "         -0.37137008, -0.41223943,  0.16171619,  0.53642821,  0.9791106 ,\n",
       "          0.89049882,  0.62282807,  0.17264549,  0.90789205,  0.24330404,\n",
       "          0.38073772,  3.14931083, -0.37750629, -0.14773312, -0.51813966,\n",
       "          0.62846172, -0.36489293, -0.21416543,  1.93022835,  1.24246371,\n",
       "          2.09657097, -1.58406627,  1.11383224,  1.39228344, -0.37933257,\n",
       "          0.99690652]]], dtype=float32), h=array([[[ -1.63152255e-02,   6.05663657e-02,   5.30044511e-02,\n",
       "           7.75003135e-01,   1.56744510e-01,  -8.13718438e-01,\n",
       "           1.26413345e-01,   5.72116911e-01,  -6.66635454e-01,\n",
       "          -2.70359129e-01,  -3.52965206e-01,   4.09612626e-01,\n",
       "           8.19064826e-02,  -1.54398695e-01,   9.37678292e-02,\n",
       "           1.16877645e-01,   1.67458773e-01,  -1.55577481e-01,\n",
       "           6.63182557e-01,  -3.60452414e-01,  -3.16016972e-01,\n",
       "          -3.57127339e-01,  -6.75752461e-02,   5.76941222e-02,\n",
       "          -2.59623993e-02,  -9.30818841e-02,  -5.60914129e-02,\n",
       "          -1.28525436e-01,  -3.10833268e-02,   6.43933564e-02,\n",
       "          -8.05365801e-01,  -1.22529536e-01,  -4.21642363e-01,\n",
       "          -3.87361467e-01,   2.99605787e-01,  -1.13379076e-01,\n",
       "          -1.43498495e-01,  -4.44565773e-01,  -1.81678116e-01,\n",
       "          -9.25326999e-03,  -2.40873590e-01,   2.05354407e-01,\n",
       "          -2.64669269e-01,   8.90758574e-01,   4.78287898e-02,\n",
       "           6.40654564e-01,  -1.49269372e-01,  -4.28924501e-01,\n",
       "          -2.93806165e-01,   1.56404272e-01,   3.63478124e-01,\n",
       "          -9.85125080e-03,  -5.43533862e-01,   7.25965023e-01,\n",
       "           1.53654635e-01,  -7.79346943e-01,   8.09907258e-01,\n",
       "          -9.17684972e-01,  -1.42424718e-01,   5.91678196e-04,\n",
       "          -5.85557461e-01,  -8.32930282e-02,  -8.24940920e-01,\n",
       "           4.07353163e-01,   6.27520263e-01,  -7.97126710e-01,\n",
       "          -4.18028347e-02,   9.53978002e-02,   6.66628540e-01,\n",
       "          -5.21830022e-01,  -8.64194393e-01,   5.51526368e-01,\n",
       "           4.01404560e-01,  -5.77908233e-02,  -3.47592205e-01,\n",
       "          -1.48245811e-01,  -4.95948121e-02,  -6.06157780e-01,\n",
       "           2.78164327e-01,  -9.38492537e-01,  -4.14430618e-01,\n",
       "          -1.30394056e-01,  -7.10164309e-01,   5.09795509e-02,\n",
       "           2.60944605e-01,  -2.00451747e-01,   1.73424482e-01,\n",
       "          -5.33542633e-01,   6.41103745e-01,  -9.80164826e-01,\n",
       "          -1.15421526e-01,  -7.17525899e-01,   9.33389068e-01,\n",
       "          -6.46580875e-01,   2.19751932e-02,   9.77451876e-02,\n",
       "          -1.21523105e-01,  -1.10561796e-01,   4.38269317e-01,\n",
       "           3.65951538e-01,   1.45335868e-01,   6.94394261e-02,\n",
       "           2.52409726e-01,   1.86096311e-01,  -3.52232456e-01,\n",
       "           6.24595225e-01,   4.98052776e-01,  -1.26095906e-01,\n",
       "           1.06608994e-01,   8.60229731e-02,   3.71127754e-01,\n",
       "          -2.51154691e-01,  -4.05236520e-02,   4.73780632e-01,\n",
       "           3.68681669e-01,   1.95830122e-01,   3.12475264e-01,\n",
       "          -3.19432467e-02,   3.86158645e-01,   3.15754890e-01,\n",
       "          -3.47348601e-01,   8.10699165e-01,  -2.27833599e-01,\n",
       "           3.48421140e-03,  -1.04603812e-01,  -3.42690080e-01,\n",
       "          -9.88522321e-02,   5.50191641e-01,   5.62005281e-01,\n",
       "           7.47467518e-01,  -6.62024438e-01,  -2.85217106e-01,\n",
       "           7.76523259e-03,   2.53996581e-01,   2.71931171e-01,\n",
       "           3.69160399e-02,   4.16619360e-01,  -7.72213280e-01,\n",
       "          -4.51848656e-01,   9.41602468e-01,   2.11575627e-03,\n",
       "          -3.44217688e-01,  -5.52593946e-01,  -6.91361845e-01,\n",
       "          -1.68192148e-01,  -2.16754973e-01,   2.03209028e-01,\n",
       "           3.02405941e-04,  -5.81077933e-01,  -7.33347297e-01,\n",
       "           4.61242124e-02,  -3.04100458e-02,   1.67310685e-01,\n",
       "           7.92747438e-01,  -6.54446840e-01,   4.77199070e-02,\n",
       "           5.28608322e-01,  -1.71352789e-01,   4.26054358e-01,\n",
       "          -2.33046293e-01,  -2.68650919e-01,   7.64314294e-01,\n",
       "          -4.84253138e-01,   2.53743529e-01,  -1.10704796e-02,\n",
       "          -4.29669060e-02,   8.81354064e-02,   5.61156034e-01,\n",
       "          -8.26153994e-01,   3.08896124e-01,  -5.29446661e-01,\n",
       "           3.93563569e-01,   5.75109152e-03,   5.14670074e-01,\n",
       "          -5.11090755e-01,   2.60229468e-01,  -7.46483877e-02,\n",
       "          -9.27661285e-02,  -3.46039474e-01,  -8.42763335e-02,\n",
       "           2.15476453e-01,   9.62091088e-02,  -1.97628096e-01,\n",
       "          -9.54455554e-01,  -9.04827192e-02,   4.01605889e-02,\n",
       "           2.49098986e-01,  -3.54957730e-02,   1.52193056e-02,\n",
       "           1.52264744e-01,  -3.71432416e-02,   1.85410097e-01,\n",
       "           4.36603844e-01,  -2.34188691e-01,   9.09716427e-01,\n",
       "          -7.84991205e-01,   1.02023937e-01,  -1.65446803e-01,\n",
       "           8.46645474e-01,  -3.46393496e-01,  -1.54849157e-01,\n",
       "          -7.10487068e-01,   6.85838461e-01,  -5.21409392e-01,\n",
       "           4.63845655e-02,  -2.15170518e-01,   2.48638168e-01,\n",
       "          -8.88522923e-01,  -6.48382187e-01,  -5.79712451e-01,\n",
       "           1.17146209e-01,   2.73793280e-01,  -4.28913802e-01,\n",
       "          -6.11723028e-02,   6.13168359e-01,  -6.08235657e-01,\n",
       "          -3.07773888e-01,  -6.75179511e-02,  -4.42586839e-01,\n",
       "           2.30403827e-03,  -4.40464765e-01,   7.58150592e-02,\n",
       "          -7.79051721e-01,  -2.42844254e-01,   1.96621716e-01,\n",
       "           3.96526307e-01,  -2.30394229e-01,  -9.89600793e-02,\n",
       "          -1.35873944e-01,  -1.88591387e-02,  -3.22524875e-01,\n",
       "          -1.44256338e-01,   1.90661161e-03,   4.88155484e-01,\n",
       "           1.94851786e-01,   9.54337940e-02,   5.33857346e-01,\n",
       "           4.87992465e-02,   6.82135582e-01,   1.55187950e-01,\n",
       "           2.78256655e-01,   7.47644678e-02,  -1.69569924e-01,\n",
       "          -7.03657120e-02,  -2.88109958e-01,   4.22616750e-01,\n",
       "          -2.94221967e-01,  -1.32101819e-01,   5.19152701e-01,\n",
       "           7.58749783e-01,   5.37100017e-01,  -6.95833340e-02,\n",
       "           7.18451381e-01,   1.03469364e-01,  -3.58987421e-01,\n",
       "           4.85634118e-01],\n",
       "        [ -1.63152292e-02,   6.05663620e-02,   5.30044399e-02,\n",
       "           7.75003076e-01,   1.56744495e-01,  -8.13718438e-01,\n",
       "           1.26413345e-01,   5.72116911e-01,  -6.66635454e-01,\n",
       "          -2.70359129e-01,  -3.52965206e-01,   4.09612775e-01,\n",
       "           8.19064677e-02,  -1.54398665e-01,   9.37678218e-02,\n",
       "           1.16877615e-01,   1.67458683e-01,  -1.55577451e-01,\n",
       "           6.63182557e-01,  -3.60452384e-01,  -3.16017032e-01,\n",
       "          -3.57127339e-01,  -6.75752461e-02,   5.76941222e-02,\n",
       "          -2.59623844e-02,  -9.30818766e-02,  -5.60914129e-02,\n",
       "          -1.28525436e-01,  -3.10833268e-02,   6.43933564e-02,\n",
       "          -8.05365682e-01,  -1.22529730e-01,  -4.21642393e-01,\n",
       "          -3.87361467e-01,   2.99605787e-01,  -1.13379076e-01,\n",
       "          -1.43498525e-01,  -4.44565803e-01,  -1.81678116e-01,\n",
       "          -9.25326627e-03,  -2.40873545e-01,   2.05354407e-01,\n",
       "          -2.64669180e-01,   8.90758514e-01,   4.78287786e-02,\n",
       "           6.40654564e-01,  -1.49269342e-01,  -4.28924501e-01,\n",
       "          -2.93806165e-01,   1.56404272e-01,   3.63478124e-01,\n",
       "          -9.85124055e-03,  -5.43533802e-01,   7.25965083e-01,\n",
       "           1.53654560e-01,  -7.79347003e-01,   8.09907198e-01,\n",
       "          -9.17684913e-01,  -1.42424688e-01,   5.91677905e-04,\n",
       "          -5.85557580e-01,  -8.32930282e-02,  -8.24940920e-01,\n",
       "           4.07353163e-01,   6.27520263e-01,  -7.97126710e-01,\n",
       "          -4.18028198e-02,   9.53978077e-02,   6.66628540e-01,\n",
       "          -5.21829963e-01,  -8.64194393e-01,   5.51526427e-01,\n",
       "           4.01404560e-01,  -5.77908084e-02,  -3.47592205e-01,\n",
       "          -1.48245871e-01,  -4.95947674e-02,  -6.06157780e-01,\n",
       "           2.78164327e-01,  -9.38492537e-01,  -4.14430618e-01,\n",
       "          -1.30394027e-01,  -7.10164309e-01,   5.09795621e-02,\n",
       "           2.60944605e-01,  -2.00451717e-01,   1.73424587e-01,\n",
       "          -5.33542633e-01,   6.41103804e-01,  -9.80164826e-01,\n",
       "          -1.15421526e-01,  -7.17525899e-01,   9.33389068e-01,\n",
       "          -6.46580875e-01,   2.19751876e-02,   9.77451578e-02,\n",
       "          -1.21523134e-01,  -1.10561736e-01,   4.38269407e-01,\n",
       "           3.65951568e-01,   1.45335853e-01,   6.94394261e-02,\n",
       "           2.52409726e-01,   1.86096311e-01,  -3.52232337e-01,\n",
       "           6.24595225e-01,   4.98052776e-01,  -1.26095906e-01,\n",
       "           1.06608987e-01,   8.60229731e-02,   3.71127814e-01,\n",
       "          -2.51154602e-01,  -4.05236520e-02,   4.73780602e-01,\n",
       "           3.68681580e-01,   1.95830077e-01,   3.12475383e-01,\n",
       "          -3.19432355e-02,   3.86158556e-01,   3.15754890e-01,\n",
       "          -3.47348601e-01,   8.10699165e-01,  -2.27833599e-01,\n",
       "           3.48421116e-03,  -1.04603820e-01,  -3.42690080e-01,\n",
       "          -9.88522172e-02,   5.50191641e-01,   5.62005281e-01,\n",
       "           7.47467458e-01,  -6.62024498e-01,  -2.85217136e-01,\n",
       "           7.76523352e-03,   2.53996581e-01,   2.71931201e-01,\n",
       "           3.69160287e-02,   4.16619331e-01,  -7.72213340e-01,\n",
       "          -4.51848656e-01,   9.41602468e-01,   2.11575325e-03,\n",
       "          -3.44217747e-01,  -5.52593946e-01,  -6.91361845e-01,\n",
       "          -1.68192104e-01,  -2.16754943e-01,   2.03209043e-01,\n",
       "           3.02408298e-04,  -5.81077993e-01,  -7.33347237e-01,\n",
       "           4.61241938e-02,  -3.04100458e-02,   1.67310730e-01,\n",
       "           7.92747498e-01,  -6.54446840e-01,   4.77199331e-02,\n",
       "           5.28608322e-01,  -1.71352714e-01,   4.26054299e-01,\n",
       "          -2.33046293e-01,  -2.68650919e-01,   7.64314294e-01,\n",
       "          -4.84253109e-01,   2.53743470e-01,  -1.10704722e-02,\n",
       "          -4.29670773e-02,   8.81354064e-02,   5.61155975e-01,\n",
       "          -8.26153994e-01,   3.08896124e-01,  -5.29446721e-01,\n",
       "           3.93563569e-01,   5.75108873e-03,   5.14670074e-01,\n",
       "          -5.11090815e-01,   2.60229498e-01,  -7.46483803e-02,\n",
       "          -9.27661285e-02,  -3.46039474e-01,  -8.42763335e-02,\n",
       "           2.15476409e-01,   9.62091014e-02,  -1.97628066e-01,\n",
       "          -9.54455614e-01,  -9.04827267e-02,   4.01606001e-02,\n",
       "           2.49098986e-01,  -3.54957506e-02,   1.52192954e-02,\n",
       "           1.52264744e-01,  -3.71432267e-02,   1.85410067e-01,\n",
       "           4.36603904e-01,  -2.34188691e-01,   9.09716427e-01,\n",
       "          -7.84991205e-01,   1.02023929e-01,  -1.65446803e-01,\n",
       "           8.46645474e-01,  -3.46393526e-01,  -1.54849157e-01,\n",
       "          -7.10487068e-01,   6.85838401e-01,  -5.21409392e-01,\n",
       "           4.63845544e-02,  -2.15170443e-01,   2.48638123e-01,\n",
       "          -8.88522804e-01,  -6.48382187e-01,  -5.79712451e-01,\n",
       "           1.17146172e-01,   2.73793221e-01,  -4.28913772e-01,\n",
       "          -6.11723103e-02,   6.13168359e-01,  -6.08235717e-01,\n",
       "          -3.07773829e-01,  -6.75179437e-02,  -4.42586780e-01,\n",
       "           2.30403850e-03,  -4.40464705e-01,   7.58150667e-02,\n",
       "          -7.79051721e-01,  -2.42844298e-01,   1.96621686e-01,\n",
       "           3.96526307e-01,  -2.30394274e-01,  -9.89600569e-02,\n",
       "          -1.35873929e-01,  -1.88591424e-02,  -3.22524786e-01,\n",
       "          -1.44256294e-01,   1.90661161e-03,   4.88155633e-01,\n",
       "           1.94851741e-01,   9.54337567e-02,   5.33857346e-01,\n",
       "           4.87992242e-02,   6.82135642e-01,   1.55187920e-01,\n",
       "           2.78256655e-01,   7.47644678e-02,  -1.69569924e-01,\n",
       "          -7.03656673e-02,  -2.88109988e-01,   4.22616750e-01,\n",
       "          -2.94222027e-01,  -1.32101804e-01,   5.19152701e-01,\n",
       "           7.58749783e-01,   5.37099957e-01,  -6.95833340e-02,\n",
       "           7.18451381e-01,   1.03469335e-01,  -3.58987391e-01,\n",
       "           4.85634089e-01]]], dtype=float32)),\n",
       "  AttentionWrapperState(cell_state=LSTMStateTuple(c=array([[[ 0.91550511,  0.12410956, -0.89061558,  1.19231999,  0.72326028,\n",
       "          0.38446757,  0.40791419, -0.46515998,  1.26736152,  1.57906306,\n",
       "         -0.30238003,  1.91019416,  0.54889709, -1.22569728,  0.90219831,\n",
       "          0.09209774, -1.17562139,  0.25690359, -0.29344475, -0.15830974,\n",
       "          0.40643847, -1.73608446,  0.34314033,  0.64082664, -0.63043499,\n",
       "         -2.50654745,  0.30534562, -0.87479246,  0.5911333 , -0.903952  ,\n",
       "         -1.44393718,  1.23307633, -0.22033256,  0.91825968, -1.27055371,\n",
       "         -0.99063587, -0.92944413,  0.34698743,  0.17662503, -0.07445465,\n",
       "          0.32882035,  0.61335486,  1.26679349,  2.56956577,  0.18887609,\n",
       "         -3.82840443,  2.59580612, -0.2399407 , -0.04097666, -0.39410135,\n",
       "         -0.06018662, -0.70368832, -2.24032521, -0.87719035,  1.979002  ,\n",
       "         -0.72366786, -0.32281655, -2.29659677,  0.79814035,  0.3197622 ,\n",
       "          1.09868276,  2.22940207, -0.17202392,  0.21734302,  0.60818434,\n",
       "         -0.09698998, -1.20817327,  2.08748269, -0.63000691, -0.30232257,\n",
       "          1.33174682,  1.54461575,  1.83026409,  0.27662465, -4.02620792,\n",
       "         -0.25385132,  1.23286688, -0.58000898,  3.5844121 ,  1.53021705,\n",
       "          1.23599529, -0.80058849, -0.85178912,  0.73563802, -0.13367879,\n",
       "         -0.40750927, -1.43608606, -0.92644095,  1.15798616,  0.95673287,\n",
       "         -1.54906523,  0.70095873,  0.83259469, -0.56136453, -1.99723029,\n",
       "         -0.28860065, -0.37609622, -1.10223949,  0.42480716,  0.54349142,\n",
       "         -0.10030537,  0.16872692, -0.01746535, -0.30087039,  1.79182827,\n",
       "         -0.21573222,  0.29643214, -1.0655849 , -0.10591462, -0.07115943,\n",
       "         -0.13909154, -1.77906656,  0.21116157,  0.45945573,  0.84410632,\n",
       "          0.20070423,  1.95741081,  1.30074596, -1.32583523,  0.78944033,\n",
       "          1.23467338,  0.16136599, -0.50800091, -0.38394147, -0.78913701,\n",
       "          0.83724409,  0.50018758, -1.4808358 , -1.83141196, -1.24800956,\n",
       "          0.38990465,  1.25132287,  0.90112793,  0.60578531, -0.09021315,\n",
       "          0.54309916,  0.81989646, -0.90593445,  1.00403285,  0.41291034,\n",
       "          0.16689466, -0.01908545,  1.22812366,  1.65557766,  1.79911029,\n",
       "          2.08420229,  0.58942443, -0.94053954,  1.40832555,  0.88955426,\n",
       "          0.31627324, -2.00996828,  0.46371311, -0.66797179,  1.27871847,\n",
       "         -1.09085679,  2.59980321, -1.91513252, -0.08947379,  0.80065393,\n",
       "         -0.29096177, -1.17928755, -1.01516974, -0.76508015, -0.40103185,\n",
       "          0.14936422, -1.14675522,  0.64906549, -0.56006861,  0.55313599,\n",
       "         -0.23403455, -0.87134087,  4.19539165,  1.03727508,  0.5995416 ,\n",
       "         -0.40666175, -0.39938203,  1.54356134,  0.9244079 , -0.3004815 ,\n",
       "         -1.14886487,  0.35182431, -0.55114281, -1.66580093,  0.94046199,\n",
       "          0.28509301, -0.65494645, -0.53526938,  0.95419258,  0.90597928,\n",
       "         -1.40542078, -1.435233  , -0.98442245,  1.79380071, -1.70924795,\n",
       "          0.61531359, -0.7408523 , -0.01399337,  0.74595308, -2.90710258,\n",
       "          0.70692074, -1.3540225 , -0.88183677, -0.60295677, -1.15199161,\n",
       "          0.68501401,  0.30282027,  0.27371478, -1.4689585 , -1.00081182,\n",
       "          0.60288739, -2.11913323, -0.30550539, -0.49685153, -0.79836798,\n",
       "         -2.77099824, -1.29068017,  0.80523002,  0.41177309, -0.94648093,\n",
       "          0.80964643,  0.36467528,  0.85322869,  4.40228319,  0.45229807,\n",
       "          0.04439777, -2.25841808, -2.9647646 , -1.10144651,  1.63693893,\n",
       "         -0.68745661,  0.2255857 , -0.60354924, -1.23290658,  1.03513777,\n",
       "         -0.90549904,  1.22310758, -1.31038427,  0.30435634, -1.49389923,\n",
       "          0.37750429,  1.38109148, -0.99395943,  0.55553055,  1.38752735,\n",
       "         -0.88947904,  0.53742898,  1.9947269 ,  1.19174981, -1.39244497,\n",
       "         -0.43967837, -0.58232915, -1.45870531, -1.34301877, -1.18598294,\n",
       "          0.9700827 ],\n",
       "        [ 0.91550541,  0.12410948, -0.8906154 ,  1.19231999,  0.72326022,\n",
       "          0.38446754,  0.40791419, -0.46515983,  1.26736116,  1.57906318,\n",
       "         -0.30237976,  1.91019404,  0.54889691, -1.2256974 ,  0.90219831,\n",
       "          0.09209776, -1.17562139,  0.25690338, -0.29344466, -0.15830986,\n",
       "          0.40643847, -1.73608446,  0.34314051,  0.64082664, -0.63043493,\n",
       "         -2.50654745,  0.30534557, -0.87479246,  0.5911333 , -0.90395164,\n",
       "         -1.44393718,  1.23307633, -0.22033267,  0.91825986, -1.27055371,\n",
       "         -0.99063575, -0.92944407,  0.3469874 ,  0.17662504, -0.07445449,\n",
       "          0.32882032,  0.61335486,  1.26679349,  2.56956577,  0.18887609,\n",
       "         -3.82840443,  2.59580612, -0.23994069, -0.04097669, -0.39410108,\n",
       "         -0.06018636, -0.70368838, -2.24032521, -0.87719035,  1.97900188,\n",
       "         -0.7236678 , -0.32281631, -2.29659677,  0.79814041,  0.31976217,\n",
       "          1.09868264,  2.22940183, -0.17202398,  0.21734321,  0.60818416,\n",
       "         -0.09699015, -1.20817351,  2.08748293, -0.63000691, -0.3023226 ,\n",
       "          1.33174682,  1.54461551,  1.83026409,  0.2766248 , -4.02620792,\n",
       "         -0.25385118,  1.232867  , -0.5800091 ,  3.58441257,  1.53021693,\n",
       "          1.23599529, -0.80058861, -0.85178888,  0.73563784, -0.13367863,\n",
       "         -0.40750939, -1.43608582, -0.9264406 ,  1.15798616,  0.95673293,\n",
       "         -1.54906523,  0.70095903,  0.83259487, -0.56136447, -1.99723029,\n",
       "         -0.28860104, -0.37609631, -1.10223937,  0.42480734,  0.54349148,\n",
       "         -0.10030538,  0.16872694, -0.0174651 , -0.30087036,  1.79182827,\n",
       "         -0.21573216,  0.29643208, -1.0655849 , -0.10591468, -0.0711594 ,\n",
       "         -0.13909145, -1.77906644,  0.21116172,  0.45945591,  0.84410632,\n",
       "          0.20070422,  1.95741081,  1.30074573, -1.32583523,  0.78944021,\n",
       "          1.23467362,  0.16136588, -0.50800103, -0.38394159, -0.78913707,\n",
       "          0.83724427,  0.50018758, -1.48083627, -1.83141208, -1.24800956,\n",
       "          0.38990474,  1.25132287,  0.90112793,  0.60578531, -0.09021318,\n",
       "          0.54309911,  0.81989646, -0.90593433,  1.00403249,  0.41291031,\n",
       "          0.16689466, -0.01908546,  1.2281239 ,  1.65557754,  1.79911029,\n",
       "          2.08420229,  0.58942437, -0.94053966,  1.40832543,  0.88955438,\n",
       "          0.31627321, -2.00996804,  0.46371308, -0.66797185,  1.27871859,\n",
       "         -1.09085691,  2.59980321, -1.91513205, -0.08947372,  0.80065405,\n",
       "         -0.29096162, -1.17928755, -1.01516962, -0.76507998, -0.401032  ,\n",
       "          0.14936405, -1.1467551 ,  0.64906549, -0.56006867,  0.55313617,\n",
       "         -0.23403451, -0.87134069,  4.19539118,  1.03727508,  0.59954166,\n",
       "         -0.40666184, -0.39938208,  1.54356122,  0.92440784, -0.30048135,\n",
       "         -1.14886439,  0.3518244 , -0.55114281, -1.66580081,  0.94046199,\n",
       "          0.28509295, -0.65494663, -0.53526932,  0.95419264,  0.9059791 ,\n",
       "         -1.40542078, -1.435233  , -0.98442221,  1.79380071, -1.70924807,\n",
       "          0.61531353, -0.7408523 , -0.01399352,  0.7459532 , -2.90710306,\n",
       "          0.70692086, -1.35402238, -0.88183677, -0.60295707, -1.15199149,\n",
       "          0.68501401,  0.30282032,  0.27371472, -1.4689585 , -1.00081193,\n",
       "          0.60288745, -2.11913371, -0.30550537, -0.49685156, -0.79836798,\n",
       "         -2.77099824, -1.29067993,  0.80523008,  0.41177318, -0.94648087,\n",
       "          0.80964637,  0.36467528,  0.85322869,  4.40228271,  0.45229834,\n",
       "          0.04439785, -2.25841808, -2.96476483, -1.10144651,  1.63693881,\n",
       "         -0.68745673,  0.22558576, -0.60354966, -1.23290646,  1.03513753,\n",
       "         -0.90549886,  1.22310758, -1.31038415,  0.30435619, -1.49389923,\n",
       "          0.37750423,  1.38109159, -0.99395931,  0.55553055,  1.38752747,\n",
       "         -0.88947898,  0.5374288 ,  1.9947269 ,  1.19174981, -1.39244497,\n",
       "         -0.43967831, -0.5823288 , -1.45870531, -1.34301901, -1.18598294,\n",
       "          0.9700827 ]]], dtype=float32), h=array([[[ 0.54517287,  0.08663546, -0.01676431,  0.81875151,  0.34127849,\n",
       "          0.15350598,  0.21143226, -0.18739949,  0.78026146,  0.87792331,\n",
       "         -0.18809873,  0.91857368,  0.05938588, -0.66989672,  0.30845356,\n",
       "          0.00108496, -0.74660343,  0.07847618, -0.11874004, -0.10460608,\n",
       "          0.01300749, -0.91431004,  0.05393687,  0.42142206, -0.02121919,\n",
       "         -0.51553255,  0.10247677, -0.50240868,  0.03061734, -0.52429187,\n",
       "         -0.85878313,  0.5552268 , -0.07463466,  0.64659268, -0.42161149,\n",
       "         -0.20951296, -0.01516514,  0.2070026 ,  0.15674086, -0.02488765,\n",
       "          0.2146306 ,  0.23472099,  0.77068561,  0.06272211,  0.01243355,\n",
       "         -0.90773463,  0.95250177, -0.0078172 , -0.03622114, -0.1142871 ,\n",
       "         -0.05122089, -0.0637603 , -0.64150178, -0.6202665 ,  0.66895801,\n",
       "         -0.04467124, -0.00848629, -0.16997632,  0.33811542,  0.20129982,\n",
       "          0.51373881,  0.73543656, -0.15052892,  0.18455245,  0.04204607,\n",
       "         -0.08919077, -0.44097096,  0.95781946, -0.28820726, -0.15664153,\n",
       "          0.86287171,  0.74606109,  0.2138374 ,  0.26380077, -0.39882395,\n",
       "         -0.21016714,  0.36944175, -0.14506555,  0.95260954,  0.83702964,\n",
       "          0.70640868, -0.12307364, -0.63103175,  0.51286077, -0.10528404,\n",
       "         -0.25358605, -0.88729244, -0.49358487,  0.64449883,  0.66645032,\n",
       "         -0.12168674,  0.58141309,  0.5258773 , -0.07802577, -0.83016682,\n",
       "         -0.26266256, -0.32814008, -0.6993618 ,  0.25017744,  0.33291394,\n",
       "         -0.0891445 ,  0.00453409, -0.00934614, -0.06367341,  0.83501279,\n",
       "         -0.16584338,  0.01613332, -0.74868739, -0.03739382, -0.0532384 ,\n",
       "         -0.10640448, -0.78281534,  0.13734712,  0.28342223,  0.407989  ,\n",
       "          0.05182401,  0.5520485 ,  0.84603703, -0.82099199,  0.53610265,\n",
       "          0.54878706,  0.03008739, -0.17578223, -0.15773879, -0.29498461,\n",
       "          0.10192043,  0.2510553 , -0.35216644, -0.01747333, -0.04787483,\n",
       "          0.12579216,  0.35217431,  0.65425599,  0.02353855, -0.07012713,\n",
       "          0.29213977,  0.66469806, -0.15858488,  0.72638124,  0.19268453,\n",
       "          0.03164035, -0.01064621,  0.25760919,  0.63376248,  0.5216949 ,\n",
       "          0.7828154 ,  0.34092629, -0.70405495,  0.09415165,  0.00116292,\n",
       "          0.15396744, -0.04487442,  0.11882039, -0.12975891,  0.54352283,\n",
       "         -0.66372192,  0.22654514, -0.43701583, -0.05321452,  0.36384922,\n",
       "         -0.0783871 , -0.8150506 , -0.04238902, -0.00364597, -0.33279315,\n",
       "          0.09673862, -0.64885038,  0.47001505, -0.22481929,  0.14947498,\n",
       "         -0.08558615, -0.51117331,  0.61451638,  0.58292156,  0.34878656,\n",
       "         -0.35783851, -0.00701621,  0.8146587 ,  0.25666133, -0.27150187,\n",
       "         -0.37687141,  0.22715189, -0.2391987 , -0.68105459,  0.66792917,\n",
       "          0.26804775, -0.54131341, -0.48477846,  0.46903357,  0.11935604,\n",
       "         -0.08079277, -0.83740968, -0.7056179 ,  0.2748515 , -0.91651881,\n",
       "          0.14293423, -0.52625948, -0.00263799,  0.15064038, -0.39409998,\n",
       "          0.42851791, -0.61571389, -0.54202151, -0.53473312, -0.22907466,\n",
       "          0.31177729,  0.23854719,  0.06149615, -0.78017133, -0.52583104,\n",
       "          0.38912928, -0.65796238, -0.00824449, -0.00569415, -0.00494607,\n",
       "         -0.89055789, -0.00625875,  0.24921633,  0.32141662, -0.68577182,\n",
       "          0.44255245,  0.0647156 ,  0.65564626,  0.55782408,  0.29625931,\n",
       "          0.02163493, -0.74892527, -0.49105534, -0.64925891,  0.897403  ,\n",
       "         -0.24854091,  0.14164297, -0.30587906, -0.50218654,  0.69675392,\n",
       "         -0.6613692 ,  0.78954655, -0.03865786,  0.15975142, -0.64085466,\n",
       "          0.29853803,  0.80999333, -0.29462296,  0.17120624,  0.854527  ,\n",
       "         -0.58307225,  0.364712  ,  0.05432976,  0.38229373, -0.87012815,\n",
       "         -0.05495622, -0.46818158, -0.33378679, -0.78500813, -0.62253791,\n",
       "          0.27744547],\n",
       "        [ 0.54517293,  0.08663539, -0.01676431,  0.81875151,  0.34127846,\n",
       "          0.15350597,  0.21143223, -0.1873994 ,  0.78026152,  0.87792325,\n",
       "         -0.18809858,  0.91857368,  0.05938587, -0.66989678,  0.30845362,\n",
       "          0.00108497, -0.74660349,  0.0784761 , -0.11873999, -0.10460615,\n",
       "          0.01300749, -0.91431004,  0.05393689,  0.42142206, -0.02121919,\n",
       "         -0.51553261,  0.10247676, -0.50240874,  0.03061734, -0.52429181,\n",
       "         -0.85878313,  0.55522674, -0.07463472,  0.64659262, -0.42161143,\n",
       "         -0.20951289, -0.01516514,  0.20700255,  0.15674087, -0.02488761,\n",
       "          0.21463059,  0.23472096,  0.77068561,  0.06272211,  0.01243355,\n",
       "         -0.90773463,  0.95250177, -0.0078172 , -0.03622115, -0.11428705,\n",
       "         -0.05122067, -0.0637603 , -0.64150167, -0.6202665 ,  0.66895795,\n",
       "         -0.04467123, -0.00848627, -0.16997631,  0.33811548,  0.20129979,\n",
       "          0.51373881,  0.73543656, -0.15052897,  0.1845526 ,  0.04204606,\n",
       "         -0.08919092, -0.44097099,  0.95781946, -0.28820732, -0.15664154,\n",
       "          0.86287171,  0.74606109,  0.21383744,  0.26380089, -0.39882398,\n",
       "         -0.21016702,  0.36944169, -0.14506556,  0.95260954,  0.83702964,\n",
       "          0.70640868, -0.12307366, -0.63103163,  0.51286066, -0.10528392,\n",
       "         -0.25358614, -0.88729239, -0.49358475,  0.64449883,  0.66645026,\n",
       "         -0.12168671,  0.58141333,  0.52587736, -0.07802574, -0.83016688,\n",
       "         -0.26266289, -0.32814014, -0.69936168,  0.25017753,  0.33291388,\n",
       "         -0.08914451,  0.00453409, -0.00934601, -0.06367341,  0.83501279,\n",
       "         -0.16584334,  0.01613332, -0.74868739, -0.03739384, -0.05323837,\n",
       "         -0.10640442, -0.7828154 ,  0.13734721,  0.28342232,  0.407989  ,\n",
       "          0.05182399,  0.55204862,  0.84603697, -0.82099193,  0.53610259,\n",
       "          0.54878724,  0.03008738, -0.17578223, -0.15773883, -0.29498461,\n",
       "          0.10192044,  0.25105527, -0.35216653, -0.01747333, -0.04787481,\n",
       "          0.12579216,  0.35217425,  0.65425599,  0.02353853, -0.07012715,\n",
       "          0.29213977,  0.66469806, -0.15858486,  0.726381  ,  0.19268452,\n",
       "          0.03164035, -0.01064622,  0.25760922,  0.63376248,  0.5216949 ,\n",
       "          0.7828154 ,  0.34092629, -0.70405501,  0.09415165,  0.00116292,\n",
       "          0.15396743, -0.04487442,  0.11882038, -0.12975891,  0.54352289,\n",
       "         -0.66372192,  0.2265451 , -0.4370158 , -0.05321449,  0.36384925,\n",
       "         -0.07838709, -0.8150506 , -0.04238903, -0.00364597, -0.33279327,\n",
       "          0.09673852, -0.64885038,  0.47001505, -0.22481933,  0.14947501,\n",
       "         -0.08558615, -0.51117325,  0.61451626,  0.5829215 ,  0.34878656,\n",
       "         -0.3578386 , -0.00701621,  0.8146587 ,  0.25666133, -0.27150175,\n",
       "         -0.37687132,  0.22715196, -0.23919876, -0.68105447,  0.66792917,\n",
       "          0.26804766, -0.54131353, -0.4847784 ,  0.46903357,  0.11935608,\n",
       "         -0.08079277, -0.83740968, -0.70561773,  0.2748515 , -0.91651881,\n",
       "          0.14293422, -0.52625948, -0.00263802,  0.1506404 , -0.39409998,\n",
       "          0.42851797, -0.61571378, -0.54202151, -0.53473336, -0.22907467,\n",
       "          0.31177723,  0.23854725,  0.06149614, -0.78017133, -0.52583104,\n",
       "          0.38912937, -0.65796232, -0.00824449, -0.00569414, -0.00494607,\n",
       "         -0.89055789, -0.00625875,  0.24921633,  0.32141674, -0.68577176,\n",
       "          0.44255236,  0.06471562,  0.65564626,  0.55782402,  0.29625946,\n",
       "          0.02163497, -0.74892533, -0.49105516, -0.64925903,  0.897403  ,\n",
       "         -0.24854091,  0.141643  , -0.30587924, -0.5021866 ,  0.6967538 ,\n",
       "         -0.66136909,  0.78954667, -0.03865785,  0.15975136, -0.64085466,\n",
       "          0.29853797,  0.80999339, -0.29462296,  0.17120624,  0.854527  ,\n",
       "         -0.58307219,  0.36471185,  0.05432978,  0.38229373, -0.87012815,\n",
       "         -0.05495622, -0.46818137, -0.33378679, -0.78500813, -0.62253791,\n",
       "          0.2774455 ]]], dtype=float32)), attention=array([[[ 4.59108353,  3.19886637,  6.3492465 , -0.09525765, -4.19298077,\n",
       "         -3.53946424, -0.72107804, -2.98481035,  3.85260868, -4.48822832,\n",
       "         -0.51362514,  2.27521801, -3.39326787, -0.81301296, -1.89946771,\n",
       "          1.91160953, -6.26811028,  5.850842  , -0.66186363, -1.47862828,\n",
       "          2.52648211,  5.54744673, -2.61684799,  0.06385105,  2.80114222,\n",
       "         -0.72459435,  5.11585188, -0.87429917, -1.13615227, -0.6043306 ,\n",
       "         -0.45616886,  0.54153317, -0.46692449,  0.80567396,  1.47459495,\n",
       "          2.47983646,  0.03343195, -0.40422916, -0.77840662,  4.22037649,\n",
       "          1.16466069,  0.59862214,  1.86365938,  0.84171742, -1.79821801,\n",
       "         -2.36733866, -3.63893676,  0.19908862,  3.46519279,  1.38151932,\n",
       "         -1.66022515, -1.27981591, -0.94502193,  2.42965198,  2.7346375 ,\n",
       "         -1.91087782,  8.40158463,  1.92581582,  0.48837265, -0.07165647,\n",
       "         -1.24623811,  4.36126757,  0.08632517, -0.75383592, -2.63456321,\n",
       "         -2.05539227, -5.9359107 ,  2.07477999,  0.04251957, -2.11292481,\n",
       "          0.99471939, -3.15824461,  4.99599791, -0.54455113, -1.87590289,\n",
       "         -0.19895414, -0.9185558 ,  1.12425935, -1.03460383, -4.29101658,\n",
       "          0.55611712, -1.71175241, -3.98794031, -1.52442896,  1.05229843,\n",
       "         -2.06256175,  0.99658751, -0.68809557,  4.95422077, -0.36110437,\n",
       "          0.67161959,  4.13391018,  0.62867928,  1.40466082,  2.82455444,\n",
       "          0.11720379, -1.51356268,  2.93485451, -0.96064878,  2.09036446,\n",
       "         -0.76956367,  0.79932046, -2.01257324,  0.36092249, -1.88506722,\n",
       "         -0.06130308,  0.27899635,  0.34836692, -2.94748783,  0.99798787,\n",
       "          0.3482402 ,  2.77073908, -0.50632715,  7.90852404,  5.35233498,\n",
       "          0.05817866,  2.08156347, -2.3478179 ,  4.64108229, -0.79022479,\n",
       "          3.48416352,  0.31772742, -2.26892829, -6.86074972, -4.54941368,\n",
       "          8.36970997,  1.61843336,  2.51488924,  1.19530106, -0.55039483,\n",
       "          0.76211214,  1.3053385 ,  0.62332082, -2.6541934 ,  4.09512901,\n",
       "         -2.26635814, -0.06476372, -0.31048596,  2.35258889, -1.76563966,\n",
       "         -0.01798856, -1.76513553,  2.97781825, -2.62684274,  2.24680233,\n",
       "         -2.14227819, -1.60603988,  2.34683657,  0.51517177, -1.63930726,\n",
       "          2.60940909,  0.58608198,  2.69198561, -0.17596817,  5.79181814,\n",
       "         -5.15522766,  4.66414118,  2.09230709, -3.9061358 ,  3.6340766 ,\n",
       "         -3.69401574,  1.4719913 , -2.25426841, -1.60755515,  0.33476797,\n",
       "          3.02068949,  4.36154556,  7.38704062,  1.29740608,  2.59119248,\n",
       "         -3.11760688, -2.4391346 , -1.80653572,  4.03407001,  0.75901586,\n",
       "         -2.43265104,  2.82672405,  6.13359261,  0.83833456,  7.25326538,\n",
       "         -2.05674458, -2.3499341 , -2.87138081, -3.05659056, -0.51584166,\n",
       "         -2.57495618,  3.08118796, -1.52466774,  0.61012781,  1.77489352,\n",
       "         -1.9975493 , -4.87564898, -0.18626954, -4.16732597, -0.57354295,\n",
       "         -2.35834217, -1.29361379, -2.96249938, -1.47824693, -2.44466901,\n",
       "         -1.95011473, -2.49406576, -0.96351862, -1.93264437, -2.01651144,\n",
       "          0.97219026,  1.91541338, -0.84583253, -1.57667518,  2.21342278,\n",
       "         -0.09560232,  4.17831707, -1.57328296, -2.11992598,  0.14131784,\n",
       "         -0.82598853, -0.77232718,  2.86442947, -0.39652002,  3.05176783,\n",
       "         -4.76891232, -2.44274998,  1.39183664, -1.64730668,  2.55260944,\n",
       "          0.52916384, -0.05070317,  4.01657772,  3.67678809,  0.7815032 ,\n",
       "         -4.21997452,  0.93687057, -1.87671077, -0.73343247, -0.72476649,\n",
       "          1.22286808,  3.92096472,  7.54777861,  0.80314124, -0.47977245,\n",
       "         -0.38357756, -2.56184649,  2.46469879,  0.48533106,  2.64418244,\n",
       "          2.13307667, -0.41187352,  4.27983665,  1.81513929,  0.74708307,\n",
       "         -0.64630795,  2.68100071, -0.54341507,  2.88787007, -3.1682601 ,\n",
       "          0.06675619],\n",
       "        [ 4.59108305,  3.19886637,  6.34924698, -0.09525776, -4.19298029,\n",
       "         -3.53946376, -0.72107792, -2.98481035,  3.85260868, -4.48822832,\n",
       "         -0.51362509,  2.27521801, -3.39326811, -0.81301332, -1.89946675,\n",
       "          1.91160929, -6.26811028,  5.85084105, -0.66186357, -1.47862852,\n",
       "          2.52648211,  5.54744625, -2.61684775,  0.06385085,  2.80114222,\n",
       "         -0.724594  ,  5.11585236, -0.87430012, -1.13615203, -0.60433048,\n",
       "         -0.4561688 ,  0.54153329, -0.46692479,  0.80567336,  1.47459507,\n",
       "          2.47983646,  0.03343183, -0.40422916, -0.77840716,  4.22037601,\n",
       "          1.16466177,  0.59862202,  1.86365926,  0.84171772, -1.79821801,\n",
       "         -2.3673389 , -3.63893771,  0.19908836,  3.46519208,  1.38151932,\n",
       "         -1.66022563, -1.27981567, -0.94502157,  2.42965221,  2.73463726,\n",
       "         -1.91087759,  8.40158463,  1.92581606,  0.48837289, -0.07165599,\n",
       "         -1.24623859,  4.36126804,  0.08632565, -0.7538358 , -2.63456321,\n",
       "         -2.05539227, -5.93591166,  2.07477856,  0.04251885, -2.11292458,\n",
       "          0.99471927, -3.15824509,  4.99599838, -0.5445509 , -1.87590289,\n",
       "         -0.19895414, -0.9185555 ,  1.12425888, -1.03460395, -4.2910161 ,\n",
       "          0.55611813, -1.71175289, -3.98793983, -1.52442932,  1.05229902,\n",
       "         -2.06256127,  0.9965874 , -0.68809485,  4.95422173, -0.36110437,\n",
       "          0.67161942,  4.13390827,  0.62867892,  1.4046607 ,  2.82455444,\n",
       "          0.11720422, -1.5135628 ,  2.93485498, -0.96064883,  2.09036446,\n",
       "         -0.76956403,  0.79931951, -2.01257253,  0.36092234, -1.88506699,\n",
       "         -0.06130278,  0.27899575,  0.34836704, -2.94748807,  0.99798679,\n",
       "          0.34824026,  2.77073812, -0.50632739,  7.90852404,  5.35233545,\n",
       "          0.05817854,  2.08156347, -2.34781814,  4.64108276, -0.79022378,\n",
       "          3.484164  ,  0.31772694, -2.26892805, -6.86074924, -4.54941416,\n",
       "          8.36970806,  1.618433  ,  2.51488924,  1.19530058, -0.55039454,\n",
       "          0.76211214,  1.30533791,  0.62332034, -2.65419388,  4.09512949,\n",
       "         -2.26635814, -0.06476319, -0.31048632,  2.35258937, -1.76563942,\n",
       "         -0.0179888 , -1.765136  ,  2.97781825, -2.62684274,  2.24680305,\n",
       "         -2.14227796, -1.60604024,  2.34683681,  0.51517224, -1.63930714,\n",
       "          2.60940862,  0.5860815 ,  2.69198585, -0.17596853,  5.79181767,\n",
       "         -5.15522766,  4.66414165,  2.09230804, -3.90613556,  3.63407683,\n",
       "         -3.69401574,  1.47199094, -2.25426865, -1.60755348,  0.33476794,\n",
       "          3.02068996,  4.36154556,  7.38704014,  1.29740536,  2.59119201,\n",
       "         -3.11760736, -2.43913412, -1.8065356 ,  4.03407049,  0.75901568,\n",
       "         -2.43265104,  2.82672477,  6.13359165,  0.83833432,  7.2532649 ,\n",
       "         -2.0567441 , -2.34993458, -2.87138081, -3.0565908 , -0.51584142,\n",
       "         -2.5749557 ,  3.08118749, -1.52466774,  0.61012685,  1.774894  ,\n",
       "         -1.99754953, -4.87564898, -0.18626958, -4.1673255 , -0.57354236,\n",
       "         -2.35834289, -1.29361391, -2.96249795, -1.47824728, -2.44466853,\n",
       "         -1.95011449, -2.494066  , -0.96351814, -1.93264389, -2.01651144,\n",
       "          0.97219086,  1.91541386, -0.84583229, -1.57667482,  2.21342278,\n",
       "         -0.09560251,  4.17831802, -1.57328236, -2.1199255 ,  0.14131796,\n",
       "         -0.82598841, -0.77232718,  2.86442995, -0.39651984,  3.05176711,\n",
       "         -4.76891184, -2.44275022,  1.3918364 , -1.6473062 ,  2.5526104 ,\n",
       "          0.529163  , -0.05070388,  4.01657915,  3.67678761,  0.7815026 ,\n",
       "         -4.21997452,  0.93687075, -1.8767103 , -0.73343241, -0.7247659 ,\n",
       "          1.22286797,  3.92096472,  7.54777908,  0.803141  , -0.47977293,\n",
       "         -0.38357791, -2.56184673,  2.46469927,  0.48533058,  2.64418244,\n",
       "          2.13307619, -0.41187355,  4.27983522,  1.81513953,  0.74708211,\n",
       "         -0.6463086 ,  2.68100166, -0.54341531,  2.88786983, -3.16826105,\n",
       "          0.06675565]]], dtype=float32), time=2, alignments=array([[[  4.26141725e-07,   5.68184623e-06,   2.33928331e-05,\n",
       "           1.49068674e-02,   9.78966355e-01,   6.09735120e-03],\n",
       "        [  4.26141725e-07,   5.68184623e-06,   2.33928331e-05,\n",
       "           1.49068674e-02,   9.78966355e-01,   6.09735120e-03]]], dtype=float32), alignment_history=()))]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the returns, next_state and output to the step function, but how exactly do we transpose this back and push it\n",
    "#into cell? Moreover what is teh mechanics that determines when the beams become different? I.E. are no longer identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_state = tf.contrib.seq2seq.BeamSearchDecoderState(\n",
    "      cell_state=next_cell_state,\n",
    "      log_probs=next_beam_probs,\n",
    "      lengths=next_prediction_len,\n",
    "      finished=next_finished)\n",
    "\n",
    "beam_search_output = tf.contrib.seq2seq.BeamSearchDecoderOutput(\n",
    "      scores=next_beam_scores,\n",
    "      predicted_ids=next_word_ids,\n",
    "      parent_ids=next_beam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define the returns\n",
    "finished = beam_search_state.finished\n",
    "next_finished = finished\n",
    "sample_ids = beam_search_output.predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is most important, look up the new seq terms and take their embedding\n",
    "#We pass that onto the decoder cell network in the next loop iteration\n",
    "\n",
    "next_inputs = tf.cond(tf.reduce_all(finished), lambda: inf_model_2.inference_decoder._start_inputs,\n",
    "              lambda: inf_model_2.inference_decoder._embedding_fn(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we take the initially created tensor array with no output values and write the beam search output onto that tensor array \n",
    "\n",
    "initial_outputs_ta = nest.map_structure(lambda ta, out: ta.write(time, out),\n",
    "                          initial_outputs_ta, beam_search_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_outputs = nest.map_structure(lambda ta: ta.stack(), initial_outputs_ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_sequence_lengths = tf.where(tf.logical_and(tf.logical_not(finished), next_finished),\n",
    "      tf.fill(tf.shape(initial_sequence_lengths), time + 1), initial_sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = beam_search_state.finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = beam_search_output.predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_inputs = control_flow_ops.cond(math_ops.reduce_all(finished), \n",
    "                                    lambda: inf_model_2.inference_decoder._start_inputs,\n",
    "                                    lambda: inf_model_2.inference_decoder._embedding_fn(sample_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_inputs\n",
    "#These are the chosen word ids which we have performed the embedding look up for that we pass on\n",
    "first_inputs = next_inputs\n",
    "\n",
    "#next_states\n",
    "#these are the next states of the decoder network which pass back through the process\n",
    "initial_state = beam_search_state\n",
    "\n",
    "initial_finished = finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_outputs_ta = nest.map_structure(_create_ta, inf_model_2.inference_decoder.output_size,\n",
    "#                                                        inf_model_2.inference_decoder.output_dtype)\n",
    "\n",
    "initial_sequence_lengths = next_sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tf.add(time, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 17322\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "tf.reset_default_graph()\n",
    "time = 1\n",
    "n_grams = pickle.load(open('n_grams_test.pkl', 'rb'))\n",
    "\n",
    "n_grams_tf = tf.constant(n_grams[time])\n",
    "\n",
    "#beam = tf.constant([[6178, 5729], [8847, 16625], [12377,  6605]])\n",
    "beam = tf.constant([[ 6171231],\n",
    "        [ 4400],\n",
    "        [10359],\n",
    "        [11678]])\n",
    "beam_pad = tf.pad(beam, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\n",
    "\n",
    "initial_beam_step = tf.constant(0)\n",
    "n_beams = tf.constant(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(n_grams[time], columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When you specify the axis of concat such a rank must exist! \n",
    "#Thus cannot specify axis=1 if the rank is 0!\n",
    "scatter_base = tf.constant([vocab_size])\n",
    "concat_base = tf.constant([[1.0 for i in range(vocab_size)]], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_probs(n_grams_tf, y_equal_2): \n",
    "    #print ('Grab Probabilities')\n",
    "    y_args = tf.where(y_equal_2)\n",
    "\n",
    "    #Grab the n_gram sequences that are matched\n",
    "    y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "    #Take the last token in each sequence and count their unique occurrences\n",
    "\n",
    "    last_token_pos = tf.shape(y_diff_gather)[-1]\n",
    "\n",
    "    y_last_token = y_diff_gather[:,0][:,last_token_pos-1]\n",
    "    y_last_token_unique = tf.unique_with_counts(y_last_token)\n",
    "        \n",
    "    total_count = tf.reduce_sum(y_last_token_unique.count)\n",
    "    \n",
    "    indices = tf.reshape(y_last_token_unique.y, [tf.shape(y_last_token_unique.y)[0], 1])\n",
    "    \n",
    "    test_add_result = tf.scatter_nd(indices=indices, \n",
    "                updates=y_last_token_unique.count, shape=scatter_base)/total_count\n",
    "\n",
    "    test_add_result = tf.log(test_add_result + 10e-10)\n",
    "    \n",
    "    return tf.reshape(test_add_result, [1, 17322])\n",
    "\n",
    "def dump_zeros(n_grams_tf, y_equal_2): \n",
    "    #print ('No matches found')\n",
    "    return tf.constant([[0. for i in range(vocab_size)]], dtype=tf.float64)\n",
    "\n",
    "#Find where current beam matches n_gram sequence up to current seq pos, cast as int\n",
    "y_test = tf.to_int32(tf.equal(n_grams_tf, beam_pad[initial_beam_step]))\n",
    "#Reduce across the length of the beam \n",
    "y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n",
    "\n",
    "y_empty = tf.reduce_sum(y_test_reduce_sum)\n",
    "\n",
    "#Find args where the beam is matched to the n_gram combinations\n",
    "y_equal_2  = tf.equal(time, y_test_reduce_sum)\n",
    "\n",
    "#Why does cond proceed down both paths?\n",
    "test_add = tf.cond(tf.equal(0, tf.reduce_sum(tf.to_int32(y_equal_2))),\n",
    "    true_fn=lambda: dump_zeros(n_grams_tf, y_equal_2),\n",
    "    false_fn=lambda : grab_probs(n_grams_tf, y_equal_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    q = sess.run([tf.equal(0, tf.reduce_sum(tf.to_int32(y_equal_2))), test_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(q[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_base = tf.concat([concat_base, test_add], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    q = sess.run([concat_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_lm_process_body(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    #This loops on each beam individually\n",
    "    \n",
    "    #test = tf.concat([test, beam[time]], axis=0)\n",
    "    \n",
    "    #Find where current beam matches n_gram sequence up to current seq pos, cast as int\n",
    "    y_test = tf.to_int32(tf.equal(n_grams_tf, beam_pad[current_beam]))\n",
    "    #Reduce across the length of the beam \n",
    "    y_test_reduce_sum = tf.reduce_sum(y_test, axis=1)\n",
    "    #Find args where the beam is matched to the n_gram combinations\n",
    "    y_args = tf.where(tf.equal(2, y_test_reduce_sum))\n",
    "    #Grab the n_gram sequences that are matched\n",
    "    y_diff_gather = tf.gather(n_grams_tf, y_args)\n",
    "    #Take the last token in each sequence and count their unique occurrences\n",
    "    y_last_token = y_diff_gather[:,0][:,time]\n",
    "    y_last_token_unique = tf.unique_with_counts(y_last_token)\n",
    "    \n",
    "    total_count = tf.reduce_sum(y_last_token_unique.count)\n",
    "    test_add = tf.scatter_nd(indices=y_last_token_unique.y, \n",
    "                    updates=y_last_token_unique.count, shape=scatter_base)/total_count\n",
    "    \n",
    "    test_add = tf.log(test_add + 10e-10)\n",
    "    \n",
    "    test = tf.concat([test, [test_add]], axis=0)\n",
    "\n",
    "    return test, n_grams_tf, beam_pad, current_beam+1, n_beams\n",
    "\n",
    "def anti_lm_process_body_condition(test, n_grams_tf, beam_pad, current_beam, n_beams):\n",
    "    return current_beam < 3\n",
    "\n",
    "outputs = tf.while_loop(anti_lm_process_body_condition, anti_lm_process_body, \n",
    "                        [concat_base, n_grams_tf, beam_pad, initial_beam_step, n_beams], \n",
    "                        shape_invariants=[tf.TensorShape([None, 17322]), n_grams_tf.get_shape(),\n",
    "                                      beam_pad.get_shape(), initial_beam_step.get_shape(), n_beams.get_shape()])\n",
    "\n",
    "anti_beam_probs = outputs[0][1:]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #q = sess.run(outputs[0].stack())\n",
    "    q = sess.run(anti_beam_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = tf.constant(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
