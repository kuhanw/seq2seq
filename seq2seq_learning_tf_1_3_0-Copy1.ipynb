{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kuhan Wang 17-09-15\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.layers.core import Dense\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import helpers\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def encodeSent(sent):\n",
    "\n",
    "    if type(sent) == str: sent = sent.split(' ')\n",
    "    \n",
    "    return [vocab_dict[word] if word in vocab_dict else 2 for word in sent]\n",
    "\n",
    "def decodeSent(sent):\n",
    "    return [inv_map[i] for i in sent]\n",
    "\n",
    "def prepare_batch(seqs_x, maxlen=None):\n",
    "    # seqs_x: a list of sentences\n",
    "    lengths_x = [len(s) for s in seqs_x]\n",
    "    if maxlen is not None:\n",
    "        new_seqs_x = []\n",
    "        new_lengths_x = []\n",
    "        for l_x, s_x in zip(lengths_x, seqs_x):\n",
    "            if l_x <= maxlen:\n",
    "                new_seqs_x.append(s_x)\n",
    "                new_lengths_x.append(l_x)\n",
    "        lengths_x = new_lengths_x\n",
    "        seqs_x = new_seqs_x\n",
    "        \n",
    "        if len(lengths_x) < 1:\n",
    "            return None, None\n",
    "\n",
    "    batch_size = len(seqs_x)\n",
    "    x_lengths = np.array(lengths_x)\n",
    "    maxlen_x = np.max(x_lengths)\n",
    "    x = np.ones((batch_size, maxlen_x)).astype('int32') * PAD\n",
    "    for idx, s_x in enumerate(seqs_x):\n",
    "        x[idx, :lengths_x[idx]] = s_x\n",
    "    return x, x_lengths\n",
    "\n",
    "def prepare_train_batch(seqs_x, seqs_y, maxlen=None):\n",
    "    # seqs_x, seqs_y: a list of sentences\n",
    "    lengths_x = [len(s) for s in seqs_x]\n",
    "    lengths_y = [len(s) for s in seqs_y]\n",
    "\n",
    "    if maxlen is not None:\n",
    "        new_seqs_x = []\n",
    "        new_seqs_y = []\n",
    "        new_lengths_x = []\n",
    "        new_lengths_y = []\n",
    "        for l_x, s_x, l_y, s_y in zip(lengths_x, seqs_x, lengths_y, seqs_y):\n",
    "            if l_x <= maxlen and l_y <= maxlen:\n",
    "                new_seqs_x.append(s_x)\n",
    "                new_lengths_x.append(l_x)\n",
    "                new_seqs_y.append(s_y)\n",
    "                new_lengths_y.append(l_y)\n",
    "        lengths_x = new_lengths_x\n",
    "        seqs_x = new_seqs_x\n",
    "        lengths_y = new_lengths_y\n",
    "        seqs_y = new_seqs_y\n",
    "\n",
    "        if len(lengths_x) < 1 or len(lengths_y) < 1:\n",
    "            return None, None, None, None\n",
    "\n",
    "    batch_size = len(seqs_x)\n",
    "    \n",
    "    x_lengths = np.array(lengths_x)\n",
    "    y_lengths = np.array(lengths_y)\n",
    "\n",
    "    maxlen_x = np.max(x_lengths)\n",
    "    maxlen_y = np.max(y_lengths)\n",
    "\n",
    "    x = np.ones((batch_size, maxlen_x)).astype('int32') * PAD\n",
    "    y = np.ones((batch_size, maxlen_y)).astype('int32') * PAD\n",
    "    \n",
    "    for idx, [s_x, s_y] in enumerate(zip(seqs_x, seqs_y)):\n",
    "        x[idx, :lengths_x[idx]] = s_x\n",
    "        y[idx, :lengths_y[idx]] = s_y\n",
    "    return x, x_lengths, y, y_lengths\n",
    "\n",
    "def generateRandomSeqBatchMajor(length_from, length_to, vocab_lower, vocab_upper, batch_size):\n",
    "    return [\n",
    "            [random.randint(vocab_lower, vocab_upper-2) for digit in range(random.randint(length_from, length_to))] + [1]\n",
    "                for batch in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra vocabulary symbols\n",
    "_GO = '_GO'\n",
    "EOS = '_EOS' # also function as PAD\n",
    "UNK = '_UNK'\n",
    "\n",
    "extra_tokens = [_GO, EOS, UNK]\n",
    "\n",
    "start_token = extra_tokens.index(_GO)\t# start_token = 0\n",
    "end_token = extra_tokens.index(EOS)\t# end_token = 1\n",
    "unk_token = extra_tokens.index(UNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = pd.read_pickle('processed_data_v01_EN-DE_py35_seq_length_5_15_sample_540659_limited_vocab.pkl')\n",
    "#vocab_dict = pickle.load(open('word_dict_v01_EN-DE_py35_seq_length_5_15_sample_540659_limited_vocab.pkl', 'rb'))\n",
    "\n",
    "#df_all = pd.read_pickle('../processed_data/processed_data_v02_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl')\n",
    "#vocab_dict = pickle.load(open('../processed_data/word_dict_v02_enron_py35_seq_length_3_49_sample_4256_limited_vocab.pkl', 'rb'))\n",
    "\n",
    "dataset = 'twitter'\n",
    "\n",
    "df_all = pd.read_pickle('../processed_data/processed_data_v02_twitter_py35_seq_length_3_19_sample_22028_lem.pkl')\n",
    "vocab_dict = pickle.load(open('../processed_data/word_dict_v02_twitter_py35_seq_length_3_19_sample_22028_lem.pkl', 'rb'))\n",
    "\n",
    "#Encode sequences\n",
    "#df_all['alpha_Pair_1_encoding'] =  df_all['alpha_Pair_1_tokens'].apply(numericEncode)\n",
    "#df_all['alpha_Pair_0_encoding'] = df_all['alpha_Pair_0_tokens'].apply(numericEncode)\n",
    "\n",
    "df_all['alpha_Pair_1_encoding'] =  df_all['alpha_Pair_1_tokens'].apply(encodeSent)\n",
    "df_all['alpha_Pair_0_encoding'] = df_all['alpha_Pair_0_tokens'].apply(encodeSent)\n",
    "\n",
    "df_all['Index'] = df_all.index.values\n",
    "\n",
    "df_all_train = df_all.sample(frac=0.90, random_state=0)\n",
    "\n",
    "df_all_dev = df_all[df_all['Index'].isin(df_all_train['Index'].values) == False]\n",
    "\n",
    "df_all_test = df_all_dev.sample(frac=0.10, random_state=0)\n",
    "\n",
    "df_all_dev = df_all_dev[df_all_dev['Index'].isin(df_all_test['Index'].values) == False]\n",
    "\n",
    "inv_map = {v: k for k, v in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_encoded_text = df_all_dev['alpha_Pair_0_encoding'].values\n",
    "dev_decoded_text = df_all_dev['alpha_Pair_1_encoding'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_text = df_all_test['alpha_Pair_0_encoding'].values\n",
    "test_decoded_text = df_all_test['alpha_Pair_1_encoding'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15898, 5), (1590, 5), (177, 5), 17181)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_train.shape, df_all_dev.shape, df_all_test.shape, len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496.8125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "UNK = 2\n",
    "vocab_size = len(vocab_dict) + 1\n",
    "#vocab_size = 30\n",
    "input_embedding_size = 1024\n",
    "\n",
    "length_from = 3\n",
    "length_to = 19\n",
    "vocab_lower = 0\n",
    "vocab_upper = vocab_size\n",
    "n_batch_size = 32\n",
    "\n",
    "batches_in_epoch = df_all_train.shape[0]/n_batch_size\n",
    "#batches_in_epoch=100\n",
    "n_cells = 128\n",
    "num_layers = 1\n",
    "\n",
    "n_epochs = 1000\n",
    "n_beam_width = 1\n",
    "\n",
    "batches_in_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_batches = helpers.random_sequences(length_from=length_from, length_to=length_to,\n",
    "                                       vocab_lower=vocab_lower, vocab_upper=vocab_size,\n",
    "                                       batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create handles for encoder and decoders\n",
    "encoder_inputs = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs',\n",
    "        )\n",
    "\n",
    "encoder_inputs_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs_length',\n",
    "        )\n",
    "\n",
    "# required for training, not required for testing\n",
    "decoder_targets = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_targets'\n",
    "        )\n",
    "\n",
    "decoder_targets_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_targets_length',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = tf.shape(encoder_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make EOS and PAD matrices to concatenate with targets\n",
    "EOS_SLICE = tf.ones([batch_size, 1], dtype=tf.int32) * EOS\n",
    "PAD_SLICE = tf.ones([batch_size, 1], dtype=tf.int32) * PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding EOS to the beginning of the decoder targets\n",
    "decoder_train_inputs = tf.concat([EOS_SLICE, decoder_targets], axis=1, name='decoder_train_inputs_concat')\n",
    "#[1,10], [10, 16]\n",
    "decoder_train_length = decoder_targets_length + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_train_targets = tf.concat([decoder_targets, PAD_SLICE], axis=1, name='decoder_train_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_decoder_length = tf.reduce_max(decoder_train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create word embeddings\n",
    "sqrt3 = math.sqrt(3)\n",
    "initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "\n",
    "#Randomly initialize a embedding vector for each term in the vocabulary\n",
    "embedding_matrix = tf.get_variable(name=\"embedding_matrix\", shape=[vocab_size, input_embedding_size],\n",
    "                                   initializer=initializer, \n",
    "                                   dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map each input unit to a column in the embedding matrix\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, encoder_inputs)\n",
    "\n",
    "decoder_train_inputs_embedded = tf.nn.embedding_lookup(embedding_matrix, decoder_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_layer = Dense(n_cells, name='input_projection')\n",
    "\n",
    "# Output projection layer to convert cell_outputs to logits\n",
    "output_layer = Dense(vocab_size, name='output_projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bi-directional encoder, encoding the forward and backward states\n",
    "#The core abstraction is in tf.nn.bidirectional_dynamic_rnn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_keep = 1\n",
    "decoder_output_keep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_cell_fw = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells), input_keep_prob=1, \n",
    "#                                             output_keep_prob=encoder_output_keep)\n",
    "\n",
    "encoder_cell_list = []\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells, state_is_tuple=True), input_keep_prob=1, \n",
    "                                            output_keep_prob=encoder_output_keep)\n",
    "    encoder_cell_list.append(cell)\n",
    "\n",
    "encoder_cell =  tf.contrib.rnn.MultiRNNCell(encoder_cell_list)\n",
    "#encoder_cell_fw = tf.contrib.rnn.MultiRNNCell([encoder_cell_fw for _ in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_cell_bw = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells), input_keep_prob=1, \n",
    "#                                             output_keep_prob=encoder_output_keep)\n",
    "\n",
    "#encoder_cell = tf.contrib.rnn.LSTMCell(n_cells)\n",
    "#encoder_cell_bw = tf.contrib.rnn.MultiRNNCell([encoder_cell_bw for _ in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_last_state = tf.nn.dynamic_rnn(\n",
    "        cell=encoder_cell, inputs=encoder_inputs_embedded,\n",
    "        sequence_length=encoder_inputs_length, dtype=tf.float32,\n",
    "        time_major=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_last_state_beam = tf.contrib.framework.nest.map_structure(\n",
    "#        lambda s: tf.contrib.seq2seq.tile_batch(s, n_beam_width), encoder_last_state)\n",
    "\n",
    "encoder_last_state_beam = tf.contrib.seq2seq.tile_batch(encoder_last_state, n_beam_width)\n",
    "\n",
    "encoder_outputs_beam = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=n_beam_width)\n",
    "\n",
    "encoder_inputs_length_beam = tf.contrib.seq2seq.tile_batch(encoder_inputs_length, multiplier=n_beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "    num_units=n_cells, \n",
    "    memory=encoder_outputs, \n",
    "    memory_sequence_length=encoder_inputs_length) \n",
    "\n",
    "decoder_cell_list = []\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(n_cells, state_is_tuple=True), input_keep_prob=1, \n",
    "                                            output_keep_prob=decoder_output_keep)\n",
    "    decoder_cell_list.append(cell)\n",
    "\n",
    "decoder_cell =  tf.contrib.rnn.MultiRNNCell(decoder_cell_list)\n",
    "\n",
    "decoder_initial_state = encoder_last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_input_feeding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_decoder_input_fn(inputs, attention):\n",
    "    if not attn_input_feeding:\n",
    "        return inputs\n",
    "\n",
    "    # Essential when use_residual=True\n",
    "    _input_layer = Dense(n_cells, dtype=tf.float32,\n",
    "                         name='attn_input_feeding')\n",
    "    return _input_layer(array_ops.concat([inputs, attention], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell_list[-1] = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell=decoder_cell_list[-1],\n",
    "            attention_mechanism=attention_mechanism,\n",
    "            attention_layer_size=n_cells,\n",
    "          #  cell_input_fn=attn_decoder_input_fn,\n",
    "            #initial_cell_state=encoder_last_state[-1],\n",
    "            initial_cell_state=encoder_last_state[-1],                   \n",
    "            alignment_history=False,\n",
    "            name='Attention_Wrapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [state for state in encoder_last_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state[-1] = decoder_cell_list[-1].zero_state(batch_size=batch_size*n_beam_width, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state = tuple(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.MultiRNNCell(decoder_cell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_cell.state_size, encoder_inputs_embedded, encoder_inputs_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(\n",
    "# (encoder_fw_outputs, encoder_bw_outputs),\n",
    "# (encoder_fw_state, encoder_bw_state)\n",
    "#) = (\n",
    "#     tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell, \n",
    "#                                     cell_bw=encoder_cell,\n",
    "#                                     inputs=encoder_inputs_embedded,\n",
    "#                                     sequence_length=encoder_inputs_length,\n",
    "#                                     time_major=True, dtype=tf.float32)\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate backward and forward outputs\n",
    "#encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_state_c = tf.concat((encoder_fw_state.c, encoder_bw_state.c), 1, name='bidirectional_concat_c')\n",
    "#encoder_state_h = tf.concat((encoder_fw_state.h, encoder_bw_state.h), 1, name='bidirectional_concat_h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_state = tf.contrib.rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_state = []\n",
    "\n",
    "#for i in range(num_layers):\n",
    "    \n",
    "#    encoder_state_c = tf.concat((encoder_fw_state[i].c, encoder_bw_state[i].c), 1, name='bidirectional_concat_c')\n",
    "#    encoder_state_h = tf.concat((encoder_fw_state[i].h, encoder_bw_state[i].h), 1, name='bidirectional_concat_h')\n",
    "    \n",
    "#    current_encoder_state = tf.contrib.rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "#    encoder_state.append(current_encoder_state)\n",
    "\n",
    "#encoder_state = tuple(encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_states = tf.transpose(encoder_outputs, perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to feed inputs for training: read inputs from dense ground truth vectors\n",
    "training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_train_inputs_embedded,\n",
    "                                   sequence_length=decoder_train_length,\n",
    "                                   time_major=False,\n",
    "                                   name='training_helper')\n",
    "\n",
    "training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                   helper=training_helper,\n",
    "                                   initial_state=decoder_initial_state, \n",
    "                                   output_layer=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(decoder_outputs_train, decoder_last_state_train, decoder_outputs_length_train) = \\\n",
    "              (tf.contrib.seq2seq.dynamic_decode(\n",
    "                                                decoder=training_decoder,\n",
    "                                                output_time_major=False,\n",
    "                                                impute_finished=True,\n",
    "                                                maximum_iterations=max_decoder_length\n",
    "                                                )\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More efficient to do the projection on the batch-time-concatenated tensor\n",
    "# logits_train: [batch_size, max_time_step + 1, num_decoder_symbols]\n",
    "# self.decoder_logits_train = output_layer(self.decoder_outputs_train.rnn_output)\n",
    "decoder_logits_train = tf.identity(decoder_outputs_train.rnn_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use argmax to extract decoder symbols to emit\n",
    "decoder_pred_train = tf.argmax(decoder_logits_train, axis=-1, name='decoder_pred_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tokens = tf.ones([batch_size*n_beam_width,], tf.int32) * EOS\n",
    "end_token = EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to feed inputs for greedy decoding: uses the argmax of the output\n",
    "decoding_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(start_tokens=start_tokens,\n",
    "                                                end_token=end_token,\n",
    "                                                embedding=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder performs greedy decoding at each time step\n",
    "inference_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                         helper=decoding_helper,\n",
    "                                         initial_state=decoder_initial_state,\n",
    "                                         output_layer=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell=decoder_cell,\n",
    "#                                                               embedding=embedding_matrix,\n",
    "#                                                               start_tokens=start_tokens,\n",
    "#                                                               end_token=end_token,\n",
    "#                                                               initial_state=decoder_initial_state,\n",
    "#                                                               beam_width=n_beam_width,\n",
    "#                                                               output_layer=output_layer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_decode_step = tf.reduce_max(encoder_inputs_length) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "(decoder_outputs_decode, decoder_last_state_decode,\n",
    "         decoder_outputs_length_decode) = (tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder=inference_decoder,\n",
    "            output_time_major=False,\n",
    "            #impute_finished=True,\t# error occurs --why?\n",
    "            maximum_iterations=max_decode_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_pred_decode = tf.argmax(decoder_outputs_decode.rnn_output, axis=-1, name='decoder_pred_decode')\n",
    "\n",
    "decoder_pred_decode_prob = tf.nn.softmax(decoder_outputs_decode.rnn_output, name='decoder_pred_decode_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_pred_decode_prob = tf.nn.softmax(decoder_outputs_decode.rnn_output, name='decoder_pred_decode_prob')\n",
    "#decoder_pred_decode_prob = decoder_outputs_decode.beam_search_decoder_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks: masking for valid and padded time steps, [batch_size, max_time_step + 1]\n",
    "masks = tf.sequence_mask(lengths=decoder_train_length, \n",
    "                         maxlen=max_decoder_length, dtype=tf.float32, name='masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes per word average cross-entropy over a batch\n",
    "# Internally calls 'nn_ops.sparse_softmax_cross_entropy_with_logits' by default\n",
    "loss = tf.contrib.seq2seq.sequence_loss(logits=decoder_logits_train, \n",
    "                                  targets=decoder_train_targets,\n",
    "                                  weights=masks,\n",
    "                                  average_across_timesteps=True,\n",
    "                                  average_across_batch=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=decoder_train_targets,\n",
    "    logits=decoder_logits_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = df_all_train['alpha_Pair_0_encoding'].values\n",
    "decoded_text = df_all_train['alpha_Pair_1_encoding'].values\n",
    "text_index = df_all_train['Index'].values\n",
    "\n",
    "input_batches = ([encoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "         decoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                 text_index[block_idx*n_batch_size:(block_idx+1)*n_batch_size]]\\\n",
    "            for block_idx in range(len(encoded_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_seq = generateRandomSeqBatchMajor(length_from=length_from, length_to=length_to,\n",
    "                                       vocab_lower=2, vocab_upper=vocab_upper,\n",
    "                                       batch_size=n_batch_size)\n",
    "input_batch_data = ran_seq\n",
    "target_batch_data = input_batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17182"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fd = make_train_inputs(input_batch_data, target_batch_data)\n",
    "fd = prepare_train_batch([[4, 5, 7, 2, 5, 1], [4, 5, 7, 4, 5, 1]], [[4, 5, 7, 2, 30, 1],[4, 5, 7, 9, 5, 1]])\n",
    "feed_dict = {encoder_inputs: fd[0],\n",
    "        encoder_inputs_length: fd[1],\n",
    "        decoder_targets: fd[2],\n",
    "        decoder_targets_length: fd[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "    for i in range(1):\n",
    "        print (i)\n",
    "        #epoch_batches = next(input_batches)\n",
    "\n",
    "        #input_batch_data = epoch_batches[0]\n",
    "        #target_batch_data = epoch_batches[1]\n",
    "        #batch_data_index = epoch_batches[2]\n",
    "        #print ([inv_map[i] for i in input_batch_data[0]])\n",
    "       #fd = prepare_train_batch(input_batch_data, target_batch_data)\n",
    "        \n",
    "        #feed_dict = {encoder_inputs: fd[0],\n",
    "        #encoder_inputs_length: fd[1],\n",
    "        #decoder_targets: fd[2],\n",
    "        #decoder_targets_length: fd[3]}\n",
    "        \n",
    "        t = session.run([loss], feed_dict)\n",
    "        #y  = session.run([encoder_outputs_original, encoder_outputs], feed_dict)\n",
    "        #if t[1] !=t[1]: \n",
    "        #    print (loss)\n",
    "         #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.01\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, \\\n",
    "                                           n_epochs*int(batches_in_epoch), 0.0001, staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_task = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 1\n",
      "learning rate 0.00999981\n",
      "epoch 0\n",
      "batch 0\n",
      "training minibatch loss: 9.749956130981445\n",
      "  sample 1:\n",
      "    enc input           > his name is ghost we shall wait and see <EOS>\n",
      "    dec input           > that s the worse part how is he gunna prove that he didn t do it ? <EOS>\n",
      "    dec train predicted > that he he part how he he he that that he he that that he that <EOS>\n",
      "dev minibatch loss: 9.567595481872559\n",
      "  DEV sample 1:\n",
      "    DEV enc input           > just think in month he will be off the stage thank you lord <EOS>\n",
      "    DEV dec input           > on stage on the importance of investing in africa amp inspiring entrepreneur in africa u <EOS>\n",
      "    DEV dec train predicted > a a a hillary opposing some camp camp do camp\n",
      "    DEV dec train infer > that that that that that that that that that that that that that that that that that that that\n",
      "global_step: 51\n",
      "learning rate 0.00999053\n",
      "epoch 0\n",
      "batch 50\n",
      "training minibatch loss: 6.092986106872559\n",
      "  sample 1:\n",
      "    enc input           > and they ain t even large enough hahaha <EOS>\n",
      "    dec input           > forreal though <EOS>\n",
      "    dec train predicted > i the <EOS>\n",
      "dev minibatch loss: 6.230810165405273\n",
      "  DEV sample 1:\n",
      "    DEV enc input           > gold plated fixture installers <EOS>\n",
      "    DEV dec input           > i think marble installers is the nail in the coffin tonight <EOS>\n",
      "    DEV dec train predicted > i m the <EOS> <EOS> <EOS> same <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "    DEV dec train infer > i m <EOS> the\n",
      "global_step: 101\n",
      "learning rate 0.00998126\n",
      "epoch 0\n",
      "batch 100\n",
      "training minibatch loss: 6.404448986053467\n",
      "  sample 1:\n",
      "    enc input           > what are you doing with excel ? <EOS>\n",
      "    dec input           > that d be a weird confession i really like excel <EOS>\n",
      "    dec train predicted > i s you a much to <EOS> m the the <EOS>\n",
      "dev minibatch loss: 5.731067657470703\n",
      "  DEV sample 1:\n",
      "    DEV enc input           > you were supposed to be on electronic blackout tonight what happened ? <EOS>\n",
      "    DEV dec input           > turn out he actually didnt prepare pity these thing arent thirty minute longer <EOS>\n",
      "    DEV dec train predicted > i to to na <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "    DEV dec train infer > i m the best message to be the same <EOS> you <EOS> you have a much <EOS> you\n"
     ]
    }
   ],
   "source": [
    "train_loss_track = []\n",
    "dev_loss_track = []\n",
    "\n",
    "all_weights = []\n",
    "dev_test_results = []\n",
    "metric_results = []\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    #saver.restore(session, \\\n",
    "    #    './seq2seq_CornelMovies_encode_100_decode_200_vocab_13679_embedding_200_seq_5_15_batch_64_layers_3_v5-210')\n",
    "    #saver.restore(session, \\\n",
    "    #    './seq2seq_CornelMovies_encode_100_decode_200_vocab_13679_embedding_200_seq_5_15_batch_64_layers_3_v5-100')\n",
    "    #saver.restore(session, \\\n",
    "    #    'd:\\coding\\seq2seq_CornelMovies_encode_200_decode_400_vocab_13679_embedding_200_seq_5_15_batch_128_layers_6_v6-990')\n",
    "    #saver.restore(session, \\\n",
    "    #    './seq2seq_CornelMovies_encode_500_decode_1000_vocab_13679_embedding_1024_seq_5_15_batch_32_layers_6_v6-30')\n",
    "    #saver.restore(session, \\\n",
    "    #'d:\\coding\\chkpt\\seq2seq_Cornell_encode_128_decode_256_vocab_13679_embedding_256_seq_5_15_batch_32_layers_3_enkeep_10_dekeep_10-203320')\n",
    "    #saver.restore(session, \\\n",
    "    #'d:\\coding\\seq2seq\\chkpt\\seq2seq_twitter_encode_128_decode_128_vocab_29164_embedding_512_seq_3_29_batch_32_layers_3_enkeep_10_dekeep_10-8858')\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        df_all_train = df_all_train.sample(frac=1, random_state=tf.train.global_step(session, global_step))\n",
    "        #tf.train.global_step(session, global_step))\n",
    "       \n",
    "        encoded_text = df_all_train['alpha_Pair_0_encoding'].values\n",
    "        decoded_text = df_all_train['alpha_Pair_1_encoding'].values\n",
    "        text_index = df_all_train['Index'].values\n",
    "\n",
    "        input_batches = ([encoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                 decoded_text[block_idx*n_batch_size:(block_idx+1)*n_batch_size], \n",
    "                         text_index[block_idx*n_batch_size:(block_idx+1)*n_batch_size]]\\\n",
    "                    for block_idx in range(len(encoded_text)))\n",
    "        \n",
    "        for batch in range(int(batches_in_epoch)):\n",
    "            mean_metric_train = []\n",
    "            mean_metric_dev = []\n",
    "\n",
    "            if copy_task == False:\n",
    "                \n",
    "                epoch_batches = next(input_batches)\n",
    "                \n",
    "                #input_batch_data = next(encoding_batches)\n",
    "                #target_batch_data = next(decoding_batches)\n",
    "                \n",
    "                input_batch_data = epoch_batches[0]\n",
    "                target_batch_data = epoch_batches[1]\n",
    "                batch_data_index = epoch_batches[2]\n",
    "\n",
    "            else:\n",
    "                ran_seq = generateRandomSeqBatchMajor(length_from=length_from, length_to=length_to,\n",
    "                                       vocab_lower=2, vocab_upper=vocab_upper,\n",
    "                                       batch_size=n_batch_size)\n",
    "                input_batch_data = ran_seq\n",
    "                target_batch_data = input_batch_data\n",
    "            \n",
    "            fd = prepare_train_batch(input_batch_data, target_batch_data)\n",
    "            feed_dict = {encoder_inputs: fd[0],\n",
    "                        encoder_inputs_length: fd[1],\n",
    "                        decoder_targets: fd[2],\n",
    "                        decoder_targets_length: fd[3]}\n",
    "           \n",
    "            _, l = session.run([train_op, loss], feed_dict)\n",
    "            \n",
    "            if batch % 50 == 0: \n",
    "                \n",
    "                print ('global_step: %s' % tf.train.global_step(session, global_step))\n",
    "                print ('learning rate', session.run(optimizer._lr))\n",
    "                \n",
    "                print ('epoch', epoch)\n",
    "                print ('batch {}'.format(batch))\n",
    "                print ('training minibatch loss: {}'.format(l))\n",
    "                \n",
    "                train_loss_track.append([tf.train.global_step(session, global_step), l])\n",
    "\n",
    "                for i, (e_in, dt_targ, dt_pred) in enumerate(zip(feed_dict[encoder_inputs], \n",
    "                                                                 feed_dict[decoder_targets], \n",
    "                                                                 session.run(decoder_pred_train, feed_dict))):\n",
    "\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    #print('    Index', batch_data_index[i])\n",
    "                    #print('    enc input           > {}'.format(e_in))\n",
    "                    print('    enc input           > {}'.format(' '.join([inv_map[i] for i in e_in if i!=0])))\n",
    "\n",
    "                    #print('    dec input           > {}'.format(dt_targ))\n",
    "                    print('    dec input           > {}'.format(' '.join([inv_map[i] for i in dt_targ if i!=0])))\n",
    "\n",
    "                    #print('    dec train predicted > {}'.format(dt_pred))\n",
    "                    print('    dec train predicted > {}'.format(' '.join([inv_map[i] for i in dt_pred if i!=0])))\n",
    "                \n",
    "                    if i >= 0: break\n",
    "                        \n",
    "                #DEV CHECK\n",
    "                df_all_dev_check = df_all_dev.sample(n=32, random_state=tf.train.global_step(session, global_step))\n",
    "\n",
    "                dev_encoded_text = df_all_dev_check['alpha_Pair_0_encoding'].values\n",
    "                dev_decoded_text = df_all_dev_check['alpha_Pair_1_encoding'].values\n",
    "\n",
    "                fd_dev = prepare_train_batch([i for i in dev_encoded_text], [i for i in dev_decoded_text])\n",
    "\n",
    "                feed_dict_dev = {encoder_inputs: fd_dev[0],\n",
    "                                 encoder_inputs_length: fd_dev[1],\n",
    "                                 decoder_targets: fd_dev[2],\n",
    "                                 decoder_targets_length: fd_dev[3]}\n",
    "\n",
    "                #fd_inf = prepare_batch([i for i in dev_encoded_text])\n",
    "\n",
    "                feed_dict_inf = {encoder_inputs: fd_dev[0],\n",
    "                                 encoder_inputs_length: fd_dev[1]}\n",
    "\n",
    "                dev_inf_out = session.run([decoder_pred_decode, decoder_pred_decode_prob], feed_dict_inf) \n",
    "                dev_loss = session.run(loss, feed_dict_dev)\n",
    "                \n",
    "                dev_loss_track.append([tf.train.global_step(session, global_step), dev_loss])\n",
    "                print ('dev minibatch loss: {}'.format(dev_loss))\n",
    "\n",
    "                for i, (e_in, dt_targ, dt_pred, dt_inf, df_inf_out_prob) in enumerate(zip(feed_dict_dev[encoder_inputs], \n",
    "                                                                 feed_dict_dev[decoder_targets], \n",
    "                                                                 session.run(decoder_pred_train, feed_dict_dev),\n",
    "                                                                 dev_inf_out[0], dev_inf_out[1])):\n",
    "\n",
    "                    print('  DEV sample {}:'.format(i + 1))\n",
    "                    #print('    Index', batch_data_index[i])\n",
    "                    #print('    DEV enc input           > {}'.format(e_in))\n",
    "                    print('    DEV enc input           > {}'.format(' '.join([inv_map[i] for i in e_in if i!=0])))\n",
    "\n",
    "                   # print('    DEV dec input           > {}'.format(dt_targ))\n",
    "                    print('    DEV dec input           > {}'.format(' '.join([inv_map[i] for i in dt_targ if i!=0])))\n",
    "\n",
    "                    #print('    DEV dec train predicted > {}'.format(dt_pred))\n",
    "                    print('    DEV dec train predicted > {}'.format(' '.join([inv_map[i] for i in dt_pred if i!=0])))\n",
    "                    \n",
    "                    #print('    DEV dec train infer > {}'.format(dt_inf))\n",
    "                    print('    DEV dec train infer > {}'.format(' '.join([inv_map[i] for i in dt_inf if i!=0])))\n",
    "                \n",
    "                    if i >= 0: break\n",
    "\n",
    "             \n",
    "                 #   df_prediction_train = predictionCheck(mean_metric_train)\n",
    "                 #   print (df_prediction_train['meanCheckList'].describe()['mean'])\n",
    "\n",
    "                 #   df_prediction_dev = predictionCheck(mean_metric_dev)\n",
    "                #    print (df_prediction_dev['meanCheckList'].describe()['mean'])\n",
    "\n",
    "                 #   metric_results.append([df_prediction_train, df_prediction_dev])\n",
    "                \n",
    "        if epoch % 3 == 0: \n",
    "            print ('Saving session')\n",
    "            #eval_dev = devCheck(dev_encoded_text, dev_decoded_text, True)\n",
    "            \n",
    "            #dev_test_results.append(eval_dev)\n",
    "            \n",
    "            #pickle.dump(dev_test_results, open('d:\\coding\\chkpt\\dev_test_results_epoch_%d.pkl' % epoch, 'wb'))\n",
    "            \n",
    "            saver.save(session, \\\n",
    "'chkpt/seq2seq_%s_encode_%d_decode_%d_vocab_%d_embedding_%d_seq_%d_%d_batch_%d_layers_%d_enkeep_%d_dekeep_%d' % \\\n",
    "                (dataset, n_cells, n_cells, vocab_size, input_embedding_size, length_from, length_to, n_batch_size, num_layers,\n",
    "                int(encoder_output_keep*10), int(decoder_output_keep*10)), \\\n",
    "                       global_step = tf.train.global_step(session, global_step))\n",
    "            #saver.save(session, 'd:\\coding\\seq2seq\\chkpt\\copy_task', global_step = tf.train.global_step(session, global_step))\n",
    "       # variables_names =[v.name for v in tf.trainable_variables()]\n",
    "       # values = session.run(variables_names)\n",
    "       # all_weights.append([values[1], values[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0fe837d7c17b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdev_loss_track\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdev_loss_track\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Dev'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_track\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloss_track\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Global Step'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sequence Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'best'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(list(zip(*dev_loss_track))[0], list(zip(*dev_loss_track))[1], label='Dev')\n",
    "plt.plot(list(zip(*loss_track))[0], list(zip(*loss_track))[1], label='Train')\n",
    "plt.xlabel('Global Step')\n",
    "plt.ylabel('Sequence Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create inference\n",
    "mean_metric = []\n",
    "chunk_size = 500\n",
    "#n_chunks = int(df_all_train.shape[0]/chunk_size)\n",
    "n_chunks=10\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, \\\n",
    "'d:\\coding\\seq2seq\\chkpt\\seq2seq_enron_encode_24_decode_48_vocab_10_embedding_32_seq_3_10_batch_32_layers_1_enkeep_10_dekeep_10-9639')\n",
    "  #  saver.restore(session, 'd:\\coding\\seq2seq\\chkpt\\copy_task-19100')\n",
    "    \n",
    "    for chunk in range(n_chunks):\n",
    "        if chunk>0: break\n",
    "        ran_seq = generateRandomSeqBatchMajor(length_from=length_from, length_to=length_to,\n",
    "                       vocab_lower=2, vocab_upper=vocab_upper,\n",
    "                       batch_size=n_batch_size)\n",
    "        \n",
    "        #input_batch_data = ran_seq\n",
    "        input_batch_data = [[3,4,5,6,7,8, 9]]\n",
    "        #input_batch_data = df_all_dev['alpha_Pair_0_encoding'].values[:32]\n",
    "        \n",
    "        fd_inf = prepare_batch(input_batch_data)\n",
    "        feed_dict_inf = {encoder_inputs: fd_inf[0],\n",
    "                    encoder_inputs_length: fd_inf[1]}\n",
    "        inf_out = session.run([decoder_pred_decode, decoder_pred_decode_prob], feed_dict_inf)\n",
    "\n",
    "        #print (df_all_train.values[0][1], df_all_train.values[1][1])\n",
    "        #print (feed_dict_inf)\n",
    "        for i, (e_in, dt_inf) in enumerate(zip(feed_dict_inf[encoder_inputs], inf_out[0])):\n",
    "            #mean_metric.append([df_all_train.values[i][0], df_all_train.values[i][1], dt_inf])\n",
    "            print('    sample {}:'.format(i + 1))\n",
    "            print('    enc input                > {}'.format([inv_map[k] for k in e_in]))\n",
    "            print('    dec input                > {}'.format([inv_map[k] for k in df_all_dev['alpha_Pair_1_encoding'].values[i]]))\n",
    "            print('    dec train inference      > {}'.format([inv_map[k] for k in dt_inf]))\n",
    "            #print('    dec train inference prob > {}'.format([inf_out[1][j][i].max() for j in range((len(inf_out[1])))]))\n",
    "            \n",
    "            #if i>0: break\n",
    "        \n",
    "       # print ('Save Model')\n",
    "       # builder = tf.saved_model.builder.SavedModelBuilder('d:\\coding\\seq2seq\\model')\n",
    "       # builder.add_meta_graph_and_variables(session, ['serve'])\n",
    "\n",
    "        #builder.save()\n",
    "    ops = session.graph.get_operations()\n",
    "\n",
    "    feed_ops = [op for op in ops if op.type=='Placeholder']\n",
    "\n",
    "    print(feed_ops)\n",
    "        #if n_chunks >0: \n",
    "         #   break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
